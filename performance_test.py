#!/usr/bin/env python3
"""
DreamSeed API ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""
import requests
import time
import statistics
import concurrent.futures
import json
from datetime import datetime

API_BASE = "http://127.0.0.1:8002"

def test_endpoint(endpoint, iterations=10):
    """ë‹¨ì¼ ì—”ë“œí¬ì¸íŠ¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print(f"\nğŸ§ª {endpoint} ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ({iterations}íšŒ)")
    
    times = []
    errors = 0
    
    for i in range(iterations):
        start_time = time.time()
        try:
            response = requests.get(f"{API_BASE}{endpoint}", timeout=10)
            end_time = time.time()
            
            if response.status_code == 200:
                times.append(end_time - start_time)
            else:
                errors += 1
                print(f"  âŒ ìš”ì²­ {i+1}: HTTP {response.status_code}")
        except Exception as e:
            errors += 1
            print(f"  âŒ ìš”ì²­ {i+1}: {e}")
    
    if times:
        avg_time = statistics.mean(times)
        min_time = min(times)
        max_time = max(times)
        median_time = statistics.median(times)
        
        print(f"  âœ… ì„±ê³µ: {len(times)}/{iterations}")
        print(f"  ğŸ“Š í‰ê·  ì‘ë‹µì‹œê°„: {avg_time:.3f}ì´ˆ")
        print(f"  ğŸ“Š ìµœì†Œ ì‘ë‹µì‹œê°„: {min_time:.3f}ì´ˆ")
        print(f"  ğŸ“Š ìµœëŒ€ ì‘ë‹µì‹œê°„: {max_time:.3f}ì´ˆ")
        print(f"  ğŸ“Š ì¤‘ê°„ê°’: {median_time:.3f}ì´ˆ")
        
        return {
            'endpoint': endpoint,
            'success_rate': len(times) / iterations,
            'avg_time': avg_time,
            'min_time': min_time,
            'max_time': max_time,
            'median_time': median_time,
            'errors': errors
        }
    else:
        print(f"  âŒ ëª¨ë“  ìš”ì²­ ì‹¤íŒ¨")
        return {
            'endpoint': endpoint,
            'success_rate': 0,
            'avg_time': 0,
            'min_time': 0,
            'max_time': 0,
            'median_time': 0,
            'errors': errors
        }

def test_concurrent_load(endpoint, concurrent_users=10, requests_per_user=5):
    """ë™ì‹œ ì‚¬ìš©ì ë¶€í•˜ í…ŒìŠ¤íŠ¸"""
    print(f"\nğŸš€ {endpoint} ë™ì‹œ ë¶€í•˜ í…ŒìŠ¤íŠ¸ ({concurrent_users}ëª… Ã— {requests_per_user}íšŒ)")
    
    def make_request():
        times = []
        for _ in range(requests_per_user):
            start_time = time.time()
            try:
                response = requests.get(f"{API_BASE}{endpoint}", timeout=10)
                end_time = time.time()
                if response.status_code == 200:
                    times.append(end_time - start_time)
            except:
                pass
        return times
    
    start_time = time.time()
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=concurrent_users) as executor:
        futures = [executor.submit(make_request) for _ in range(concurrent_users)]
        results = [future.result() for future in concurrent.futures.as_completed(futures)]
    
    end_time = time.time()
    total_time = end_time - start_time
    
    all_times = []
    for result in results:
        all_times.extend(result)
    
    if all_times:
        total_requests = len(all_times)
        success_rate = total_requests / (concurrent_users * requests_per_user)
        rps = total_requests / total_time
        
        print(f"  âœ… ì´ ìš”ì²­: {total_requests}")
        print(f"  âœ… ì„±ê³µë¥ : {success_rate:.2%}")
        print(f"  âœ… RPS: {rps:.2f}")
        print(f"  âœ… ì´ ì‹œê°„: {total_time:.2f}ì´ˆ")
        print(f"  ğŸ“Š í‰ê·  ì‘ë‹µì‹œê°„: {statistics.mean(all_times):.3f}ì´ˆ")
        
        return {
            'endpoint': endpoint,
            'concurrent_users': concurrent_users,
            'requests_per_user': requests_per_user,
            'total_requests': total_requests,
            'success_rate': success_rate,
            'rps': rps,
            'total_time': total_time,
            'avg_response_time': statistics.mean(all_times)
        }
    else:
        print(f"  âŒ ëª¨ë“  ìš”ì²­ ì‹¤íŒ¨")
        return None

def test_cache_performance():
    """ìºì‹œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print(f"\nğŸ’¾ ìºì‹œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
    
    # ì²« ë²ˆì§¸ ìš”ì²­ (ìºì‹œ ë¯¸ìŠ¤)
    start_time = time.time()
    response1 = requests.get(f"{API_BASE}/api/dashboard/stats")
    first_time = time.time() - start_time
    
    # ë‘ ë²ˆì§¸ ìš”ì²­ (ìºì‹œ íˆíŠ¸)
    start_time = time.time()
    response2 = requests.get(f"{API_BASE}/api/dashboard/stats")
    second_time = time.time() - start_time
    
    print(f"  ğŸ“Š ì²« ë²ˆì§¸ ìš”ì²­ (ìºì‹œ ë¯¸ìŠ¤): {first_time:.3f}ì´ˆ")
    print(f"  ğŸ“Š ë‘ ë²ˆì§¸ ìš”ì²­ (ìºì‹œ íˆíŠ¸): {second_time:.3f}ì´ˆ")
    print(f"  ğŸ“Š ìºì‹œ íš¨ê³¼: {first_time/second_time:.1f}x ë¹¨ë¼ì§")
    
    return {
        'cache_miss_time': first_time,
        'cache_hit_time': second_time,
        'cache_improvement': first_time / second_time
    }

def get_system_info():
    """ì‹œìŠ¤í…œ ì •ë³´ ìˆ˜ì§‘"""
    print(f"\nğŸ“Š ì‹œìŠ¤í…œ ì •ë³´")
    
    # Redis ì •ë³´
    try:
        cache_response = requests.get(f"{API_BASE}/api/cache/status")
        if cache_response.status_code == 200:
            cache_info = cache_response.json()
            print(f"  ğŸ’¾ Redis ìƒíƒœ: {cache_info.get('status', 'unknown')}")
            print(f"  ğŸ’¾ ìºì‹œëœ í‚¤: {cache_info.get('cached_keys', 0)}")
            print(f"  ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {cache_info.get('used_memory_human', 'unknown')}")
    except:
        print(f"  âŒ Redis ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨")
    
    # í—¬ìŠ¤ì²´í¬
    try:
        health_response = requests.get(f"{API_BASE}/healthz")
        if health_response.status_code == 200:
            health_info = health_response.json()
            print(f"  ğŸ¥ API ìƒíƒœ: {health_info.get('status', 'unknown')}")
            print(f"  ğŸ¥ ìºì‹œ ìƒíƒœ: {health_info.get('cache', 'unknown')}")
    except:
        print(f"  âŒ í—¬ìŠ¤ì²´í¬ ì‹¤íŒ¨")

def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ğŸš€ DreamSeed API ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print(f"â° ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # ì‹œìŠ¤í…œ ì •ë³´
    get_system_info()
    
    # í…ŒìŠ¤íŠ¸í•  ì—”ë“œí¬ì¸íŠ¸ë“¤
    endpoints = [
        "/healthz",
        "/api/dashboard/stats",
        "/api/dashboard/user-growth",
        "/api/dashboard/daily-activity",
        "/api/dashboard/country-data",
        "/api/dashboard/recent-activities"
    ]
    
    results = []
    
    # ê°œë³„ ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸
    for endpoint in endpoints:
        result = test_endpoint(endpoint, iterations=5)
        results.append(result)
    
    # ìºì‹œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
    cache_result = test_cache_performance()
    
    # ë™ì‹œ ë¶€í•˜ í…ŒìŠ¤íŠ¸ (stats ì—”ë“œí¬ì¸íŠ¸)
    load_result = test_concurrent_load("/api/dashboard/stats", concurrent_users=5, requests_per_user=3)
    
    # ê²°ê³¼ ìš”ì•½
    print(f"\nğŸ“‹ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print(f"{'ì—”ë“œí¬ì¸íŠ¸':<30} {'ì„±ê³µë¥ ':<8} {'í‰ê· ì‘ë‹µì‹œê°„':<12} {'ìµœëŒ€ì‘ë‹µì‹œê°„':<12}")
    print("-" * 70)
    
    for result in results:
        print(f"{result['endpoint']:<30} {result['success_rate']:<8.1%} {result['avg_time']:<12.3f} {result['max_time']:<12.3f}")
    
    if cache_result:
        print(f"\nğŸ’¾ ìºì‹œ ì„±ëŠ¥:")
        print(f"  ìºì‹œ ë¯¸ìŠ¤: {cache_result['cache_miss_time']:.3f}ì´ˆ")
        print(f"  ìºì‹œ íˆíŠ¸: {cache_result['cache_hit_time']:.3f}ì´ˆ")
        print(f"  ì„±ëŠ¥ í–¥ìƒ: {cache_result['cache_improvement']:.1f}x")
    
    if load_result:
        print(f"\nğŸš€ ë¶€í•˜ í…ŒìŠ¤íŠ¸:")
        print(f"  ì´ ìš”ì²­: {load_result['total_requests']}")
        print(f"  ì„±ê³µë¥ : {load_result['success_rate']:.1%}")
        print(f"  RPS: {load_result['rps']:.2f}")
        print(f"  í‰ê·  ì‘ë‹µì‹œê°„: {load_result['avg_response_time']:.3f}ì´ˆ")
    
    print(f"\nâœ… ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

if __name__ == "__main__":
    main()

