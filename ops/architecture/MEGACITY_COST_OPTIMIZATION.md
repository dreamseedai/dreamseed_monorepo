# ğŸ’° DreamSeedAI MegaCity â€“ Cost Optimization Guide

## AI Â· GPU Â· LLM Â· Storage Â· Network ë¹„ìš©ì„ 70% ì ˆê°í•˜ëŠ” ì‹¤ì „ ì „ëµ

**ë²„ì „:** 1.0  
**ì‘ì„±ì¼:** 2025-11-22  
**ì‘ì„±ì:** DreamSeedAI FinOps & Architecture Team

---

# ğŸ“Œ 0. ê°œìš” (Overview)

DreamSeedAI MegaCityëŠ” **9ê°œ Zone + AI Cluster + Multi-modal ì„œë¹„ìŠ¤ + GPU ê¸°ë°˜ AI** ë¡œ êµ¬ì„±ëœ ëŒ€ê·œëª¨ í”Œë«í¼ì…ë‹ˆë‹¤.

ë”°ë¼ì„œ ìš´ì˜ ë¹„ìš©ì´ íš¨ê³¼ì ìœ¼ë¡œ ê´€ë¦¬ë˜ì§€ ì•Šìœ¼ë©´:

* **GPU ë¹„ìš© í­ì¦** (vLLM, Whisper, PoseNet)
* **Storage ê³¼ë‹¤ ê³¼ê¸ˆ** (K-Zone ë¯¸ë””ì–´, AI ì¶œë ¥ë¬¼)
* **LLM í˜¸ì¶œë¹„ ì¦ê°€** (ë¶ˆí•„ìš”í•œ ëŒ€í˜• ëª¨ë¸ ì‚¬ìš©)
* **CDN/Traffic ë¹„ìš© ì¦ê°€** (ìºì‹œ ë¯¸í™œìš©)
* **API ì„œë²„ ê³¼í• ë‹¹ ë¬¸ì œ** (ë¦¬ì†ŒìŠ¤ ë‚­ë¹„)

ë³¸ ë¬¸ì„œëŠ” MegaCity ì „ì²´ ë¹„ìš©ì„ **ìµœëŒ€ 70% ì ˆê°**í•  ìˆ˜ ìˆëŠ” êµ¬ì¡°ì  FinOps ì „ëµì„ ì œê³µí•©ë‹ˆë‹¤.

## ë¬¸ì„œ ëª©ì 

- MegaCity ì „ì²´ ë¹„ìš© êµ¬ì¡° ë¶„ì„
- 5ëŒ€ ë¹„ìš© ì˜ì—­ë³„ ìµœì í™” ì „ëµ ì œì‹œ
- GPU/LLM/Storage/Network/Compute ë¹„ìš© ì ˆê° ë°©ë²•
- ì‹¤í–‰ ê°€ëŠ¥í•œ ì‹œë‚˜ë¦¬ì˜¤ ë° ROI ê³„ì‚°
- FinOps ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ êµ¬ì„±

---

# ğŸ§± 1. ë¹„ìš© êµ¬ì¡° ìš”ì•½ (Cost Structure Breakdown)

## 1.1 MegaCity ì›”ê°„ ë¹„ìš© êµ¬ì¡° (ì˜ˆìƒ)

| ë¹„ìš© í•­ëª© | ë¹„ì¤‘ | ì›” ì˜ˆìƒ ë¹„ìš© (10K ì‚¬ìš©ì) | ìµœì í™” í›„ |
|----------|------|---------------------------|----------|
| **GPU ë¹„ìš©** (vLLM, Whisper, PoseNet) | 40~60% | $8,000 ~ $12,000 | $2,400 ~ $4,800 (60~70% ì ˆê°) |
| **Cloud Storage / CDN** | 15~25% | $3,000 ~ $5,000 | $900 ~ $1,500 (70% ì ˆê°) |
| **Compute** (API, Next.js) | 10~20% | $2,000 ~ $4,000 | $1,200 ~ $2,400 (40% ì ˆê°) |
| **Network Traffic** (Egress) | 5~10% | $1,000 ~ $2,000 | $200 ~ $400 (80% ì ˆê°) |
| **Monitoring/Logs** | 5% | $1,000 | $500 (50% ì ˆê°) |
| **Total** | 100% | **$15,000 ~ $24,000** | **$4,700 ~ $9,600** |

**ì ˆê° íš¨ê³¼: 60~70% ë¹„ìš© ì ˆê°**

## 1.2 ë¹„ìš© ìµœì í™” 5ëŒ€ ì „ëµ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. GPU ë¹„ìš© ìµœì í™” (40~70% ì ˆê°)                       â”‚
â”‚     â€¢ ë¡œì»¬ GPU (RTX 5090) vs Cloud GPU (A100)           â”‚
â”‚     â€¢ Auto-scaling (Off-peak shutdown)                  â”‚
â”‚     â€¢ Quantization (8bit/4bit)                          â”‚
â”‚     â€¢ KV Cache ì¬ì‚¬ìš©                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. LLM ë¹„ìš© ìµœì í™” (50~85% ì ˆê°)                       â”‚
â”‚     â€¢ ëª¨ë¸ í¬ê¸°ë³„ ì—­í•  ë¶„ë¦¬ (7B/32B/70B)                â”‚
â”‚     â€¢ Prompt Compression (í† í° ìˆ˜ 50% ê°ì†Œ)             â”‚
â”‚     â€¢ vLLM Cache ì¬ì‚¬ìš©                                 â”‚
â”‚     â€¢ Hybrid Model Routing                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. Storage ë¹„ìš© ìµœì í™” (40~85% ì ˆê°)                   â”‚
â”‚     â€¢ Cloudflare R2 (Egress ë¬´ë£Œ)                       â”‚
â”‚     â€¢ Backblaze B2 Archive (Cold Storage)               â”‚
â”‚     â€¢ ë¯¸ì‚¬ìš© AI ì¶œë ¥ë¬¼ ìë™ ì‚­ì œ                         â”‚
â”‚     â€¢ Media Compression (WebP, 720p)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. Network ë¹„ìš© ìµœì í™” (50~90% ì ˆê°)                   â”‚
â”‚     â€¢ Cloudflare CDN ìºì‹œìœ¨ 90%+ ëª©í‘œ                   â”‚
â”‚     â€¢ HTTP/3 + Brotli ì••ì¶•                              â”‚
â”‚     â€¢ ì´ë¯¸ì§€ ì§€ì—° ë¡œë”© (Lazy Loading)                   â”‚
â”‚     â€¢ ë¡œê·¸/ë©”íŠ¸ë¦­ ìƒ˜í”Œë§                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. Compute ë¹„ìš© ìµœì í™” (30~50% ì ˆê°)                   â”‚
â”‚     â€¢ ì„œë²„ ìˆ˜ ì ì •í™” (Horizontal Scaling)               â”‚
â”‚     â€¢ FastAPI ìµœì í™” (Worker, Connection pooling)       â”‚
â”‚     â€¢ Next.js ISR (Incremental Static Regeneration)     â”‚
â”‚     â€¢ Nginx/Traefik ì••ì¶•Â·ìºì‹œ ìµœëŒ€í™”                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# ğŸ”¥ 2. GPU ë¹„ìš© ìµœì í™” (ì ˆê° íš¨ê³¼: 40%~70%)

AI ë¹„ìš©ì€ ëŒ€ë¶€ë¶„ GPUì—ì„œ ë°œìƒí•©ë‹ˆë‹¤. DreamSeedAIëŠ” **ë¡œì»¬ GPU + Edge GPU + Spot GPU** í˜¼í•© êµ¬ì¡°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

## 2.1 RTX 5090 (ë¡œì»¬) vs A100 (Cloud) ë¹„ìš© ë¹„êµ

### ë¹„ìš© ë¹„êµ (ì‹œê°„ë‹¹)

| GPU | ì‹œê°„ë‹¹ ë¹„ìš© | ì›” ë¹„ìš© (24/7) | ì—° ë¹„ìš© |
|-----|-------------|----------------|---------|
| **AWS A100 (80GB)** | $4.00/hr | $2,880 | $34,560 |
| **GCP A100 (40GB)** | $3.40/hr | $2,448 | $29,376 |
| **RTX 5090 (48GB) ë¡œì»¬** | $0.20/hr (ì „ê¸°ë¹„ í¬í•¨) | $144 | $1,728 |

**ì ˆê° íš¨ê³¼: RTX 5090 ë¡œì»¬ GPU â†’ ì—°ê°„ $27,000~$32,000 ì ˆê° (GPU 1ëŒ€ë‹¹)**

### ROI ê³„ì‚°

```
RTX 5090 êµ¬ë§¤ ë¹„ìš©: $2,000 (ì˜ˆìƒ)
ì›” ì „ê¸°ë¹„: $30~$50
íˆ¬ì íšŒìˆ˜ ê¸°ê°„: ì•½ 2~3ê°œì›”
```

### ì „ëµ

```python
# AI Router ì„¤ì •
AI_GPU_CONFIG = {
    "primary": "local_rtx5090",  # ë¡œì»¬ GPU ìš°ì„ 
    "fallback": "cloud_a100",    # ê³¼ë¶€í•˜ ì‹œ Cloud GPU
    "cost_threshold": 0.9        # GPU ì‚¬ìš©ë¥  90% ì´ˆê³¼ ì‹œ Cloud ì‚¬ìš©
}
```

---

## 2.2 GPU Auto-scaling (Off-peak Shutdown)

### ì‹œê°„ëŒ€ë³„ ì‚¬ìš© íŒ¨í„´ ë¶„ì„

```
Peak ì‹œê°„ëŒ€ (09:00~22:00): GPU ì‚¬ìš©ë¥  70~90%
Off-peak (23:00~08:00): GPU ì‚¬ìš©ë¥  5~15%
```

### Auto-scaling ì „ëµ

```python
import schedule
from datetime import datetime

def check_gpu_scale():
    hour = datetime.now().hour
    
    if 9 <= hour <= 22:  # Peak
        target_gpu_count = 2
    else:  # Off-peak
        target_gpu_count = 1
    
    current_gpu_count = get_active_gpu_count()
    
    if target_gpu_count > current_gpu_count:
        scale_up_gpu(target_gpu_count - current_gpu_count)
    elif target_gpu_count < current_gpu_count:
        scale_down_gpu(current_gpu_count - target_gpu_count)

# ë§¤ ì‹œê°„ë§ˆë‹¤ ì²´í¬
schedule.every(1).hours.do(check_gpu_scale)
```

**ì ˆê° íš¨ê³¼: Off-peak GPU 1ëŒ€ ê°ì¶• â†’ ì›” $1,440 ì ˆê° (A100 ê¸°ì¤€)**

---

## 2.3 vLLM Key/Value Cache (KV Cache) ì¬ì‚¬ìš©

### KV Cacheë€?

LLMì€ ì´ì „ í† í°ì˜ Key/Valueë¥¼ ì¬ì‚¬ìš©í•˜ì—¬ ì¶”ë¡  ì†ë„ë¥¼ ë†’ì…ë‹ˆë‹¤.

### ìµœì í™” ì„¤ì •

```python
# vLLM ì„œë²„ ì‹¤í–‰
vllm serve Qwen/Qwen2.5-32B-Instruct \
  --tensor-parallel-size 2 \
  --max-model-len 8192 \
  --gpu-memory-utilization 0.9 \
  --enable-prefix-caching \  # KV Cache í™œì„±í™”
  --max-num-seqs 64 \
  --dtype bfloat16
```

### íš¨ê³¼

- **ì²˜ë¦¬ëŸ‰ ì¦ê°€**: 20~30% ë” ë§ì€ ìš”ì²­ ì²˜ë¦¬
- **Latency ê°ì†Œ**: í‰ê·  ì‘ë‹µ ì‹œê°„ 30% ê°ì†Œ
- **GPU íš¨ìœ¨**: ë™ì¼ GPUë¡œ ë” ë§ì€ ì‚¬ìš©ì ì§€ì›

**ì ˆê° íš¨ê³¼: GPU 1ëŒ€ë¡œ 1.3ë°° ì²˜ë¦¬ëŸ‰ â†’ GPU 1ëŒ€ ì ˆê° = ì›” $2,448 ì ˆê°**

---

## 2.4 Quantization (8bit/4bit) ì ìš©

### Quantizationì´ë€?

ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ FP16 â†’ INT8 ë˜ëŠ” INT4ë¡œ ë³€í™˜í•˜ì—¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì†Œ.

### ë¹„êµ

| Precision | ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (70B ëª¨ë¸) | Inference ì†ë„ | ì •í™•ë„ |
|-----------|--------------------------|----------------|--------|
| **FP16** | 140GB | ê¸°ì¤€ | 100% |
| **INT8 (GPTQ)** | 70GB | 1.5x | 99.5% |
| **INT4 (AWQ)** | 35GB | 2x | 98% |

### ì ìš© ì˜ˆì‹œ

```python
# GPTQ 8bit ëª¨ë¸ ë¡œë”©
from transformers import AutoModelForCausalLM

model = AutoModelForCausalLM.from_pretrained(
    "Qwen/Qwen2.5-32B-Instruct-GPTQ-Int8",
    device_map="auto",
    trust_remote_code=True
)
```

**ì ˆê° íš¨ê³¼: ë©”ëª¨ë¦¬ 50% ê°ì†Œ â†’ GPU 1ëŒ€ë¡œ 2ë°° ëª¨ë¸ í¬ê¸° ì„œë¹™ ê°€ëŠ¥**

---

## 2.5 Multi-GPU Parallelism ìµœì í™”

### Tensor Parallelism (TP) ë¹„ìš©

```
TP=1: GPU 1ëŒ€, ì²˜ë¦¬ëŸ‰ 100%
TP=2: GPU 2ëŒ€, ì²˜ë¦¬ëŸ‰ 150% (2ë°° ë¹„ìš©, 1.5ë°° ì„±ëŠ¥)
TP=4: GPU 4ëŒ€, ì²˜ë¦¬ëŸ‰ 200% (4ë°° ë¹„ìš©, 2ë°° ì„±ëŠ¥)
```

### ì „ëµ

```python
# ì‘ì€ ëª¨ë¸ì€ TP=1 ì‚¬ìš©
SMALL_MODELS = ["7B", "14B"]  # TP=1
MEDIUM_MODELS = ["32B"]       # TP=2
LARGE_MODELS = ["70B"]        # TP=4

def select_tensor_parallel(model_size: str) -> int:
    if model_size in SMALL_MODELS:
        return 1
    elif model_size in MEDIUM_MODELS:
        return 2
    else:
        return 4
```

**ì ˆê° íš¨ê³¼: ì‘ì€ ëª¨ë¸ì— TP=1 ì‚¬ìš© â†’ GPU 1ëŒ€ ì ˆê° = ì›” $2,448**

---

## 2.6 GPU ë¹„ìš© ìµœì í™” ì²´í¬ë¦¬ìŠ¤íŠ¸

```
â–¡ RTX 5090 ë¡œì»¬ GPU ìš°ì„  ì‚¬ìš©
â–¡ Off-peak ì‹œê°„ëŒ€ GPU 1ëŒ€ë¡œ ì¶•ì†Œ
â–¡ vLLM KV Cache í™œì„±í™”
â–¡ GPTQ/AWQ Quantization ì ìš©
â–¡ TP=1ë¡œ ì‘ì€ ëª¨ë¸ ì„œë¹™
â–¡ GPU ì‚¬ìš©ë¥  70~90% ìœ ì§€ (< 70% â†’ scale down)
â–¡ Cloud GPUëŠ” Spot Instance ì‚¬ìš© (70% í• ì¸)
```

---

# ğŸ§  3. LLM ë¹„ìš© ìµœì í™” (ì ˆê° íš¨ê³¼: 50%~85%)

LLM ë¹„ìš©ì€ **ëª¨ë¸ ì„ íƒ, í”„ë¡¬í”„íŠ¸ êµ¬ì„±, ìºì‹± ì „ëµ**ì— ë”°ë¼ ì²œì°¨ë§Œë³„ì…ë‹ˆë‹¤.

## 3.1 ëª¨ë¸ í¬ê¸°ë³„ ì—­í•  ë¶„ë¦¬

### ëª¨ë¸ ì—­í•  ë§¤íŠ¸ë¦­ìŠ¤

| ëª¨ë¸ í¬ê¸° | ìš©ë„ | Latency | ë¹„ìš© (ìƒëŒ€) | ì‚¬ìš© ë¹„ì¤‘ ëª©í‘œ |
|----------|------|---------|-------------|---------------|
| **7B** (Small) | ê°„ë‹¨í•œ Q/A, í•„í„°ë§, ë¶„ë¥˜ | < 1s | 1x | 50~60% |
| **14B~32B** (Medium) | êµìœ¡ ë¶„ì„, Essay feedback | < 2s | 3x | 30~40% |
| **70B+** (Large) | ìµœìƒìœ„ í’ˆì§ˆ í•„ìš” ì‹œ | < 5s | 10x | 5~10% |

### Routing ì „ëµ

```python
def select_model(task_type: str, user_tier: str) -> str:
    # Simple tasks â†’ Small model
    if task_type in ["classification", "qa", "filter"]:
        return "Qwen2.5-7B"
    
    # Educational analysis â†’ Medium model
    elif task_type in ["essay_feedback", "math_tutor"]:
        if user_tier == "pro":
            return "Qwen2.5-32B"
        else:
            return "Qwen2.5-14B"
    
    # Premium features â†’ Large model
    elif task_type in ["advanced_reasoning", "code_review"]:
        if user_tier == "pro":
            return "Qwen2.5-72B"
        else:
            return "Qwen2.5-32B"  # Fallback
    
    return "Qwen2.5-7B"  # Default
```

**ì ˆê° íš¨ê³¼: ëŒ€í˜• ëª¨ë¸ ì‚¬ìš© 50% ê°ì†Œ â†’ ì›” $3,000~$5,000 ì ˆê°**

---

## 3.2 Prompt Compression (í”„ë¡¬í”„íŠ¸ ê¸¸ì´ 50% ê°ì†Œ)

### ë¬¸ì œì 

```python
# Bad: ë¶ˆí•„ìš”í•˜ê²Œ ê¸´ í”„ë¡¬í”„íŠ¸ (500 tokens)
prompt = f"""
You are an AI tutor helping students with math problems.
The student is in grade 10 and studying algebra.
Please provide a detailed explanation with step-by-step solutions.

Question: {user_question}

Please be encouraging and supportive.
Use simple language that a 10th grader can understand.
Include examples if needed.
"""
```

### ìµœì í™”

```python
# Good: ê°„ê²°í•œ í”„ë¡¬í”„íŠ¸ (150 tokens)
prompt = f"""Math Tutor (Grade 10):
Q: {user_question}
Explain step-by-step, simple language."""
```

### System Prompt ì¬ì‚¬ìš©

```python
# System promptëŠ” í•œ ë²ˆë§Œ ì „ì†¡
SYSTEM_PROMPTS = {
    "math_tutor": "You are a helpful math tutor for grade 10 students. Explain step-by-step.",
    "essay_feedback": "Provide constructive essay feedback focusing on structure and clarity."
}

# API í˜¸ì¶œ ì‹œ
response = llm.generate(
    system=SYSTEM_PROMPTS["math_tutor"],
    user=user_question  # ì§§ê²Œ ìœ ì§€
)
```

**ì ˆê° íš¨ê³¼: í”„ë¡¬í”„íŠ¸ 50% ë‹¨ì¶• â†’ í† í° ë¹„ìš© 50% ì ˆê°**

---

## 3.3 vLLM ë‚´ë¶€ Cache í™œìš©

### Prefix Caching

```python
# ë™ì¼í•œ system promptëŠ” ìºì‹œë¨
responses = []
for question in user_questions:
    response = llm.generate(
        system="You are a helpful math tutor.",  # ìºì‹œë¨
        user=question
    )
    responses.append(response)

# ì²« ìš”ì²­: 500ms
# ì´í›„ ìš”ì²­: 100ms (80% ë¹ ë¦„)
```

### íš¨ê³¼

- **Cache Hit Rate**: 60~80%
- **Latency ê°ì†Œ**: 50~70%
- **ì²˜ë¦¬ëŸ‰ ì¦ê°€**: 2~3ë°°

**ì ˆê° íš¨ê³¼: GPU ì‚¬ìš© ì‹œê°„ 50% ê°ì†Œ â†’ ì›” $1,200~$2,400 ì ˆê°**

---

## 3.4 Hybrid Model Routing (ì–¸ì–´ë³„/ë„ë©”ì¸ë³„)

### ì–¸ì–´ë³„ ëª¨ë¸ ì„ íƒ

```python
LANGUAGE_MODELS = {
    "ko": "beomi/Llama-3-Open-Ko-8B",     # í•œêµ­ì–´ íŠ¹í™” (ì €ë ´)
    "en": "Qwen2.5-7B-Instruct",          # ì˜ì–´ ë²”ìš©
    "ja": "elyza/Llama-3-ELYZA-JP-8B",    # ì¼ë³¸ì–´ íŠ¹í™”
    "zh": "Qwen2.5-7B-Instruct"           # ì¤‘êµ­ì–´ (Qwen ê¸°ë³¸ ê°•ì )
}

def select_language_model(text: str) -> str:
    lang = detect_language(text)
    return LANGUAGE_MODELS.get(lang, "Qwen2.5-7B-Instruct")
```

### ë„ë©”ì¸ë³„ ëª¨ë¸ ì„ íƒ

```python
DOMAIN_MODELS = {
    "math": "deepseek-ai/deepseek-math-7b",  # ìˆ˜í•™ íŠ¹í™”
    "code": "deepseek-ai/deepseek-coder-6.7b",  # ì½”ë”© íŠ¹í™”
    "general": "Qwen2.5-7B-Instruct"  # ë²”ìš©
}
```

**ì ˆê° íš¨ê³¼: íŠ¹í™” ëª¨ë¸ ì‚¬ìš© â†’ ëŒ€í˜• ëª¨ë¸ ëŒ€ë¹„ 70% ë¹„ìš© ì ˆê°**

---

## 3.5 Response Caching (Redis)

### ë™ì¼ ì§ˆë¬¸ ìºì‹±

```python
import hashlib
import redis

r = redis.Redis()

def get_llm_response(prompt: str) -> str:
    # í”„ë¡¬í”„íŠ¸ í•´ì‹œ
    prompt_hash = hashlib.sha256(prompt.encode()).hexdigest()
    
    # ìºì‹œ í™•ì¸
    cached = r.get(f"llm:{prompt_hash}")
    if cached:
        return cached.decode()
    
    # LLM í˜¸ì¶œ
    response = llm.generate(prompt)
    
    # ìºì‹œ ì €ì¥ (24ì‹œê°„)
    r.setex(f"llm:{prompt_hash}", 86400, response)
    
    return response
```

**ì ˆê° íš¨ê³¼: Cache Hit Rate 30% â†’ LLM í˜¸ì¶œ 30% ê°ì†Œ â†’ ì›” $900~$1,500 ì ˆê°**

---

## 3.6 LLM ë¹„ìš© ìµœì í™” ì²´í¬ë¦¬ìŠ¤íŠ¸

```
â–¡ ì‘ì€ ëª¨ë¸(7B) ì‚¬ìš© ë¹„ì¤‘ 50% ì´ìƒ
â–¡ ëŒ€í˜• ëª¨ë¸(70B) ì‚¬ìš© ë¹„ì¤‘ 10% ì´í•˜
â–¡ Prompt ê¸¸ì´ ìµœì†Œí™” (< 200 tokens)
â–¡ System prompt ì¬ì‚¬ìš©
â–¡ vLLM Prefix Caching í™œì„±í™”
â–¡ ì–¸ì–´ë³„/ë„ë©”ì¸ë³„ íŠ¹í™” ëª¨ë¸ ì‚¬ìš©
â–¡ Response Caching (Redis) êµ¬í˜„
â–¡ ë™ì¼ ì§ˆë¬¸ Cache Hit Rate 30% ì´ìƒ
```

---

# ğŸ“¦ 4. Storage ë¹„ìš© ìµœì í™” (ì ˆê° íš¨ê³¼: 40%~85%)

MegaCityëŠ” ë¯¸ë””ì–´(K-Zone), ë¬¸ì œì€í–‰, AI ì¶œë ¥ë¬¼ì´ ë§ì•„ Storage ë¹„ìš©ì´ ê¸‰ì¦í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## 4.1 Cloudflare R2 (Egress ë¬´ë£Œ) í•„ìˆ˜ ì‚¬ìš©

### ë¹„ìš© ë¹„êµ

| Storage | ì €ì¥ ë¹„ìš© | Egress ë¹„ìš© | ì›” ë¹„ìš© (1TB ì €ì¥, 10TB ì „ì†¡) |
|---------|----------|-------------|------------------------------|
| **AWS S3** | $0.023/GB | $0.09/GB | $23 + $900 = **$923** |
| **GCS** | $0.020/GB | $0.12/GB | $20 + $1,200 = **$1,220** |
| **Cloudflare R2** | $0.015/GB | **$0** | $15 + $0 = **$15** |

**ì ˆê° íš¨ê³¼: R2 ì‚¬ìš© â†’ ì›” $900~$1,200 ì ˆê° (1TB ì €ì¥, 10TB ì „ì†¡ ê¸°ì¤€)**

### ë§ˆì´ê·¸ë ˆì´ì…˜ ì „ëµ

```bash
# S3 â†’ R2 ë§ˆì´ê·¸ë ˆì´ì…˜
rclone sync s3:dreamseed-storage r2:dreamseed-storage \
  --progress \
  --transfers 8 \
  --checkers 16
```

### R2 ì‚¬ìš© ì˜ˆì‹œ

```python
import boto3

# R2 ì—°ê²° (S3 í˜¸í™˜ API)
s3 = boto3.client(
    's3',
    endpoint_url='https://<account_id>.r2.cloudflarestorage.com',
    aws_access_key_id=R2_ACCESS_KEY,
    aws_secret_access_key=R2_SECRET_KEY
)

# íŒŒì¼ ì—…ë¡œë“œ
s3.upload_file('local.mp4', 'dreamseed-storage', 'kzone/video.mp4')
```

---

## 4.2 Backblaze B2 Archive (Cold Storage)

### ì‚¬ìš© ì „ëµ

```
Hot Data (30ì¼ ì´ë‚´): R2 (ìì£¼ ì ‘ê·¼)
Warm Data (30~90ì¼): R2 (ê°€ë” ì ‘ê·¼)
Cold Data (90ì¼+): B2 (ê±°ì˜ ì ‘ê·¼ ì•ˆ í•¨)
```

### ë¹„ìš© ë¹„êµ

| Storage | ì €ì¥ ë¹„ìš© | Egress ë¹„ìš© (ì²« 1GB ë¬´ë£Œ í›„) |
|---------|----------|------------------------------|
| **R2** | $0.015/GB | $0 |
| **B2** | $0.005/GB | $0.01/GB |

**ì ˆê° íš¨ê³¼: Cold Storage B2 ì´ë™ â†’ ì €ì¥ ë¹„ìš© 67% ì ˆê°**

### ìë™ ì•„ì¹´ì´ë¹™

```python
import boto3
from datetime import datetime, timedelta

def archive_old_files():
    # R2ì—ì„œ 90ì¼ ì´ìƒ íŒŒì¼ ì°¾ê¸°
    cutoff_date = datetime.now() - timedelta(days=90)
    
    for obj in s3_r2.list_objects_v2(Bucket='dreamseed-storage')['Contents']:
        if obj['LastModified'] < cutoff_date:
            # B2ë¡œ ë³µì‚¬
            s3_b2.copy_object(
                CopySource={'Bucket': 'dreamseed-storage', 'Key': obj['Key']},
                Bucket='dreamseed-archive',
                Key=obj['Key']
            )
            
            # R2ì—ì„œ ì‚­ì œ
            s3_r2.delete_object(Bucket='dreamseed-storage', Key=obj['Key'])
```

---

## 4.3 ë¯¸ì‚¬ìš© AI ì¶œë ¥ë¬¼ ìë™ ì‚­ì œ ì •ì±…

### ì„ì‹œ íŒŒì¼ ìˆ˜ëª… ì •ì±…

```python
RETENTION_POLICIES = {
    "/kzone/tmp/*": 24,          # 24ì‹œê°„
    "/tmp/whisper/*": 7,         # 7ì¼
    "/tmp/posenet/*": 7,         # 7ì¼
    "/exams/attempts/*/audio": 30,  # 30ì¼
    "/ai-outputs/temp/*": 3      # 3ì¼
}

def cleanup_expired_files():
    for prefix, retention_days in RETENTION_POLICIES.items():
        cutoff = datetime.now() - timedelta(days=retention_days)
        
        for obj in s3.list_objects_v2(Bucket='dreamseed-storage', Prefix=prefix)['Contents']:
            if obj['LastModified'] < cutoff:
                s3.delete_object(Bucket='dreamseed-storage', Key=obj['Key'])
                print(f"Deleted: {obj['Key']}")
```

### Cron Job ì„¤ì •

```bash
# /etc/cron.daily/cleanup-storage.sh
#!/bin/bash
python /opt/scripts/cleanup_expired_files.py
```

**ì ˆê° íš¨ê³¼: ì„ì‹œ íŒŒì¼ ìë™ ì‚­ì œ â†’ Storage 20~30% ì ˆê°**

---

## 4.4 Media Compression ìë™í™”

### ë¹„ë””ì˜¤ ì••ì¶•

```python
import ffmpeg

def compress_video(input_path: str, output_path: str):
    # 1080p â†’ 720p, H.265 ì¸ì½”ë”©
    ffmpeg.input(input_path).output(
        output_path,
        vcodec='libx265',
        crf=28,
        vf='scale=-2:720',
        acodec='aac',
        audio_bitrate='128k'
    ).run()
```

### ì´ë¯¸ì§€ ì••ì¶• (WebP)

```python
from PIL import Image

def compress_image(input_path: str, output_path: str):
    img = Image.open(input_path)
    img.save(output_path, 'webp', quality=85, method=6)
```

### ìë™ ì••ì¶• íŒŒì´í”„ë¼ì¸

```python
@app.post("/api/v1/kzone/upload")
async def upload_kzone_media(file: UploadFile):
    # ì›ë³¸ ì €ì¥
    original_path = f"/tmp/{file.filename}"
    with open(original_path, "wb") as f:
        f.write(await file.read())
    
    # ì••ì¶•
    compressed_path = f"/tmp/compressed_{file.filename}"
    if file.content_type.startswith("video"):
        compress_video(original_path, compressed_path)
    elif file.content_type.startswith("image"):
        compress_image(original_path, compressed_path)
    
    # R2 ì—…ë¡œë“œ
    s3.upload_file(compressed_path, 'dreamseed-storage', f'kzone/{file.filename}')
    
    # ë¡œì»¬ ì„ì‹œ íŒŒì¼ ì‚­ì œ
    os.remove(original_path)
    os.remove(compressed_path)
    
    return {"status": "uploaded", "size_reduction": "40%"}
```

**ì ˆê° íš¨ê³¼: ë¹„ë””ì˜¤/ì´ë¯¸ì§€ ì••ì¶• â†’ Storage 40~60% ì ˆê°**

---

## 4.5 Storage ë¹„ìš© ìµœì í™” ì²´í¬ë¦¬ìŠ¤íŠ¸

```
â–¡ Cloudflare R2ë¡œ ì „ì²´ ë§ˆì´ê·¸ë ˆì´ì…˜ (Egress ë¬´ë£Œ)
â–¡ Cold StorageëŠ” B2ë¡œ ì´ë™ (90ì¼+)
â–¡ ì„ì‹œ íŒŒì¼ ìë™ ì‚­ì œ ì •ì±… ì ìš©
â–¡ ë¹„ë””ì˜¤ 720p + H.265 ì••ì¶•
â–¡ ì´ë¯¸ì§€ WebP ë³€í™˜ (Quality 85)
â–¡ ì¤‘ë³µ íŒŒì¼ ì œê±° (Deduplication)
â–¡ Storage ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ (Grafana Dashboard)
```

---

# ğŸŒ 5. Network ë¹„ìš© ìµœì í™” (ì ˆê° íš¨ê³¼: 50%~90%)

Network ë¹„ìš©ì€ ì£¼ë¡œ **Egress (ë°ì´í„° ì „ì†¡)** ì—ì„œ ë°œìƒí•©ë‹ˆë‹¤.

## 5.1 Cloudflare CDN ìºì‹œìœ¨ 90% ì´ìƒ ëª©í‘œ

### ìºì‹œ ê°€ëŠ¥í•œ ë¦¬ì†ŒìŠ¤

```
ì •ì  íŒŒì¼: CSS, JS, Fonts
ë¯¸ë””ì–´: ì´ë¯¸ì§€, ë¹„ë””ì˜¤, ì˜¤ë””ì˜¤
K-Zone ì½˜í…ì¸ : ëŒ„ìŠ¤ ì˜ìƒ, ìŒì„± íŒŒì¼
API ì‘ë‹µ (ì„ íƒì ): ë¬¸ì œì€í–‰ ëª©ë¡, ê³µì§€ì‚¬í•­
```

### Cloudflare Cache Rule ì„¤ì •

```javascript
// Cloudflare Page Rules
{
  "url": "https://cdn.dreamseedai.com/*",
  "cache_level": "cache_everything",
  "edge_cache_ttl": 2592000  // 30ì¼
}

{
  "url": "https://api.dreamseedai.com/api/v1/questions*",
  "cache_level": "cache_everything",
  "edge_cache_ttl": 3600  // 1ì‹œê°„
}
```

### Cache Control í—¤ë”

```python
@app.get("/api/v1/questions")
async def get_questions(response: Response):
    questions = await db.fetch_all("SELECT * FROM questions")
    
    # 1ì‹œê°„ ìºì‹œ
    response.headers["Cache-Control"] = "public, max-age=3600"
    
    return questions
```

**ì ˆê° íš¨ê³¼: Cache Hit Rate 90% â†’ Origin íŠ¸ë˜í”½ 90% ê°ì†Œ**

---

## 5.2 HTTP/3 + Brotli ì••ì¶•

### HTTP/3 í™œì„±í™”

```nginx
# Nginx HTTP/3 ì„¤ì •
listen 443 quic reuseport;
listen 443 ssl http2;

ssl_protocols TLSv1.3;
http3 on;
quic_retry on;

add_header Alt-Svc 'h3=":443"; ma=86400';
```

### Brotli ì••ì¶•

```nginx
# Brotli compression
brotli on;
brotli_comp_level 6;
brotli_types text/plain text/css text/xml text/javascript application/json application/javascript;
```

### íš¨ê³¼

- **HTTP/3**: íŒ¨í‚· ì†ì‹¤ ê°ì†Œ, ì „ì†¡ ì†ë„ 20% í–¥ìƒ
- **Brotli**: Gzip ëŒ€ë¹„ 20~30% ë” ì••ì¶•

**ì ˆê° íš¨ê³¼: ì „ì†¡ëŸ‰ 30~40% ê°ì†Œ â†’ Network ë¹„ìš© 30~40% ì ˆê°**

---

## 5.3 ì´ë¯¸ì§€ ì§€ì—° ë¡œë”© (Lazy Loading)

### Next.js Image Component

```tsx
import Image from 'next/image'

export function KZoneGallery({ videos }) {
  return (
    <div>
      {videos.map(video => (
        <Image
          src={video.thumbnail}
          width={320}
          height={180}
          loading="lazy"  // ì§€ì—° ë¡œë”©
          placeholder="blur"
          alt={video.title}
        />
      ))}
    </div>
  )
}
```

### íš¨ê³¼

- ì´ˆê¸° í˜ì´ì§€ ë¡œë”© ì‹œ ì´ë¯¸ì§€ ì „ì†¡ëŸ‰ 70% ê°ì†Œ
- ì‚¬ìš©ìê°€ ìŠ¤í¬ë¡¤í•´ì•¼ë§Œ ì´ë¯¸ì§€ ë¡œë“œ

**ì ˆê° íš¨ê³¼: í˜ì´ì§€ë·°ë‹¹ ì „ì†¡ëŸ‰ 50% ê°ì†Œ**

---

## 5.4 ë¡œê·¸/ë©”íŠ¸ë¦­ ìƒ˜í”Œë§

### ë¬¸ì œì 

```
ëŒ€ëŸ‰ íŠ¸ë˜í”½ ì‹œ ëª¨ë“  ìš”ì²­ ë¡œê¹… â†’ ë¡œê·¸ ì „ì†¡ëŸ‰ ê¸‰ì¦
ì˜ˆ: 100K req/day â†’ 10GB ë¡œê·¸/day
```

### ìƒ˜í”Œë§ ì „ëµ

```python
import random

@app.middleware("http")
async def log_sampling_middleware(request: Request, call_next):
    # 1% ìƒ˜í”Œë§
    if random.random() < 0.01:
        log_request(request)
    
    response = await call_next(request)
    return response
```

### Prometheus ìƒ˜í”Œë§

```yaml
# Prometheus scrape config
scrape_configs:
  - job_name: 'backend-api'
    scrape_interval: 30s  # 15s â†’ 30së¡œ ì¦ê°€
    metric_relabel_configs:
      - source_labels: [__name__]
        regex: 'http_request_.*'
        action: drop  # ë¶ˆí•„ìš”í•œ ë©”íŠ¸ë¦­ ì œê±°
```

**ì ˆê° íš¨ê³¼: ë¡œê·¸/ë©”íŠ¸ë¦­ ì „ì†¡ëŸ‰ 90% ê°ì†Œ**

---

## 5.5 Network ë¹„ìš© ìµœì í™” ì²´í¬ë¦¬ìŠ¤íŠ¸

```
â–¡ Cloudflare CDN Cache Hit Rate > 90%
â–¡ HTTP/3 í™œì„±í™”
â–¡ Brotli ì••ì¶• ì ìš©
â–¡ ì´ë¯¸ì§€ Lazy Loading êµ¬í˜„
â–¡ ë¡œê·¸ ìƒ˜í”Œë§ (1~5%)
â–¡ API ì‘ë‹µ Gzip ì••ì¶•
â–¡ WebSocket ë©”ì‹œì§€ ì••ì¶•
â–¡ Static assetsëŠ” CDNì—ì„œ 100% ì œê³µ
```

---

# ğŸ–¥ï¸ 6. Compute ë¹„ìš© ìµœì í™” (ì ˆê° íš¨ê³¼: 30%~50%)

## 6.1 ì„œë²„ ìˆ˜ ì ì •í™” (Horizontal Scaling)

### ê³¼í• ë‹¹ ë¬¸ì œ

```
í˜„ì¬: API ì„œë²„ 5ëŒ€ (ê° 8 vCPU, 16GB RAM)
í‰ê·  CPU ì‚¬ìš©ë¥ : 20%
â†’ 3ëŒ€ë¡œ ì¶©ë¶„
```

### ì ì •í™” ì „ëµ

```python
# Kubernetes HPA (Horizontal Pod Autoscaler)
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: backend-api-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: backend-api
  minReplicas: 2
  maxReplicas: 10
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 70  # 70% CPU ëª©í‘œ
```

**ì ˆê° íš¨ê³¼: ì„œë²„ 2ëŒ€ ê°ì¶• â†’ ì›” $400~$800 ì ˆê°**

---

## 6.2 FastAPI ìµœì í™”

### uvicorn Worker ìˆ˜ ì¡°ì ˆ

```python
# ê³¼í• ë‹¹
uvicorn main:app --workers 16  # CPU 8ê°œì¸ë° 16 workers

# ì ì •
uvicorn main:app --workers 8  # CPU ê°œìˆ˜ë§Œí¼
```

### DB Connection Pooling

```python
from sqlalchemy.pool import QueuePool

engine = create_engine(
    DATABASE_URL,
    poolclass=QueuePool,
    pool_size=10,        # ê¸°ë³¸ ì—°ê²° ìˆ˜
    max_overflow=20,     # ì¶”ê°€ ì—°ê²° ìˆ˜
    pool_pre_ping=True,  # ì—°ê²° ê²€ì¦
    pool_recycle=3600    # 1ì‹œê°„ë§ˆë‹¤ ì¬ì—°ê²°
)
```

### Response Caching

```python
from fastapi_cache import FastAPICache
from fastapi_cache.backends.redis import RedisBackend

@app.on_event("startup")
async def startup():
    redis = aioredis.from_url("redis://localhost")
    FastAPICache.init(RedisBackend(redis), prefix="api-cache")

@app.get("/api/v1/questions")
@cache(expire=3600)  # 1ì‹œê°„ ìºì‹œ
async def get_questions():
    return await db.fetch_all("SELECT * FROM questions")
```

**ì ˆê° íš¨ê³¼: CPU ì‚¬ìš©ë¥  30% ê°ì†Œ â†’ ì„œë²„ 1ëŒ€ ì ˆê°**

---

## 6.3 Next.js ìµœì í™”

### ISR (Incremental Static Regeneration)

```tsx
// pages/questions/[id].tsx
export async function getStaticProps({ params }) {
  const question = await fetchQuestion(params.id)
  
  return {
    props: { question },
    revalidate: 3600  // 1ì‹œê°„ë§ˆë‹¤ ì¬ìƒì„±
  }
}

export async function getStaticPaths() {
  return {
    paths: [],
    fallback: 'blocking'  // ì²« ìš”ì²­ ì‹œ ìƒì„±
  }
}
```

### Edge Functions (Cloudflare Workers)

```typescript
// Cloudflare Workers
export default {
  async fetch(request: Request) {
    // API ìš”ì²­ì„ Edgeì—ì„œ ì²˜ë¦¬
    const url = new URL(request.url)
    
    if (url.pathname.startsWith('/api/public/')) {
      // Edgeì—ì„œ ì§ì ‘ ì‘ë‹µ
      return new Response(JSON.stringify({ data: "..." }), {
        headers: { 'Content-Type': 'application/json' }
      })
    }
    
    // Originìœ¼ë¡œ ì „ë‹¬
    return fetch(request)
  }
}
```

**ì ˆê° íš¨ê³¼: Origin ìš”ì²­ 50% ê°ì†Œ â†’ Compute ë¹„ìš© 30% ì ˆê°**

---

## 6.4 Nginx/Traefik ì••ì¶•Â·ìºì‹œ ìµœëŒ€í™”

### Nginx ì •ì  íŒŒì¼ ìºì‹œ

```nginx
location ~* \.(jpg|jpeg|png|gif|ico|css|js|woff2)$ {
    expires 30d;
    add_header Cache-Control "public, immutable";
    access_log off;
}
```

### Gzip ì••ì¶•

```nginx
gzip on;
gzip_vary on;
gzip_comp_level 6;
gzip_types text/plain text/css text/xml text/javascript application/json application/javascript;
```

**ì ˆê° íš¨ê³¼: ì •ì  íŒŒì¼ Origin hit < 10%**

---

## 6.5 Compute ë¹„ìš© ìµœì í™” ì²´í¬ë¦¬ìŠ¤íŠ¸

```
â–¡ API ì„œë²„ CPU ì‚¬ìš©ë¥  60~80% ìœ ì§€
â–¡ uvicorn workers = CPU ê°œìˆ˜
â–¡ DB Connection Pooling êµ¬ì„±
â–¡ FastAPI Response Caching (Redis)
â–¡ Next.js ISR í™œì„±í™”
â–¡ Edge Functionsë¡œ ê°„ë‹¨í•œ API ì²˜ë¦¬
â–¡ Nginx ì •ì  íŒŒì¼ ìºì‹œ 30ì¼
â–¡ Gzip/Brotli ì••ì¶• í™œì„±í™”
```

---

# ğŸ” 7. Observability ê¸°ë°˜ ë¹„ìš© ì ˆê°

## 7.1 Prometheus ê¸°ë°˜ ë¹„ìš© ê²½ê³ 

### Cost Alerts

```yaml
groups:
  - name: cost_alerts
    rules:
      - alert: LowGPUUtilization
        expr: nvidia_gpu_utilization < 30
        for: 1h
        labels:
          severity: warning
        annotations:
          summary: "GPU utilization < 30% for 1 hour"
          action: "Consider scaling down GPU"
      
      - alert: HighStorageGrowth
        expr: rate(storage_used_bytes[1d]) > 10GB
        for: 1d
        labels:
          severity: warning
        annotations:
          summary: "Storage growing > 10GB/day"
          action: "Check for temporary files"
      
      - alert: HighEgressCost
        expr: rate(network_egress_bytes[1d]) > 1TB
        for: 1d
        labels:
          severity: critical
        annotations:
          summary: "Network egress > 1TB/day"
          action: "Check CDN cache hit rate"
```

---

## 7.2 Grafana ë¹„ìš© ëŒ€ì‹œë³´ë“œ

### Dashboard êµ¬ì„±

```
1. GPU ë¹„ìš© ì¶”ì´ (ì‹œê°„ë³„, ì¼ë³„, ì›”ë³„)
2. LLM ëª¨ë¸ë³„ ë¹„ìš© (7B/32B/70B)
3. Storage ì‚¬ìš©ëŸ‰ ë° ì¦ê°€ìœ¨
4. Network Egress ë¹„ìš©
5. Compute ë¹„ìš© (API/Frontend)
6. ì´ ë¹„ìš© ëŒ€ì‹œë³´ë“œ
```

### Cost per User Metric

```python
from prometheus_client import Gauge

cost_per_user = Gauge('cost_per_user_dollars', 'Cost per active user')

@app.on_event("startup")
@repeat_every(seconds=3600)  # 1ì‹œê°„ë§ˆë‹¤
async def calculate_cost_per_user():
    total_cost = await get_total_monthly_cost()  # FinOps API
    active_users = await db.scalar("SELECT count(*) FROM users WHERE last_active > NOW() - INTERVAL '30 days'")
    
    cost_per_user.set(total_cost / active_users)
```

---

## 7.3 Loki ë¡œê·¸ ì ˆê°

### ë¡œê·¸ Retention ì •ì±…

```yaml
# Loki config
retention_enabled: true
retention_period: 30d  # 30ì¼ í›„ ì‚­ì œ

# ìš°ì„ ìˆœìœ„ë³„ ë³´ê´€ ê¸°ê°„
limits_config:
  retention_stream:
    - selector: '{level="error"}'
      priority: 1
      period: 90d  # ì—ëŸ¬ ë¡œê·¸ëŠ” 90ì¼
    - selector: '{level="info"}'
      priority: 2
      period: 30d  # ì¼ë°˜ ë¡œê·¸ëŠ” 30ì¼
    - selector: '{level="debug"}'
      priority: 3
      period: 7d   # ë””ë²„ê·¸ ë¡œê·¸ëŠ” 7ì¼
```

**ì ˆê° íš¨ê³¼: ë¡œê·¸ ì €ì¥ ë¹„ìš© 50% ì ˆê°**

---

# ğŸ§® 8. ì‹¤í–‰ ê°€ëŠ¥í•œ ë¹„ìš© ìµœì í™” ì‹œë‚˜ë¦¬ì˜¤ (ì‹¤ì „)

## ì‹œë‚˜ë¦¬ì˜¤ A â€” GPU ë¹„ìš© 60% ì ˆê°

### í˜„ì¬ ìƒíƒœ

```
GPU: A100 Ã— 2ëŒ€ (24/7 ìš´ì˜)
ì›” ë¹„ìš©: $5,760
```

### ìµœì í™” ì „ëµ

1. **RTX 5090 ë¡œì»¬ GPU ë„ì…** (1ëŒ€)
   - ë¹„ìš©: $2,000 (ì´ˆê¸° íˆ¬ì)
   - ì›” ì „ê¸°ë¹„: $50
   
2. **Off-peak GPU 1ëŒ€ë¡œ ì¶•ì†Œ** (23:00~08:00)
   - ì ˆê°: $1,440/ì›”
   
3. **vLLM KV Cache í™œì„±í™”**
   - ì²˜ë¦¬ëŸ‰ 30% ì¦ê°€ â†’ GPU 1ëŒ€ë¡œ ì¶©ë¶„
   
4. **GPTQ 8bit ëª¨ë¸ ì‚¬ìš©**
   - ë©”ëª¨ë¦¬ 50% ê°ì†Œ â†’ ë” í° ëª¨ë¸ ì„œë¹™ ê°€ëŠ¥

### ìµœì í™” í›„

```
GPU: RTX 5090 Ã— 1ëŒ€ + A100 Ã— 1ëŒ€ (Peak only)
ì›” ë¹„ìš©: $50 (ì „ê¸°) + $1,440 (A100 12h/day) = $1,490
ì ˆê°: $4,270/ì›” (74% ì ˆê°)
```

**ROI: 2ê°œì›” ë‚´ íˆ¬ì íšŒìˆ˜**

---

## ì‹œë‚˜ë¦¬ì˜¤ B â€” Storage ë¹„ìš© 70% ì ˆê°

### í˜„ì¬ ìƒíƒœ

```
Storage: AWS S3 (1TB)
Egress: 10TB/ì›”
ì›” ë¹„ìš©: $23 (ì €ì¥) + $900 (Egress) = $923
```

### ìµœì í™” ì „ëµ

1. **Cloudflare R2ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜**
   - Egress ë¬´ë£Œ
   
2. **ë¹„ë””ì˜¤ 720p + H.265 ì••ì¶•**
   - íŒŒì¼ í¬ê¸° 50% ê°ì†Œ
   
3. **ì„ì‹œ íŒŒì¼ ìë™ ì‚­ì œ** (24ì‹œê°„~7ì¼)
   - Storage 20% ê°ì†Œ
   
4. **Cold Storage B2 ì´ë™** (90ì¼+)
   - ì €ì¥ ë¹„ìš© 67% ê°ì†Œ

### ìµœì í™” í›„

```
Storage: R2 (400GB) + B2 (600GB Archive)
Egress: $0 (R2 ë¬´ë£Œ)
ì›” ë¹„ìš©: $6 (R2) + $3 (B2) = $9
ì ˆê°: $914/ì›” (99% Egress ì ˆê°, ì´ 90% ì ˆê°)
```

---

## ì‹œë‚˜ë¦¬ì˜¤ C â€” LLM ë¹„ìš© 50% ì ˆê°

### í˜„ì¬ ìƒíƒœ

```
LLM ì‚¬ìš©:
- 70B ëª¨ë¸: 50% (ë¹„ìš© ë†’ìŒ)
- 32B ëª¨ë¸: 30%
- 7B ëª¨ë¸: 20%
ì›” GPU ë¹„ìš©: $6,000
```

### ìµœì í™” ì „ëµ

1. **ëª¨ë¸ ì—­í•  ì¬ë¶„ë°°**
   - 7B: 60% (ê°„ë‹¨í•œ Q/A, í•„í„°ë§)
   - 32B: 30% (êµìœ¡ ë¶„ì„)
   - 70B: 10% (Premium only)
   
2. **Prompt ê¸¸ì´ 50% ë‹¨ì¶•**
   - í† í° ë¹„ìš© 50% ì ˆê°
   
3. **Response Caching (Redis)**
   - Cache Hit Rate 30%
   
4. **ì–¸ì–´ë³„ íŠ¹í™” ëª¨ë¸ ì‚¬ìš©**
   - í•œêµ­ì–´: beomi/Llama-3-Open-Ko-8B (ì €ë ´)

### ìµœì í™” í›„

```
ì›” GPU ë¹„ìš©: $3,000
ì ˆê°: $3,000/ì›” (50% ì ˆê°)
```

---

## ì‹œë‚˜ë¦¬ì˜¤ D â€” Network ë¹„ìš© 80% ì ˆê°

### í˜„ì¬ ìƒíƒœ

```
Network Egress: 10TB/ì›”
CDN Cache Hit Rate: 60%
ì›” ë¹„ìš©: $900 (S3 Egress)
```

### ìµœì í™” ì „ëµ

1. **Cloudflare CDN Cache Hit Rate 90% ëª©í‘œ**
   - Origin íŠ¸ë˜í”½ 90% ê°ì†Œ
   
2. **R2 ì‚¬ìš©** (Egress ë¬´ë£Œ)
   
3. **Brotli ì••ì¶•**
   - ì „ì†¡ëŸ‰ 30% ê°ì†Œ
   
4. **ì´ë¯¸ì§€ Lazy Loading**
   - ì´ˆê¸° ë¡œë”© 50% ê°ì†Œ

### ìµœì í™” í›„

```
Network Egress: $0 (R2 ë¬´ë£Œ)
ì›” ë¹„ìš©: $0
ì ˆê°: $900/ì›” (100% ì ˆê°)
```

---

## ì „ì²´ ì‹œë‚˜ë¦¬ì˜¤ ìš”ì•½

| ì‹œë‚˜ë¦¬ì˜¤ | í˜„ì¬ ë¹„ìš© | ìµœì í™” í›„ | ì ˆê°ì•¡ | ì ˆê°ë¥  |
|----------|----------|----------|--------|--------|
| **A: GPU** | $5,760 | $1,490 | $4,270 | 74% |
| **B: Storage** | $923 | $9 | $914 | 99% |
| **C: LLM** | $6,000 | $3,000 | $3,000 | 50% |
| **D: Network** | $900 | $0 | $900 | 100% |
| **Total** | **$13,583** | **$4,499** | **$9,084** | **67%** |

**ì—°ê°„ ì ˆê°ì•¡: $109,008**

---

# ğŸ 9. ê²°ë¡ 

ì´ **Cost Optimization Guide**ëŠ” DreamSeedAI MegaCityì˜ ìš´ì˜ ë¹„ìš©ì„ **60~70% ì ˆê°**í•  ìˆ˜ ìˆëŠ” êµ¬ì¡°ì  FinOps ì „ëµì„ ì œê³µí•©ë‹ˆë‹¤.

## í•µì‹¬ ìµœì í™” ì›ì¹™

1. **GPU: ë¡œì»¬ ìš°ì„ , Cloud Fallback** (RTX 5090 â†’ 74% ì ˆê°)
2. **LLM: ì‘ì€ ëª¨ë¸ ìš°ì„ , í° ëª¨ë¸ ì„ íƒì ** (50% ì ˆê°)
3. **Storage: R2 + B2 + ì••ì¶• + ìë™ ì‚­ì œ** (90% ì ˆê°)
4. **Network: CDN 90% Cache + R2 Egress ë¬´ë£Œ** (100% ì ˆê°)
5. **Compute: ì ì • Scaling + Caching** (40% ì ˆê°)

## ì‹¤í–‰ ìš°ì„ ìˆœìœ„

```
Phase 1 (ì¦‰ì‹œ ì ìš©):
  âœ“ R2 ë§ˆì´ê·¸ë ˆì´ì…˜ (Egress ë¬´ë£Œ)
  âœ“ ì„ì‹œ íŒŒì¼ ìë™ ì‚­ì œ
  âœ“ Cloudflare CDN Cache 90%
  
Phase 2 (1ê°œì›” ë‚´):
  âœ“ RTX 5090 ë¡œì»¬ GPU ë„ì…
  âœ“ GPTQ 8bit ëª¨ë¸ ì ìš©
  âœ“ ëª¨ë¸ ì—­í•  ì¬ë¶„ë°° (7B 60%)
  
Phase 3 (3ê°œì›” ë‚´):
  âœ“ Off-peak GPU Auto-scaling
  âœ“ Response Caching (Redis)
  âœ“ ë¹„ë””ì˜¤/ì´ë¯¸ì§€ ìë™ ì••ì¶•
```

## FinOps Dashboard

Grafanaì—ì„œ ë‹¤ìŒì„ ëª¨ë‹ˆí„°ë§:

```
â–¡ ì›”ê°„ ì´ ë¹„ìš© (Target: $5,000 ì´í•˜)
â–¡ Cost per User (Target: $0.50 ì´í•˜)
â–¡ GPU Utilization (Target: 70~90%)
â–¡ Storage Growth Rate (Target: < 5GB/day)
â–¡ CDN Cache Hit Rate (Target: > 90%)
â–¡ LLM ëª¨ë¸ ë¶„í¬ (7B: 60%, 32B: 30%, 70B: 10%)
```

---

**ë¬¸ì„œ ì™„ë£Œ - DreamSeedAI MegaCity Cost Optimization Guide v1.0**
