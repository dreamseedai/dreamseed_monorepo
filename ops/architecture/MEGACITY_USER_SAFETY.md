# ğŸ›¡ï¸ DreamSeedAI MegaCity â€“ User Safety Guide

## í•™ìƒ Â· í•™ë¶€ëª¨ Â· êµì‚¬ ë³´í˜¸ ì •ì±… Â· AI ì•ˆì „ Â· ì½˜í…ì¸  ì•ˆì „ Â· ê°œì¸ì •ë³´ ë³´í˜¸ ê¸°ì¤€

**ë²„ì „:** 1.0  
**ì‘ì„±ì¼:** 2025-11-22  
**ì‘ì„±ì:** DreamSeedAI User Safety & Trust Team

---

# ğŸ“Œ 0. ê°œìš” (Overview)

DreamSeedAI MegaCityëŠ” í•™ìƒ, í•™ë¶€ëª¨, êµì‚¬, ì¼ë°˜ ì‚¬ìš©ì ëª¨ë‘ê°€ ì•ˆì „í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” **ì‹ ë¢° ê¸°ë°˜ êµìœ¡Â·AI í”Œë«í¼**ì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.

ì´ ë¬¸ì„œëŠ” MegaCityì˜ ëª¨ë“  Zone(UnivPrepAI, SkillPrepAI, My-Ktube ë“±)ì— ê³µí†µ ì ìš©ë˜ëŠ” **ì‚¬ìš©ì ì•ˆì „(User Safety) ê¸°ì¤€**ì„ ê·œì •í•©ë‹ˆë‹¤.

## ë¬¸ì„œ ëª©ì 

- í•™ìƒ, í•™ë¶€ëª¨, êµì‚¬ë¥¼ í¬í•¨í•œ ëª¨ë“  ì‚¬ìš©ì ë³´í˜¸
- ìœ í•´ ì½˜í…ì¸  ì°¨ë‹¨ ë° AI ì•ˆì „ì„± í™•ë³´
- ê°œì¸ì •ë³´ ë³´í˜¸ ë° í”„ë¼ì´ë²„ì‹œ ê¶Œë¦¬ ë³´ì¥
- ì•ˆì „ ì‚¬ê³  ëŒ€ì‘ ë° ì‹ ê³  ì‹œìŠ¤í…œ êµ¬ì¶•
- ì‚¬ìš©ì ìƒí˜¸ì‘ìš© ì•ˆì „ ê·œì • ì •ë¦½

## ì•ˆì „ ì²´ê³„ êµ¬ì¡°

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              DreamSeedAI MegaCity User Safety           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚         â”‚          â”‚          â”‚          â”‚          â”‚
    â–¼         â–¼          â–¼          â–¼          â–¼          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚Content â”‚â”‚   AI   â”‚â”‚Student â”‚â”‚Privacy â”‚â”‚  User  â”‚      â”‚
â”‚ Safety â”‚â”‚ Safety â”‚â”‚ Safety â”‚â”‚Protectnâ”‚â”‚Interactâ”‚      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
    â”‚         â”‚          â”‚          â”‚          â”‚          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Safety Monitoring   â”‚
              â”‚  & Incident Response â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

ì•ˆì „ í•­ëª©ì€ ë‹¤ìŒ **5ê°œ ì¶•**ìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤:

```
1. ì½˜í…ì¸  ì•ˆì „ (Content Safety)
   - ìœ í•´ ì½˜í…ì¸  ì°¨ë‹¨
   - ê²½ê³ /ì œí•œ ì½˜í…ì¸  ê´€ë¦¬
   - Zoneë³„ íŠ¹ìˆ˜ ê·œì •

2. AI ì•ˆì „ (AI Safety)
   - Prompt Injection ë°©ì§€
   - ìœ í•´ ì¶œë ¥ ê°ì§€ ë° í•„í„°ë§
   - êµìœ¡ì  í”„ë ˆì´ë°
   - AI ì—­í•  ì œí•œ

3. í•™ìŠµì ì•ˆì „ (Student Safety)
   - í•™ìƒ ê³„ì • ë³´í˜¸
   - ì‹œí—˜Â·ì„±ì  ë³´í˜¸
   - ì‹¤ì‹œê°„ ìƒí˜¸ì‘ìš© ì•ˆì „

4. ê°œì¸ì •ë³´/í”„ë¼ì´ë²„ì‹œ ë³´í˜¸ (Privacy Protection)
   - ìµœì†Œ ì •ë³´ ìˆ˜ì§‘
   - ì•”í˜¸í™” ë° ë³´ì•ˆ
   - GDPR/PIPA ê¶Œë¦¬ ë³´ì¥
   - ì˜ìƒ/ìŒì„± ë°ì´í„° ë³´í˜¸

5. ì‚¬ìš©ì ìƒí˜¸ì‘ìš© ì•ˆì „ (User Interaction Safety)
   - Parent-Student ìŠ¹ì¸
   - Teacher-Student ìƒí˜¸ì‘ìš©
   - ì»¤ë®¤ë‹ˆí‹° ì•ˆì „
```

---

# ğŸ§© 1. ì½˜í…ì¸  ì•ˆì „ (Content Safety)

## 1.1 ê¸ˆì§€ ì½˜í…ì¸  (Prohibited Content)

ë‹¤ìŒ ì½˜í…ì¸ ëŠ” ì „ Zoneì—ì„œ **ì¦‰ì‹œ ì°¨ë‹¨**ë©ë‹ˆë‹¤:

### ê¸ˆì§€ ì½˜í…ì¸  ì¹´í…Œê³ ë¦¬

| ì¹´í…Œê³ ë¦¬ | ì„¤ëª… | ì¡°ì¹˜ | ì²˜ë²Œ |
|---------|------|------|------|
| **ìŒë€ë¬¼/ì„±ì  ì½˜í…ì¸ ** | íŠ¹íˆ ë¯¸ì„±ë…„ì ê´€ë ¨ ëª¨ë“  ì„±ì  ì½˜í…ì¸  | ì¦‰ì‹œ ì°¨ë‹¨ + ê³„ì • ì˜êµ¬ ì •ì§€ | ë²•ì  ì‹ ê³  |
| **ì•„ë™ í•™ëŒ€/ì°©ì·¨** | ì•„ë™ ì„± ì°©ì·¨ë¬¼(CSAM), ì•„ë™ í•™ëŒ€ ì½˜í…ì¸  | ì¦‰ì‹œ ì°¨ë‹¨ + ë²• ì§‘í–‰ ê¸°ê´€ ì‹ ê³  | ê³„ì • ì˜êµ¬ ì •ì§€ |
| **í˜ì˜¤/ì°¨ë³„ í‘œí˜„** | ì¸ì¢…, ì„±ë³„, ì¢…êµ, ì¥ì•  ê¸°ë°˜ í˜ì˜¤ | ì¦‰ì‹œ ì‚­ì œ + ê²½ê³  | 3íšŒ ëˆ„ì  ì‹œ ê³„ì • ì •ì§€ |
| **ìí•´/í­ë ¥/í…ŒëŸ¬** | ìì‚´ ì¡°ì¥, í­ë ¥ ë¬˜ì‚¬, í…ŒëŸ¬ ì„ ë™ | ì¦‰ì‹œ ì°¨ë‹¨ + ëª¨ë‹ˆí„°ë§ | ê³„ì • ì •ì§€ + ë²•ì  ì‹ ê³  |
| **ë„ë°•/ì‚¬ê¸°/ë¶ˆë²•** | ë„ë°• ì‚¬ì´íŠ¸, ì‚¬ê¸°, ë§ˆì•½, ë¶ˆë²• í™œë™ | ì¦‰ì‹œ ì°¨ë‹¨ | ê³„ì • ì˜êµ¬ ì •ì§€ |
| **ë¬´ë‹¨ ì–¼êµ´/ìŒì„± í•©ì„±** | K-Zoneì—ì„œ ë™ì˜ ì—†ëŠ” Deepfake | ì¦‰ì‹œ ì‚­ì œ + ê²½ê³  | 2íšŒ ëˆ„ì  ì‹œ ê³„ì • ì •ì§€ |

### ì½˜í…ì¸  í•„í„°ë§ ì‹œìŠ¤í…œ

```python
from transformers import pipeline

# NSFW ì´ë¯¸ì§€ íƒì§€
nsfw_detector = pipeline("image-classification", model="Falconsai/nsfw_image_detection")

async def check_image_safety(image_path: str) -> dict:
    result = nsfw_detector(image_path)[0]
    
    if result["label"] == "nsfw" and result["score"] > 0.7:
        return {
            "is_safe": False,
            "reason": "NSFW content detected",
            "score": result["score"]
        }
    
    return {"is_safe": True}

# í…ìŠ¤íŠ¸ ìœ í•´ì„± íƒì§€
toxicity_detector = pipeline("text-classification", model="unitary/toxic-bert")

async def check_text_safety(text: str) -> dict:
    result = toxicity_detector(text)[0]
    
    if result["label"] == "toxic" and result["score"] > 0.7:
        return {
            "is_safe": False,
            "reason": "Toxic content detected",
            "type": result["label"],
            "score": result["score"]
        }
    
    return {"is_safe": True}

@app.post("/api/v1/content/upload")
async def upload_content(
    file: UploadFile,
    text: str,
    user: User = Depends(get_current_user)
):
    # ì´ë¯¸ì§€ ì•ˆì „ ê²€ì‚¬
    if file.content_type.startswith("image/"):
        safety_check = await check_image_safety(file)
        if not safety_check["is_safe"]:
            await log_safety_incident("nsfw_image_blocked", user.id, safety_check)
            raise HTTPException(400, "Unsafe content detected")
    
    # í…ìŠ¤íŠ¸ ì•ˆì „ ê²€ì‚¬
    text_safety = await check_text_safety(text)
    if not text_safety["is_safe"]:
        await log_safety_incident("toxic_text_blocked", user.id, text_safety)
        raise HTTPException(400, "Unsafe content detected")
    
    # ì—…ë¡œë“œ ì§„í–‰
    return await upload_to_storage(file, text)
```

## 1.2 ê²½ê³ /ì œí•œ ì½˜í…ì¸  (Warning Content)

ë‹¤ìŒ ì½˜í…ì¸ ëŠ” **ê²½ê³  í‘œì‹œ** ë˜ëŠ” **ì—°ë ¹ ì œí•œ** ì ìš©:

### ê²½ê³  ì½˜í…ì¸  ì¹´í…Œê³ ë¦¬

| ì¹´í…Œê³ ë¦¬ | ì¡°ì¹˜ | í‘œì‹œ |
|---------|------|------|
| **ì •ì¹˜ì  ë…¼ìŸ** | ì¤‘ë¦½ì  í”„ë ˆì´ë° ë˜ëŠ” ì•½í™” | "âš ï¸ ì •ì¹˜ì  ì½˜í…ì¸ " |
| **ì¢…êµì  ê°ˆë“±** | ë‹¤ì–‘ì„± ì¡´ì¤‘ í”„ë ˆì´ë° | "âš ï¸ ì¢…êµì  ì½˜í…ì¸ " |
| **í’ì/íŒ¨ëŸ¬ë””** | êµìœ¡ì  ë§¥ë½ ê°•ì¡° | "âš ï¸ í’ì ì½˜í…ì¸ " |
| **í­ë ¥ì  ê²Œì„** | ì—°ë ¹ ì œí•œ (18ì„¸+) | "ğŸ” 18ì„¸ ì´ìƒ" |

### AI Safety Layer ì¬ê²€í† 

```python
async def review_warning_content(content: str) -> dict:
    # AI ê¸°ë°˜ ì½˜í…ì¸  ì¬ì‘ì„±
    safe_version = await llm_rewrite(
        content,
        system_prompt="""
        ë‹¤ìŒ ì½˜í…ì¸ ë¥¼ êµìœ¡ì ì´ê³  ê±´ì„¤ì ì¸ ë°©ì‹ìœ¼ë¡œ ì¬ì‘ì„±í•˜ì„¸ìš”.
        - ì¤‘ë¦½ì  ê´€ì  ìœ ì§€
        - ë‹¤ì–‘ì„± ì¡´ì¤‘
        - í•™ìŠµì ì •ì„œ ë³´í˜¸
        """
    )
    
    return {
        "original": content,
        "safe_version": safe_version,
        "warning": "ì´ ì½˜í…ì¸ ëŠ” ì•ˆì „ì„ ìœ„í•´ ì¬ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤."
    }
```

## 1.3 K-Zone ì „ìš© ê·œì • (K-Zone Specific Rules)

K-Zone (My-Ktube, K-Zone Creator Studio)ëŠ” **ì—„ê²©í•œ ì½˜í…ì¸  ê·œì •**ì„ ì ìš©í•©ë‹ˆë‹¤.

### K-Zone ì½˜í…ì¸  ê·œì¹™

```
1. íƒ€ì¸ì˜ ì–¼êµ´Â·ìŒì„± ê¸°ë°˜ í•©ì„±ì€ ë³¸ì¸ ë™ì˜ í•„ìˆ˜ (Opt-in)
2. ë™ì˜ ì—†ëŠ” Deepfake â†’ ì¦‰ì‹œ ì‚­ì œ + ê³„ì • ê²½ê³ 
3. ì˜ìƒ/ìŒì„± ì—…ë¡œë“œ ì‹œ ë¯¼ê°í•œ ì–¼êµ´ ìë™ ëª¨ìì´í¬ ì˜µì…˜ í™œì„±
4. Creator Studio ê²°ê³¼ë¬¼ì€ 30ì¼ ìë™ ì‚­ì œ
5. K-POP ì•„í‹°ìŠ¤íŠ¸ ìŒì„± í´ë¡œë‹ì€ ê³µì‹ ë¼ì´ì„ ìŠ¤ë§Œ í—ˆìš©
```

### K-Zone ë™ì˜ ì‹œìŠ¤í…œ

```python
@app.post("/api/v1/kzone/voice-consent")
async def request_voice_consent(
    request: VoiceConsentRequest,
    user: User = Depends(get_current_user)
):
    # ë™ì˜ ìš”ì²­ ìƒì„±
    consent = await db.execute(
        """
        INSERT INTO voice_consents (requester_id, owner_id, voice_sample_url, status)
        VALUES (:requester_id, :owner_id, :voice_url, 'pending')
        RETURNING *
        """,
        {
            "requester_id": user.id,
            "owner_id": request.owner_id,
            "voice_url": request.voice_sample_url
        }
    )
    
    # ì†Œìœ ìì—ê²Œ ì•Œë¦¼
    await send_notification(
        request.owner_id,
        f"{user.name}ë‹˜ì´ ê·€í•˜ì˜ ìŒì„± ì‚¬ìš©ì„ ìš”ì²­í–ˆìŠµë‹ˆë‹¤.",
        consent_id=consent.id
    )
    
    return {"status": "pending", "consent_id": consent.id}

@app.post("/api/v1/kzone/voice-consent/{consent_id}/approve")
async def approve_voice_consent(
    consent_id: int,
    user: User = Depends(get_current_user)
):
    consent = await db.fetchone(
        "SELECT * FROM voice_consents WHERE id = :id AND owner_id = :user_id",
        {"id": consent_id, "user_id": user.id}
    )
    
    if not consent:
        raise HTTPException(404, "Consent not found")
    
    await db.execute(
        "UPDATE voice_consents SET status = 'approved', approved_at = NOW() WHERE id = :id",
        {"id": consent_id}
    )
    
    # Audit Log ê¸°ë¡
    await log_audit(user.id, "voice_consent_granted", consent_id)
    
    return {"status": "approved"}
```

### K-Zone ìë™ ëª¨ìì´í¬

```python
import cv2
import mediapipe as mp

async def auto_blur_sensitive_areas(video_path: str) -> str:
    """ë¯¼ê° ë¶€ìœ„ ìë™ ëª¨ìì´í¬"""
    mp_pose = mp.solutions.pose
    pose = mp_pose.Pose()
    
    cap = cv2.VideoCapture(video_path)
    output_path = f"{video_path}_blurred.mp4"
    out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), 30, (width, height))
    
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        
        # Pose ê°ì§€
        results = pose.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
        
        if results.pose_landmarks:
            # ë¯¼ê° ë¶€ìœ„ ì¢Œí‘œ ì¶”ì¶œ (ì˜ˆ: ê°€ìŠ´, ê³¨ë°˜)
            sensitive_areas = [
                results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER],
                results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER],
                # ... (ë¯¼ê° ë¶€ìœ„ keypoints)
            ]
            
            # ëª¨ìì´í¬ ì ìš©
            for area in sensitive_areas:
                x, y = int(area.x * width), int(area.y * height)
                frame[y-50:y+50, x-50:x+50] = cv2.blur(frame[y-50:y+50, x-50:x+50], (50, 50))
        
        out.write(frame)
    
    cap.release()
    out.release()
    
    return output_path
```

---

# ğŸ¤– 2. AI ì•ˆì „ (AI Safety)

## 2.1 Prompt Injection ë°©ì§€ (Prompt Injection Defense)

AI ì…ë ¥ì—ì„œ ë‹¤ìŒ íŒ¨í„´ì€ **ìë™ ì°¨ë‹¨**ë©ë‹ˆë‹¤:

### Prompt Injection íƒì§€ íŒ¨í„´

```python
PROMPT_INJECTION_PATTERNS = [
    r"ignore previous",
    r"disregard.*instruction",
    r"jailbreak",
    r"system override",
    r"roleplay as malicious",
    r"pretend you are",
    r"act as.*admin",
    r"bypass.*filter",
    r"reveal.*prompt",
    r"show.*system.*message",
]

import re

def detect_prompt_injection(prompt: str) -> dict:
    """Prompt Injection ì‹œë„ íƒì§€"""
    prompt_lower = prompt.lower()
    
    for pattern in PROMPT_INJECTION_PATTERNS:
        if re.search(pattern, prompt_lower):
            return {
                "is_safe": False,
                "reason": "Prompt injection detected",
                "pattern": pattern
            }
    
    return {"is_safe": True}

@app.post("/api/v1/ai-tutor")
async def ai_tutor(
    request: AITutorRequest,
    user: User = Depends(get_current_user)
):
    # Prompt Injection ê²€ì‚¬
    safety_check = detect_prompt_injection(request.prompt)
    if not safety_check["is_safe"]:
        await log_safety_incident("prompt_injection_attempt", user.id, safety_check)
        raise HTTPException(400, "Invalid prompt detected")
    
    # AI ì‘ë‹µ ìƒì„±
    response = await call_llm(request.prompt)
    return {"response": response}
```

## 2.2 ìœ í•´ ì¶œë ¥ ê°ì§€ (Harmful Output Filter)

AI ì‘ë‹µì—ì„œ ë‹¤ìŒ í‘œí˜„ ë°œê²¬ ì‹œ **ìë™ í•„í„°ë§**:

### ìœ í•´ ì¶œë ¥ ì¹´í…Œê³ ë¦¬

| ì¹´í…Œê³ ë¦¬ | ì˜ˆì‹œ | ì¡°ì¹˜ |
|---------|------|------|
| **ìš•ì„¤/í­ì–¸** | ì €ì†í•œ ì–¸ì–´, ëª¨ìš• | ì‘ë‹µ ì¬ìƒì„± |
| **í­ë ¥/ìí•´** | ìì‚´ ì¡°ì¥, í­ë ¥ ë¬˜ì‚¬ | ì‘ë‹µ ì°¨ë‹¨ + ê²½ê³  |
| **ì„±ì  ì½˜í…ì¸ ** | ì„±ì  ì•”ì‹œ, ë¬˜ì‚¬ | ì‘ë‹µ ì°¨ë‹¨ |
| **ì°¨ë³„/í˜ì˜¤** | ì¸ì¢…, ì„±ë³„ ê¸°ë°˜ ì¡°ë¡± | ì‘ë‹µ ì¬ìƒì„± |

### ìœ í•´ ì¶œë ¥ í•„í„°ë§ êµ¬í˜„

```python
from transformers import pipeline

hate_detector = pipeline("text-classification", model="facebook/roberta-hate-speech-dynabench-r4-target")

async def filter_harmful_output(text: str) -> dict:
    """AI ì¶œë ¥ë¬¼ ìœ í•´ì„± ê²€ì‚¬"""
    
    # Hate Speech íƒì§€
    hate_result = hate_detector(text)[0]
    if hate_result["label"] == "hate" and hate_result["score"] > 0.7:
        return {
            "is_safe": False,
            "reason": "Hate speech detected",
            "score": hate_result["score"]
        }
    
    # ìš•ì„¤ í‚¤ì›Œë“œ ê²€ì‚¬
    PROFANITY_KEYWORDS = ["ìš•ì„¤1", "ìš•ì„¤2", "ìš•ì„¤3"]  # ì‹¤ì œ ìš•ì„¤ì€ ë³„ë„ íŒŒì¼
    if any(word in text for word in PROFANITY_KEYWORDS):
        return {"is_safe": False, "reason": "Profanity detected"}
    
    return {"is_safe": True}

@app.post("/api/v1/ai-tutor")
async def ai_tutor(request: AITutorRequest):
    response = await call_llm(request.prompt)
    
    # ìœ í•´ ì¶œë ¥ ê²€ì‚¬
    safety_check = await filter_harmful_output(response)
    
    if not safety_check["is_safe"]:
        await log_safety_incident("harmful_output_blocked", user.id, safety_check)
        
        # ì‘ë‹µ ì¬ìƒì„± (ìµœëŒ€ 3íšŒ)
        for retry in range(3):
            response = await call_llm(
                request.prompt,
                system_prompt="ê±´ì„¤ì ì´ê³  êµìœ¡ì ì¸ ë°©ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”."
            )
            if (await filter_harmful_output(response))["is_safe"]:
                break
        else:
            response = "ì£„ì†¡í•©ë‹ˆë‹¤. ì ì ˆí•œ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    return {"response": response}
```

## 2.3 êµìœ¡ì  í”„ë ˆì´ë° ì ìš© (Educational Framing)

AI Tutorì™€ K-Zone AIëŠ” ì‘ë‹µì„ ë‹¤ìŒ **êµìœ¡ì  ê·œì¹™**ìœ¼ë¡œ í¬ë§·íŒ…:

### êµìœ¡ì  í”„ë ˆì´ë° ê·œì¹™

```
1. ê±´ì„¤ì /ë°°ë ¤ì  ì–¸ì–´ ì‚¬ìš©
   - "í‹€ë ¸ì–´" â†’ "ë‹¤ì‹œ í•œë²ˆ ìƒê°í•´ë³¼ê¹Œìš”?"
   - "ëª¨ë¥´ê² ì–´" â†’ "ì´ ë¶€ë¶„ì„ í•¨ê»˜ ì‚´í´ë´…ì‹œë‹¤"

2. êµìœ¡ì  ëª©ì  ê°•ì¡°
   - ì •ë‹µë§Œ ì œê³µí•˜ì§€ ì•Šê³  ì‚¬ê³  ê³¼ì • ì„¤ëª…
   - ë‹¨ê³„ë³„ í•™ìŠµ ìœ ë„

3. í•™ìŠµì ì •ì„œ ë³´í˜¸
   - ì‹¤ìˆ˜ë¥¼ ìì—°ìŠ¤ëŸ¬ìš´ í•™ìŠµ ê³¼ì •ìœ¼ë¡œ í”„ë ˆì´ë°
   - ê¸ì •ì  í”¼ë“œë°± ìš°ì„ 
```

### System Prompt í…œí”Œë¦¿

```python
EDUCATIONAL_SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ DreamSeedAIì˜ êµìœ¡ AI Tutorì…ë‹ˆë‹¤.

**ì‘ë‹µ ê·œì¹™:**
1. í•™ìƒì„ ì¡´ì¤‘í•˜ê³  ë°°ë ¤í•˜ëŠ” ì–¸ì–´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
2. ì •ë‹µë§Œ ì œê³µí•˜ì§€ ë§ê³ , ì‚¬ê³  ê³¼ì •ì„ ë‹¨ê³„ë³„ë¡œ ì„¤ëª…í•˜ì„¸ìš”.
3. í•™ìƒì˜ ì‹¤ìˆ˜ëŠ” í•™ìŠµì˜ ê¸°íšŒë¡œ í”„ë ˆì´ë°í•˜ì„¸ìš”.
4. ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ì•„ì•¼ í•  í‘œí˜„:
   - ìš•ì„¤, í­ë ¥ì  ì–¸ì–´
   - ì°¨ë³„ì  í‘œí˜„
   - ì„±ì  ì•”ì‹œ
   - "í‹€ë ¸ì–´", "ë°”ë³´ê°™ì´" ë“± ë¶€ì •ì  í‘œí˜„

**ì˜ˆì‹œ:**
í•™ìƒ: "ì´ ë¬¸ì œ ë‹µì´ ë­ì˜ˆìš”?"
ì‘ë‹µ: "ì¢‹ì€ ì§ˆë¬¸ì´ì—ìš”! í•¨ê»˜ ë‹¨ê³„ë³„ë¡œ í’€ì–´ë³¼ê¹Œìš”? ë¨¼ì €..."
"""

async def call_educational_llm(prompt: str, user_context: dict) -> str:
    response = await call_llm(
        prompt,
        system_prompt=EDUCATIONAL_SYSTEM_PROMPT,
        temperature=0.7,
        max_tokens=500
    )
    return response
```

## 2.4 AI ë¯¼ê° ì—­í•  ì œí•œ (AI Role Restrictions)

AIëŠ” íŠ¹ì • **ë¯¼ê°í•œ ì‹œë‚˜ë¦¬ì˜¤**ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤:

### ê¸ˆì§€ëœ AI ì—­í• 

```
âŒ ì‹¬ë¦¬ ìƒë‹´ì‚¬ ì—­í•  (ì „ë¬¸ ìƒë‹´ í•„ìš”)
âŒ ì˜ì‚¬/ì˜ë£Œì§„ ì§„ë‹¨ ì—­í•  (ì˜ë£Œ ë©´í—ˆ í•„ìš”)
âŒ ë²•ë¥  ì „ë¬¸ê°€ ì—­í•  (ë²•ì  ìë¬¸ ë¶ˆê°€)
âŒ ê¸ˆìœµ ìë¬¸ ì—­í•  (íˆ¬ì ì¡°ì–¸ ê¸ˆì§€)
âŒ ìœ„í—˜í•œ í–‰ë™ ì¡°ì–¸ (ìí•´, ë²”ì£„ ë“±)
```

### ì—­í•  ì œí•œ êµ¬í˜„

```python
RESTRICTED_ROLES = [
    "psychologist", "therapist", "counselor",
    "doctor", "physician", "medical",
    "lawyer", "attorney", "legal advisor",
    "financial advisor", "investment advisor"
]

def detect_restricted_role(prompt: str) -> dict:
    """ë¯¼ê° ì—­í•  ìš”ì²­ íƒì§€"""
    prompt_lower = prompt.lower()
    
    for role in RESTRICTED_ROLES:
        if role in prompt_lower and any(
            keyword in prompt_lower 
            for keyword in ["act as", "roleplay", "pretend", "you are"]
        ):
            return {
                "is_restricted": True,
                "role": role,
                "message": f"AIëŠ” {role} ì—­í• ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            }
    
    return {"is_restricted": False}

@app.post("/api/v1/ai-tutor")
async def ai_tutor(request: AITutorRequest):
    # ì—­í•  ì œí•œ ê²€ì‚¬
    role_check = detect_restricted_role(request.prompt)
    if role_check["is_restricted"]:
        return {
            "response": f"ì£„ì†¡í•©ë‹ˆë‹¤. {role_check['message']} ì „ë¬¸ê°€ì™€ ìƒë‹´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."
        }
    
    response = await call_llm(request.prompt)
    return {"response": response}
```

---

# ğŸ§’ 3. í•™ìŠµì ì•ˆì „ (Student Safety)

## 3.1 í•™ìƒ ê³„ì • ë³´í˜¸ (Student Account Protection)

### Parent-Student ì—°ê²° ìŠ¹ì¸

```python
@app.post("/api/v1/parent/link-student")
async def link_student(
    request: LinkStudentRequest,
    parent: User = Depends(get_current_user)
):
    if parent.role != "parent":
        raise HTTPException(403, "Only parents can link students")
    
    # í•™ìƒì—ê²Œ ìŠ¹ì¸ ìš”ì²­
    link_request = await db.execute(
        """
        INSERT INTO parent_student_links (parent_id, student_id, status)
        VALUES (:parent_id, :student_id, 'pending')
        RETURNING *
        """,
        {"parent_id": parent.id, "student_id": request.student_id}
    )
    
    # í•™ìƒì—ê²Œ ì•Œë¦¼
    await send_notification(
        request.student_id,
        f"{parent.name}ë‹˜ì´ í•™ë¶€ëª¨ ì—°ê²°ì„ ìš”ì²­í–ˆìŠµë‹ˆë‹¤.",
        link_request_id=link_request.id
    )
    
    return {"status": "pending", "expires_in": "7 days"}

@app.post("/api/v1/student/approve-parent/{link_id}")
async def approve_parent_link(
    link_id: int,
    student: User = Depends(get_current_user)
):
    link = await db.fetchone(
        "SELECT * FROM parent_student_links WHERE id = :id AND student_id = :student_id",
        {"id": link_id, "student_id": student.id}
    )
    
    if not link:
        raise HTTPException(404, "Link request not found")
    
    await db.execute(
        "UPDATE parent_student_links SET status = 'approved', approved_at = NOW() WHERE id = :id",
        {"id": link_id}
    )
    
    # Audit Log ê¸°ë¡
    await log_audit(student.id, "parent_link_approved", link_id)
    
    return {"status": "approved"}
```

### í•™ìƒ ê³„ì • ë¯¼ê° ê¸°ëŠ¥ ì œí•œ

```python
@app.post("/api/v1/ai-tutor")
async def ai_tutor(
    request: AITutorRequest,
    user: User = Depends(get_current_user)
):
    # í•™ìƒì€ NSFW ì½˜í…ì¸  ìë™ í•„í„°ë§ (ë” ì—„ê²©)
    if user.role == "student":
        # í•™ìƒìš© ì—„ê²© í•„í„°
        safety_check = await check_student_safe_content(request.prompt)
        if not safety_check["is_safe"]:
            raise HTTPException(400, "Content not suitable for students")
    
    response = await call_llm(request.prompt)
    return {"response": response}
```

## 3.2 ì‹œí—˜Â·ì„±ì  ë³´í˜¸ (Exam & Grade Protection)

### ì„±ì  ì ‘ê·¼ ê¶Œí•œ

```sql
-- RLS ì •ì±…: í•™ìƒ ì„±ì ì€ ë³¸ì¸ + ì—°ê²°ëœ í•™ë¶€ëª¨ + ë‹´ë‹¹ êµì‚¬ë§Œ ì¡°íšŒ
CREATE POLICY student_grades_policy ON exam_attempts
FOR SELECT USING (
    auth.uid() = user_id  -- ë³¸ì¸
    OR auth.uid() IN (
        SELECT parent_id FROM parent_student_links 
        WHERE student_id = exam_attempts.user_id AND status = 'approved'
    )  -- ìŠ¹ì¸ëœ í•™ë¶€ëª¨
    OR auth.uid() IN (
        SELECT teacher_id FROM teacher_student_assignments 
        WHERE student_id = exam_attempts.user_id
    )  -- ë‹´ë‹¹ êµì‚¬
);
```

### ì„±ì  ë°ì´í„° ë³´ì¡´ ì •ì±…

```python
@app.on_event("startup")
@repeat_every(seconds=86400)  # 1ì¼ë§ˆë‹¤
async def cleanup_old_grades():
    """3ë…„ ì´ìƒ ëœ ì„±ì  ë°ì´í„° ìµëª…í™”"""
    await db.execute(
        """
        UPDATE exam_attempts SET
            user_id = NULL,
            anonymized = TRUE,
            anonymized_at = NOW()
        WHERE created_at < NOW() - INTERVAL '3 years'
          AND anonymized = FALSE
        """
    )
```

## 3.3 ì‹¤ì‹œê°„ ìƒí˜¸ì‘ìš© ì•ˆì „ (Real-time Interaction Safety)

### ìŒì„±/ì˜ìƒ ìë™ ì•ˆì „ ë§ˆìŠ¤í¬

```python
@app.post("/api/v1/kzone/dance-lab/upload")
async def upload_dance_video(
    file: UploadFile,
    user: User = Depends(get_current_user)
):
    # í•™ìƒ ê³„ì •ì€ ìë™ ëª¨ìì´í¬ ì ìš©
    if user.role == "student":
        # ë¯¼ê° ë¶€ìœ„ ìë™ ë¸”ëŸ¬
        safe_video = await auto_blur_sensitive_areas(file)
        upload_url = await upload_to_storage(safe_video)
    else:
        upload_url = await upload_to_storage(file)
    
    return {"video_url": upload_url}
```

---

# ğŸ” 4. ê°œì¸ì •ë³´ ë° í”„ë¼ì´ë²„ì‹œ ë³´í˜¸ (Privacy Protection)

## 4.1 ìµœì†Œ ì •ë³´ ìˆ˜ì§‘ ì›ì¹™ (Data Minimization)

### ìˆ˜ì§‘ ì •ë³´

```
âœ… í•„ìˆ˜ ìˆ˜ì§‘:
   - ì´ë©”ì¼ (ë˜ëŠ” OAuth)
   - ë¹„ë°€ë²ˆí˜¸ (ë˜ëŠ” OAuth)
   - í•™ìŠµ ê´€ë ¨ ë°ì´í„° (ì‹œí—˜ ì‹œë„, AI ì‚¬ìš© ê¸°ë¡)

âŒ ìˆ˜ì§‘ ê¸ˆì§€:
   - ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸
   - ì •í™•í•œ ì£¼ì†Œ (ì‹œ/êµ¬ê¹Œì§€ë§Œ)
   - GPS ìœ„ì¹˜
   - ì‹ ìš©ì¹´ë“œ ë²ˆí˜¸ (ê²°ì œ ëŒ€í–‰ì‚¬ ì²˜ë¦¬)
   - ë¯¼ê° ê±´ê°• ì •ë³´
```

### ìµœì†Œ ìˆ˜ì§‘ ê²€ì¦

```python
@app.post("/api/v1/auth/register")
async def register(request: RegisterRequest):
    # í•„ìˆ˜ í•­ëª©ë§Œ ìˆ˜ì§‘
    required_fields = {"email", "password", "name", "role"}
    provided_fields = set(request.dict(exclude_unset=True).keys())
    
    # ë¶ˆí•„ìš”í•œ ì •ë³´ ìˆ˜ì§‘ ë°©ì§€
    unnecessary_fields = provided_fields - required_fields
    if unnecessary_fields:
        raise HTTPException(400, f"Unnecessary fields: {unnecessary_fields}")
    
    user = await create_user(request)
    return {"user_id": user.id}
```

## 4.2 ê°œì¸ì •ë³´ ì•”í˜¸í™” (Data Encryption)

### DB ì»¬ëŸ¼ ë‹¨ìœ„ ì•”í˜¸í™” (pgcrypto)

```sql
CREATE EXTENSION IF NOT EXISTS pgcrypto;

-- ì „í™”ë²ˆí˜¸ ì•”í˜¸í™”
ALTER TABLE users ADD COLUMN phone_encrypted BYTEA;

UPDATE users 
SET phone_encrypted = pgp_sym_encrypt(phone, current_setting('app.encryption_key'))
WHERE phone IS NOT NULL;

-- ë³µí˜¸í™” í•¨ìˆ˜
CREATE OR REPLACE FUNCTION decrypt_phone(user_id INTEGER)
RETURNS TEXT AS $$
BEGIN
    RETURN pgp_sym_decrypt(
        (SELECT phone_encrypted FROM users WHERE id = user_id),
        current_setting('app.encryption_key')
    );
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;
```

### íŒŒì¼ ì €ì¥ ì•”í˜¸í™”

```python
from cryptography.fernet import Fernet

class FileEncryptor:
    def __init__(self, key: bytes):
        self.cipher = Fernet(key)
    
    async def encrypt_and_upload(self, file: UploadFile) -> str:
        """íŒŒì¼ ì•”í˜¸í™” í›„ R2 ì—…ë¡œë“œ"""
        content = await file.read()
        encrypted = self.cipher.encrypt(content)
        
        # Cloudflare R2 ì—…ë¡œë“œ (private)
        url = await r2_client.upload(
            key=f"encrypted/{file.filename}",
            body=encrypted,
            content_type=file.content_type,
            metadata={"encrypted": "true"}
        )
        
        return url
    
    async def download_and_decrypt(self, url: str) -> bytes:
        """R2ì—ì„œ ë‹¤ìš´ë¡œë“œ í›„ ë³µí˜¸í™”"""
        encrypted = await r2_client.download(url)
        decrypted = self.cipher.decrypt(encrypted)
        return decrypted

# ì‚¬ìš©
encryptor = FileEncryptor(ENCRYPTION_KEY)
url = await encryptor.encrypt_and_upload(file)
```

## 4.3 í”„ë¼ì´ë²„ì‹œ ê¶Œë¦¬ (Privacy Rights)

GDPR/PIPA ê¸°ì¤€:

### 1. Right to Access (ì—´ëŒê¶Œ)

```python
@app.get("/api/v1/privacy/my-data")
async def get_my_data(user: User = Depends(get_current_user)):
    """ì‚¬ìš©ì ë°ì´í„° ì „ì²´ ë‹¤ìš´ë¡œë“œ"""
    data = {
        "personal_info": {
            "email": user.email,
            "name": user.name,
            "phone": await decrypt_phone(user.id),
            "created_at": user.created_at
        },
        "exam_history": await get_exam_attempts(user.id),
        "ai_usage": await get_ai_requests(user.id),
        "audit_log": await get_audit_logs(user.id)
    }
    
    return JSONResponse(
        content=data,
        headers={"Content-Disposition": "attachment; filename=my_data.json"}
    )
```

### 2. Right to Erasure (ì‚­ì œê¶Œ)

```python
@app.delete("/api/v1/privacy/delete-account")
async def delete_my_account(user: User = Depends(get_current_user)):
    """ê³„ì • ì‚­ì œ (GDPR Right to Erasure)"""
    
    # 1. PII ì‚­ì œ/ìµëª…í™”
    await db.execute(
        """
        UPDATE users SET
            email = 'deleted_' || id || '@deleted.local',
            phone_encrypted = NULL,
            name = 'Deleted User',
            deleted_at = NOW()
        WHERE id = :id
        """,
        {"id": user.id}
    )
    
    # 2. Audit Log ìµëª…í™”
    await db.execute(
        "UPDATE audit_log SET user_id = NULL WHERE user_id = :id",
        {"id": user.id}
    )
    
    # 3. AI ì¶œë ¥ë¬¼ ì‚­ì œ
    await r2_client.delete_prefix(f"/users/{user.id}/")
    
    # 4. ì„±ì  ë°ì´í„° ìµëª…í™” (í†µê³„ëŠ” ìœ ì§€)
    await db.execute(
        "UPDATE exam_attempts SET user_id = NULL, anonymized = TRUE WHERE user_id = :id",
        {"id": user.id}
    )
    
    return {"status": "deleted", "message": "Account deleted successfully"}
```

### 3. Right to Portability (ì´ë™ê¶Œ)

```python
@app.get("/api/v1/privacy/export-data")
async def export_my_data(user: User = Depends(get_current_user)):
    """ë°ì´í„° ì´ë™ê¶Œ (JSON ë‹¤ìš´ë¡œë“œ)"""
    data = await get_all_user_data(user.id)
    
    return Response(
        content=json.dumps(data, indent=2, ensure_ascii=False),
        media_type="application/json",
        headers={"Content-Disposition": "attachment; filename=my_data.json"}
    )
```

### 4. Right to Restrict Processing (ì²˜ë¦¬ ì œí•œê¶Œ)

```python
@app.post("/api/v1/privacy/restrict-processing")
async def restrict_processing(user: User = Depends(get_current_user)):
    """ë°ì´í„° ì²˜ë¦¬ ì œí•œ"""
    await db.execute(
        "UPDATE users SET processing_restricted = TRUE WHERE id = :id",
        {"id": user.id}
    )
    
    # ì œí•œ ì¤‘ì—ëŠ” AI ê¸°ëŠ¥ ë¹„í™œì„±í™”
    await redis.setex(f"user:{user.id}:restricted", 86400, "true")
    
    return {"status": "restricted", "message": "Data processing restricted"}
```

## 4.4 ì˜ìƒ/ìŒì„± ë³´í˜¸ (Media Data Protection)

### ìë™ ì‚­ì œ ì •ì±…

```python
@app.on_event("startup")
@repeat_every(seconds=86400)  # 1ì¼ë§ˆë‹¤
async def cleanup_media_files():
    """ì˜ìƒ/ìŒì„± ìë™ ì‚­ì œ"""
    
    # Whisper ì—…ë¡œë“œ íŒŒì¼ 7ì¼ í›„ ì‚­ì œ
    await r2_client.delete_objects_older_than("/tmp/whisper/", days=7)
    
    # PoseNet ì—…ë¡œë“œ íŒŒì¼ 7ì¼ í›„ ì‚­ì œ
    await r2_client.delete_objects_older_than("/tmp/posenet/", days=7)
    
    # K-Zone Creator Studio 30ì¼ í›„ ì‚­ì œ
    await r2_client.delete_objects_older_than("/kzone/creator-studio/", days=30)
```

---

# ğŸ‘¥ 5. ì‚¬ìš©ì ìƒí˜¸ì‘ìš© ì•ˆì „ (User Interaction Safety)

## 5.1 Parentâ€“Student ìŠ¹ì¸ (Parent-Student Approval)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Parent      â”‚  ì—°ê²° ìš”ì²­
â”‚  Request     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Student     â”‚  ìŠ¹ì¸ (7ì¼ ì´ë‚´)
â”‚  Approval    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Connection  â”‚  ì—°ê²° í™•ë¦½
â”‚  Established â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ìŠ¹ì¸ ë§Œë£Œ ì²˜ë¦¬

```python
@app.on_event("startup")
@repeat_every(seconds=86400)  # 1ì¼ë§ˆë‹¤
async def expire_pending_links():
    """7ì¼ ê²½ê³¼ ìŠ¹ì¸ ìš”ì²­ ìë™ ë§Œë£Œ"""
    await db.execute(
        """
        UPDATE parent_student_links SET
            status = 'expired',
            expired_at = NOW()
        WHERE status = 'pending'
          AND created_at < NOW() - INTERVAL '7 days'
        """
    )
```

## 5.2 Teacherâ€“Student ìƒí˜¸ì‘ìš© (Teacher-Student Interaction)

### 1:1 ë©”ì‹œì§€ ì œí•œ

```python
@app.post("/api/v1/messages/send")
async def send_message(
    request: MessageRequest,
    sender: User = Depends(get_current_user)
):
    # í•™ìƒâ†”êµì‚¬ 1:1 ë©”ì‹œì§€ëŠ” ì œí•œ
    if sender.role == "student" and request.recipient_role == "teacher":
        # ëŒ€ì‹œë³´ë“œ/ê·¸ë£¹ ì±„íŒ…ë§Œ í—ˆìš©
        raise HTTPException(403, "Direct messaging is not allowed. Please use class dashboard.")
    
    # êµì‚¬â†’í•™ìƒì€ í—ˆìš© (ê³µì§€, í”¼ë“œë°±)
    message = await create_message(sender.id, request.recipient_id, request.content)
    return message
```

### ì±„íŒ… ë¡œê·¸ ë³´ì¡´

```python
@app.on_event("startup")
@repeat_every(seconds=86400)  # 1ì¼ë§ˆë‹¤
async def cleanup_old_messages():
    """1ë…„ ì´ìƒ ëœ ì±„íŒ… ë¡œê·¸ ì‚­ì œ"""
    await db.execute(
        "DELETE FROM messages WHERE created_at < NOW() - INTERVAL '1 year'"
    )
```

## 5.3 ì»¤ë®¤ë‹ˆí‹° ì•ˆì „ (K-Zone Community Safety)

### ì‹¤ì‹œê°„ ìš•ì„¤/í˜ì˜¤ í•„í„°

```python
from profanity_check import predict

@app.post("/api/v1/kzone/chat")
async def send_chat_message(
    request: ChatRequest,
    user: User = Depends(get_current_user)
):
    # ìš•ì„¤ ê²€ì‚¬
    is_profane = predict([request.message])[0] == 1
    
    if is_profane:
        # ê²½ê³  ëˆ„ì 
        await increment_warning_count(user.id)
        
        # ê²½ê³  íšŸìˆ˜ í™•ì¸
        warning_count = await get_warning_count(user.id)
        
        if warning_count >= 3:
            # 3íšŒ ëˆ„ì  â†’ 24ì‹œê°„ ì±„íŒ… ê¸ˆì§€
            await ban_user(user.id, duration=86400, reason="Repeated profanity")
            raise HTTPException(403, "You are temporarily banned from chat (24 hours)")
        
        raise HTTPException(400, "Your message contains inappropriate language")
    
    # ë©”ì‹œì§€ ì „ì†¡
    message = await broadcast_chat(request.message, user.id)
    return message
```

### ê³„ì • ë°´ ì •ì±…

```
1ì°¨ ê²½ê³ : 24ì‹œê°„ ì±„íŒ… ì œí•œ
2ì°¨ ê²½ê³ : 7ì¼ ì±„íŒ… ì œí•œ
3ì°¨ ê²½ê³ : 30ì¼ ê³„ì • ì •ì§€
4ì°¨ ê²½ê³ : ì˜êµ¬ ê³„ì • ì •ì§€
```

```python
async def ban_user(user_id: int, duration: int, reason: str):
    """ì‚¬ìš©ì ê³„ì • ì œí•œ"""
    await db.execute(
        """
        INSERT INTO user_bans (user_id, duration, reason, expires_at)
        VALUES (:user_id, :duration, :reason, NOW() + INTERVAL ':duration seconds')
        """,
        {"user_id": user_id, "duration": duration, "reason": reason}
    )
    
    # Redisì— ë°´ ì •ë³´ ìºì‹±
    await redis.setex(f"user:{user_id}:banned", duration, reason)
    
    # Audit Log ê¸°ë¡
    await log_audit(user_id, "user_banned", {"duration": duration, "reason": reason})
```

---

# ğŸ› ï¸ 6. ì•ˆì „ ì‚¬ê³  ëŒ€ì‘ í”„ë¡œì„¸ìŠ¤ (Safety Incident Response)

## 6.1 ì‚¬ê³  ìœ í˜• (Incident Types)

| ì‚¬ê³  ìœ í˜• | ì‹¬ê°ë„ | SLA | ë‹´ë‹¹ì |
|----------|--------|-----|--------|
| **ìœ í•´ ì½˜í…ì¸  ì¶œë ¥** | P2 | 1ì‹œê°„ | Safety Team |
| **AI ì¶œë ¥ ì˜¤ë¥˜** | P3 | 4ì‹œê°„ | AI Team |
| **ì‚¬ìš©ì ê°„ ë¶€ì ì ˆ ìƒí˜¸ì‘ìš©** | P2 | 1ì‹œê°„ | Community Manager |
| **ê°œì¸ì •ë³´ ë…¸ì¶œ** | P1 | 15ë¶„ | Security + Legal |
| **CSAM (ì•„ë™ ì„± ì°©ì·¨ë¬¼)** | P0 | ì¦‰ì‹œ | Legal + Law Enforcement |

## 6.2 ëŒ€ì‘ ì ˆì°¨ (Response Procedure)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. ì‚¬ê³  ê°ì§€    â”‚  AI Filter / User Report / Automated Alert
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. ê¸´ê¸‰ ì°¨ë‹¨    â”‚  ì½˜í…ì¸  ì¦‰ì‹œ ì‚­ì œ / ê³„ì • ì¼ì‹œ ì •ì§€
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. Safety ê²€í†   â”‚  Safety Team ìˆ˜ë™ ê²€í† 
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. ì›ì¸ ë¶„ì„    â”‚  AI ë¡œê·¸ ë¶„ì„ / ì‚¬ìš©ì íŒ¨í„´ ë¶„ì„
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. ì¬ë°œ ë°©ì§€    â”‚  í•„í„° ì—…ë°ì´íŠ¸ / ì •ì±… ë³€ê²½ / ëª¨ë¸ ì¬í•™ìŠµ
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ìë™ ì‚¬ê³  ê°ì§€

```python
@app.on_event("startup")
@repeat_every(seconds=300)  # 5ë¶„ë§ˆë‹¤
async def safety_incident_monitor():
    """ì•ˆì „ ì‚¬ê³  ìë™ ê°ì§€"""
    
    # 1. ìœ í•´ ì½˜í…ì¸  ê¸‰ì¦ ê°ì§€
    harmful_content_count = await db.scalar(
        "SELECT count(*) FROM safety_logs WHERE type = 'harmful_content' AND created_at > NOW() - INTERVAL '1 hour'"
    )
    if harmful_content_count > 10:
        await send_alert("ğŸš¨ Harmful content spike detected (10+ in last hour)")
    
    # 2. AI ì¶œë ¥ ì˜¤ë¥˜ ê¸‰ì¦
    ai_error_count = await db.scalar(
        "SELECT count(*) FROM safety_logs WHERE type = 'ai_error' AND created_at > NOW() - INTERVAL '1 hour'"
    )
    if ai_error_count > 50:
        await send_alert("âš ï¸ AI output error spike detected (50+ in last hour)")
    
    # 3. ì‚¬ìš©ì ì‹ ê³  ê¸‰ì¦
    user_report_count = await db.scalar(
        "SELECT count(*) FROM user_reports WHERE created_at > NOW() - INTERVAL '1 hour'"
    )
    if user_report_count > 20:
        await send_alert("ğŸ“¢ User report spike detected (20+ in last hour)")
```

## 6.3 ì‚¬ìš©ì ì‹ ê³  ì‹œìŠ¤í…œ (User Reporting System)

### ì‹ ê³  ë²„íŠ¼

```python
@app.post("/api/v1/report")
async def report_content(
    request: ReportRequest,
    user: User = Depends(get_current_user)
):
    """ì½˜í…ì¸ /ì‚¬ìš©ì ì‹ ê³ """
    report = await db.execute(
        """
        INSERT INTO user_reports (reporter_id, content_id, content_type, reason, description, status)
        VALUES (:reporter_id, :content_id, :content_type, :reason, :description, 'pending')
        RETURNING *
        """,
        {
            "reporter_id": user.id,
            "content_id": request.content_id,
            "content_type": request.content_type,  # 'message', 'video', 'image', 'user'
            "reason": request.reason,  # 'spam', 'harassment', 'inappropriate', 'hate'
            "description": request.description
        }
    )
    
    # Safety Teamì— Slack ì•Œë¦¼
    await send_slack(
        "#safety-alerts",
        f"New report: {request.content_type} - {request.reason}\nReporter: {user.email}"
    )
    
    return {"status": "pending", "report_id": report.id}
```

### ì‹ ê³  ì²˜ë¦¬ SLA

```
P0 (CSAM, ì•„ë™ í•™ëŒ€): ì¦‰ì‹œ ì²˜ë¦¬ + ë²• ì§‘í–‰ ê¸°ê´€ ì‹ ê³ 
P1 (ê°œì¸ì •ë³´ ë…¸ì¶œ): 15ë¶„ ì´ë‚´
P2 (ìœ í•´ ì½˜í…ì¸ , ê´´ë¡­í˜): 1ì‹œê°„ ì´ë‚´
P3 (ìŠ¤íŒ¸, ê¸°íƒ€): 24ì‹œê°„ ì´ë‚´
```

---

# ğŸ“‹ 7. ì•ˆì „ ê´€ë ¨ ë¡œê·¸ ë° ë³´ì¡´ ê·œì • (Safety Logs & Retention)

## 7.1 ë¡œê·¸ ë³´ì¡´ ê¸°ê°„

| ë¡œê·¸ ìœ í˜• | ë³´ì¡´ ê¸°ê°„ | ì‚­ì œ ë°©ë²• |
|----------|----------|----------|
| **ìœ í•´ ì¶œë ¥ ë¡œê·¸** | 90ì¼ | Auto-delete |
| **ì‚¬ìš©ì ì‹ ê³  ì‚¬ê±´** | 1ë…„ | Anonymize |
| **AI Abuse íƒì§€ ë¡œê·¸** | 180ì¼ | Auto-delete |
| **ê³„ì • ë°´ ê¸°ë¡** | 2ë…„ | Anonymize |
| **CSAM ì‚¬ê³ ** | ì˜êµ¬ ë³´ì¡´ | ë²•ì  ìš”êµ¬ ì‹œë§Œ ì‚­ì œ |

## 7.2 ë¡œê·¸ ìë™ ì‚­ì œ

```python
@app.on_event("startup")
@repeat_every(seconds=86400)  # 1ì¼ë§ˆë‹¤
async def cleanup_safety_logs():
    """ì•ˆì „ ë¡œê·¸ ìë™ ì‚­ì œ"""
    
    # 90ì¼ ì´ìƒ ëœ ìœ í•´ ì¶œë ¥ ë¡œê·¸ ì‚­ì œ
    await db.execute(
        "DELETE FROM safety_logs WHERE type = 'harmful_output' AND created_at < NOW() - INTERVAL '90 days'"
    )
    
    # 180ì¼ ì´ìƒ ëœ AI Abuse ë¡œê·¸ ì‚­ì œ
    await db.execute(
        "DELETE FROM safety_logs WHERE type = 'ai_abuse' AND created_at < NOW() - INTERVAL '180 days'"
    )
    
    # 1ë…„ ì´ìƒ ëœ ì‚¬ìš©ì ì‹ ê³  ìµëª…í™”
    await db.execute(
        """
        UPDATE user_reports SET
            reporter_id = NULL,
            anonymized = TRUE
        WHERE created_at < NOW() - INTERVAL '1 year'
          AND anonymized = FALSE
        """
    )
```

---

# ğŸ 8. ê²°ë¡  (Conclusion)

ì´ **User Safety Guide**ëŠ” DreamSeedAI MegaCityì˜ êµìœ¡Â·ë¬¸í™”Â·AI ì„œë¹„ìŠ¤ê°€ **í•™ìƒÂ·í•™ë¶€ëª¨Â·êµì‚¬ ëª¨ë‘ì—ê²Œ ì•ˆì „í•˜ê²Œ ì œê³µ**ë  ìˆ˜ ìˆë„ë¡ ë³´ì¥í•˜ëŠ” í•µì‹¬ ê¸°ì¤€ ë¬¸ì„œì…ë‹ˆë‹¤.

## í•µì‹¬ ì•ˆì „ ì›ì¹™

```
1. ì½˜í…ì¸  ì•ˆì „ ìš°ì„  (Content Safety First)
   - ìœ í•´ ì½˜í…ì¸  ì¦‰ì‹œ ì°¨ë‹¨
   - K-Zone ë™ì˜ ê¸°ë°˜ ì–¼êµ´/ìŒì„± í•©ì„±

2. AI ì•ˆì „ì„± ë³´ì¥ (AI Safety)
   - Prompt Injection ë°©ì–´
   - ìœ í•´ ì¶œë ¥ ìë™ í•„í„°ë§
   - êµìœ¡ì  í”„ë ˆì´ë° ì ìš©

3. í•™ìŠµì ë³´í˜¸ (Student Protection)
   - Parent-Student ìŠ¹ì¸ ì²´ê³„
   - ì„±ì  ë°ì´í„° ì ‘ê·¼ ì œí•œ
   - ì‹¤ì‹œê°„ ìƒí˜¸ì‘ìš© ì•ˆì „

4. í”„ë¼ì´ë²„ì‹œ ìµœìš°ì„  (Privacy First)
   - ìµœì†Œ ì •ë³´ ìˆ˜ì§‘
   - ì•”í˜¸í™” ë° ë³´ì•ˆ
   - GDPR/PIPA ê¶Œë¦¬ ë³´ì¥

5. ì‹ ì†í•œ ì‚¬ê³  ëŒ€ì‘ (Rapid Response)
   - 24ì‹œê°„ ì‹ ê³  ì²˜ë¦¬ SLA
   - P0 ì‚¬ê³  ì¦‰ì‹œ ëŒ€ì‘
   - ì¬ë°œ ë°©ì§€ ì¡°ì¹˜
```

## ì•ˆì „ ì²´í¬ë¦¬ìŠ¤íŠ¸

```
â–¡ ì½˜í…ì¸  í•„í„° (NSFW, Hate Speech, Violence) í™œì„±
â–¡ AI Prompt Injection ë°©ì–´ í™œì„±
â–¡ AI ì¶œë ¥ ìœ í•´ì„± ê²€ì‚¬ í™œì„±
â–¡ Parent-Student ìŠ¹ì¸ ì²´ê³„ ìš´ì˜
â–¡ ì„±ì  ë°ì´í„° RLS ì •ì±… ì ìš©
â–¡ ê°œì¸ì •ë³´ ì•”í˜¸í™” (pgcrypto) ì ìš©
â–¡ GDPR/PIPA ê¶Œë¦¬ (Access, Erasure, Portability) êµ¬í˜„
â–¡ ì‚¬ìš©ì ì‹ ê³  ì‹œìŠ¤í…œ í™œì„± (24ì‹œê°„ SLA)
â–¡ ì•ˆì „ ë¡œê·¸ ë³´ì¡´ ì •ì±… ì¤€ìˆ˜ (90ì¼~2ë…„)
â–¡ ê¸´ê¸‰ ì‚¬ê³  ëŒ€ì‘ ì ˆì°¨ ë¬¸ì„œí™”
```

MegaCityì˜ **AI Safety Â· Content Safety Â· Privacy ë³´í˜¸ Â· ì—­í• Â·ìŠ¹ì¸ ì²´ê³„**ê°€ í•¨ê»˜ ë™ì‘í•˜ì—¬ ì „ì²´ ì‚¬ìš©ìì—ê²Œ **ì‹ ë¢° ê¸°ë°˜ ê²½í—˜**ì„ ì œê³µí•©ë‹ˆë‹¤.

---

**ë¬¸ì„œ ì™„ë£Œ - DreamSeedAI MegaCity User Safety Guide v1.0**
