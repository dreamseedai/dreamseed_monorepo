# DreamSeedAI: 2. ì •ì±… ê³„ì¸µ (Policy Layer) ìƒì„¸ ì„¤ê³„

ì •ì±… ê³„ì¸µì€ ê±°ë²„ë„ŒìŠ¤ ê³„ì¸µì˜ ì›ì¹™ë“¤ì„ ì‹¤ì œ í”Œë«í¼ ë‚´ ê·œì¹™ê³¼ ë¡œì§ìœ¼ë¡œ êµ¬í˜„í•œ ê³„ì¸µì…ë‹ˆë‹¤. ì‰½ê²Œ ë§í•´, ê±°ë²„ë„ŒìŠ¤ê°€ "ë¬´ì—‡ì„ í•´ì•¼ í•œë‹¤/í•˜ì§€ ë§ì•„ì•¼ í•œë‹¤"ë¥¼ ì •í–ˆë‹¤ë©´, ì •ì±… ê³„ì¸µì€ "ê·¸ê²ƒì„ ì‹¤í˜„í•˜ê¸° ìœ„í•´ ì‹œìŠ¤í…œì´ ë”°ë¼ì•¼ í•  ì„¸ë¶€ ê·œì¹™ê³¼ ì‹¤í–‰ ë°©ë²•"ì„ ë‹¤ë£¹ë‹ˆë‹¤.

---

## 1. í•µì‹¬ ì—­í• 

*   **ì›ì¹™ì˜ êµ¬ì²´í™”**: ê±°ë²„ë„ŒìŠ¤ ê³„ì¸µì—ì„œ ì œì‹œëœ ì¶”ìƒì ì¸ ì›ì¹™ì„ êµ¬ì²´ì ì¸ ì •ì±… ë° ê·œì¹™ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
*   **ì‹œìŠ¤í…œ ì œì–´**: ì‹œìŠ¤í…œ ê³„ì¸µì˜ ë™ì‘ì„ ì œì–´í•˜ê³ , AI ì•Œê³ ë¦¬ì¦˜ì˜ í–‰ë™ ë²”ìœ„ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
*   **ì‹¤í–‰ ë°©ë²• ëª…ì‹œ**: ì •ì±…ì„ ì‹œí–‰í•˜ê¸° ìœ„í•œ ì ˆì°¨, ê¸°ìˆ ì  êµ¬í˜„ ë°©ë²•, ë° ì±…ì„ ì†Œì¬ë¥¼ ëª…í™•íˆ í•©ë‹ˆë‹¤.
*   **ìƒí™©ë³„ ì •ì±… ì ìš©**: í”Œë«í¼ ìš´ì˜ ìƒí™©ì— ë”°ë¼ ì ì ˆí•œ ì •ì±…ì„ ì„ íƒì ìœ¼ë¡œ ì ìš©í•©ë‹ˆë‹¤.

---

## 2. ì£¼ìš” êµ¬ì„± ìš”ì†Œ

### 2.1 ì •ì±… ì—”ì§„ (Policy Engine)

ì •ì±… ê·œì¹™ì„ í‰ê°€í•˜ê³  ì‹¤í–‰í•˜ëŠ” í•µì‹¬ ì»´í¬ë„ŒíŠ¸ì…ë‹ˆë‹¤.

**êµ¬í˜„ ê¸°ìˆ **: Open Policy Agent (OPA)

**íŠ¹ì§•**:
*   ê·œì¹™ ê¸°ë°˜ ì‹œìŠ¤í…œ (Rule-Based System): ì‚¬ì „ ì •ì˜ëœ ê·œì¹™ì— ë”°ë¼ ì˜ì‚¬ ê²°ì • ìˆ˜í–‰
*   Rego ì–¸ì–´: ì„ ì–¸ì  ì •ì±… ì–¸ì–´ë¡œ ë³µì¡í•œ ê·œì¹™ í‘œí˜„ ê°€ëŠ¥
*   ì‹¤ì‹œê°„ í‰ê°€: HTTP APIë¥¼ í†µí•œ ë°€ë¦¬ì´ˆ ë‹¨ìœ„ ì •ì±… í‰ê°€
*   ë¨¸ì‹  ëŸ¬ë‹ í†µí•© (ì„ íƒ): í•™ìŠµëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ìƒí™©ì— ë§ëŠ” ì •ì±… ì ìš©

**DreamSeedAI êµ¬í˜„ í˜„í™©**:
```
governance/
â”œâ”€â”€ bundles/
â”‚   â”œâ”€â”€ phase0.rego          # ê¸°ë³¸ ì •ì±… (ê°œë°œ/í…ŒìŠ¤íŠ¸)
â”‚   â”œâ”€â”€ phase1.rego          # ì¤‘ê¸‰ ì •ì±… (ìŠ¤í…Œì´ì§•)
â”‚   â””â”€â”€ production.rego      # ìš´ì˜ ì •ì±… (í”„ë¡œë•ì…˜)
â””â”€â”€ compiled/
    â”œâ”€â”€ phase0.json
    â”œâ”€â”€ phase1.json
    â””â”€â”€ production.json
```

### 2.2 ì •ì±… ì €ì¥ì†Œ (Policy Repository)

ì •ì±… ê·œì¹™, ì„¤ì •, ë° ê´€ë ¨ ë©”íƒ€ë°ì´í„°ë¥¼ ì €ì¥í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

**êµ¬í˜„ ë°©ì‹**:
*   **Git ì €ì¥ì†Œ**: ì •ì±… ì†ŒìŠ¤ ì½”ë“œ ë²„ì „ ê´€ë¦¬
*   **ConfigMap**: Kubernetesì—ì„œ ì»´íŒŒì¼ëœ ì •ì±… ë²ˆë“¤ ì €ì¥
*   **ë°ì´í„°ë² ì´ìŠ¤**: ì •ì±… ë©”íƒ€ë°ì´í„° ë° ì‹¤í–‰ ì´ë ¥ ì €ì¥

**DreamSeedAI êµ¬í˜„**:
```yaml
# ops/k8s/governance/base/configmap-policy-bundle.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: governance-policy-bundle
data:
  policy.json: |
    {ì»´íŒŒì¼ëœ OPA ì •ì±… ë²ˆë“¤}
```

**ë²„ì „ ê´€ë¦¬**:
*   ì •ì±… ë³€ê²½ ì‹œ Git ì»¤ë°‹ìœ¼ë¡œ ì´ë ¥ ì¶”ì 
*   ConfigMap Hashë¥¼ í†µí•œ ìë™ Hot Reload
*   ë¡¤ë°± ê°€ëŠ¥ (Git revert + ì¬ë°°í¬)

### 2.3 ì •ì±… ê´€ë¦¬ ì¸í„°í˜ì´ìŠ¤ (Policy Management Interface)

ê´€ë¦¬ìê°€ ì •ì±…ì„ ìƒì„±, ìˆ˜ì •, ì‚­ì œ, ë° ë°°í¬í•  ìˆ˜ ìˆëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

**ê¸°ëŠ¥**:
*   ì •ì±… í¸ì§‘: Rego ì½”ë“œ í¸ì§‘ ë° ê²€ì¦
*   í…ŒìŠ¤íŠ¸: ì •ì±… ì‹œë®¬ë ˆì´ì…˜ ë° ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
*   ë°°í¬: í™˜ê²½ë³„ ì •ì±… ë°°í¬ (dev â†’ staging â†’ production)
*   ê°ì‚¬: ì •ì±… ë³€ê²½ ì´ë ¥ ì¡°íšŒ

**DreamSeedAI êµ¬í˜„ ê³„íš**:
*   **í˜„ì¬**: Git + ìˆ˜ë™ ë°°í¬
*   **í–¥í›„**:
    *   Web UI: FastAPI ê¸°ë°˜ ì •ì±… ê´€ë¦¬ ëŒ€ì‹œë³´ë“œ
    *   API: RESTful APIë¡œ ì •ì±… CRUD
    *   ìŠ¹ì¸ ì›Œí¬í”Œë¡œ: ì •ì±… ë³€ê²½ ìŠ¹ì¸ í”„ë¡œì„¸ìŠ¤

### 2.4 ëª¨ë‹ˆí„°ë§ ë° ê°ì‚¬ ì‹œìŠ¤í…œ (Monitoring and Auditing System)

ì •ì±… ì‹œí–‰ ìƒí™©ì„ ëª¨ë‹ˆí„°ë§í•˜ê³ , ê°ì‚¬ ê¸°ë¡ì„ ìƒì„±í•©ë‹ˆë‹¤.

**DreamSeedAI êµ¬í˜„ í˜„í™©**:

#### Prometheus ë©”íŠ¸ë¦­ (19ê°œ)
```yaml
# Governance ë©”íŠ¸ë¦­ (7ê°œ)
- governance_policy_evaluations_total      # ì •ì±… í‰ê°€ íšŸìˆ˜
- governance_policy_deny_total             # ì •ì±… ê±°ë¶€ íšŸìˆ˜
- governance_policy_bundle_reload_total    # ì •ì±… ë²ˆë“¤ ë¦¬ë¡œë“œ íšŸìˆ˜
- governance_policy_errors_total           # ì •ì±… í‰ê°€ ì˜¤ë¥˜
- governance_policy_evaluation_duration    # ì •ì±… í‰ê°€ ì§€ì—°ì‹œê°„
- governance_policy_bundle_version         # í˜„ì¬ ì •ì±… ë²ˆë“¤ ë²„ì „
- governance_policy_hot_reload_success     # Hot Reload ì„±ê³µ ì—¬ë¶€
```

#### ì•Œë¦¼ ê·œì¹™ (15ê°œ ì¤‘ ì •ì±… ê´€ë ¨ 5ê°œ)
```yaml
- GovernancePolicyBundleLoadFailure        # Critical: ì •ì±… ë²ˆë“¤ ë¡œë“œ ì‹¤íŒ¨
- GovernancePolicyEvaluationErrors         # Warning: ì •ì±… í‰ê°€ ì˜¤ë¥˜ ê¸‰ì¦
- GovernanceHighDenyRate                   # Warning: ì •ì±… ê±°ë¶€ìœ¨ ë†’ìŒ
- GovernancePolicyBundleStale              # Warning: ì •ì±… ë²ˆë“¤ ì˜¤ë˜ë¨
- GovernanceHotReloadFailure               # Warning: Hot Reload ì‹¤íŒ¨
```

#### Grafana ëŒ€ì‹œë³´ë“œ
*   ì •ì±… í‰ê°€ ì„±ê³µ/ì‹¤íŒ¨ìœ¨ ì‹œê°í™”
*   ì •ì±…ë³„ ê±°ë¶€ìœ¨ ì¶”ì´
*   ì •ì±… í‰ê°€ ì§€ì—°ì‹œê°„ ë¶„í¬
*   ì •ì±… ë²ˆë“¤ ë²„ì „ ì´ë ¥

#### Alertmanager (Slack í†µí•©)
*   Critical ì•Œë¦¼: ì¦‰ì‹œ Slack ì „ì†¡ (ë¹¨ê°•ìƒ‰)
*   Warning ì•Œë¦¼: 30ì´ˆ ê·¸ë£¹í™” í›„ ì „ì†¡ (ì£¼í™©ìƒ‰)

---

## 3. ì •ì±… ì—”ì§„ ë™ì‘ ë°©ì‹

### 3.1 ì‹¤í–‰ íë¦„

```
1. ìƒí™© ì¸ì‹
   â†“
2. ì •ì±… ê²€ìƒ‰
   â†“
3. ê·œì¹™ í‰ê°€
   â†“
4. ì•¡ì…˜ ì‹¤í–‰
   â†“
5. ë¡œê¹… ë° ê°ì‚¬
```

### 3.2 ìƒì„¸ ë‹¨ê³„

#### 1ï¸âƒ£ ìƒí™© ì¸ì‹
ì •ì±… ì—”ì§„ì€ í”Œë«í¼ ìš´ì˜ ì‹œì ì— ëŒ€í•œ ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.

**ìˆ˜ì§‘ ë°ì´í„°**:
*   ìš”ì²­ ì»¨í…ìŠ¤íŠ¸: user_id, role, phase, endpoint
*   í•™ìƒ í™œë™: í•™ìŠµ í™œë™, ì½˜í…ì¸  ì ‘ê·¼, ë¬¸ì œ ì œì¶œ
*   êµì‚¬ ì‘ì—…: ê´€ë¦¬ ì‘ì—…, ë°ì´í„° ì ‘ê·¼, ë¦¬í¬íŠ¸ ìƒì„±
*   ì‹œìŠ¤í…œ ì´ë²¤íŠ¸: AI ëª¨ë¸ í˜¸ì¶œ, ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬, ì™¸ë¶€ API í˜¸ì¶œ

**DreamSeedAI êµ¬í˜„**:
```python
# governance/backend/policy_middleware.py
async def policy_middleware(request: Request, call_next):
    # 1. ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘
    user_id = request.headers.get("X-User-ID")
    role = request.headers.get("X-User-Role")
    phase = os.getenv("DEPLOYMENT_PHASE", "phase0")
    
    # 2. ì •ì±… í‰ê°€ ì…ë ¥ ìƒì„±
    input_data = {
        "user": {"id": user_id, "role": role},
        "request": {
            "method": request.method,
            "path": request.url.path,
            "phase": phase
        }
    }
```

#### 2ï¸âƒ£ ì •ì±… ê²€ìƒ‰
ì •ì±… ì—”ì§„ì€ ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•´ë‹¹ ìƒí™©ì— ì ìš© ê°€ëŠ¥í•œ ì •ì±… ê·œì¹™ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.

**DreamSeedAI êµ¬í˜„**:
```python
# governance/backend/policy_routes.py
ROUTE_POLICY_MAP = {
    r"^/api/curriculum/.*": {
        "policy": "curriculum_access",
        "require_feature_flag": "curriculum_management"
    },
    r"^/api/students/\d+/data$": {
        "policy": "student_data_access",
        "require_feature_flag": "student_data_access"
    },
    # ... 34ê°œ ì—”ë“œí¬ì¸íŠ¸ ë§¤í•‘
}
```

#### 3ï¸âƒ£ ê·œì¹™ í‰ê°€
ì •ì±… ì—”ì§„ì€ ê²€ìƒ‰ëœ ì •ì±… ê·œì¹™ì„ í‰ê°€í•˜ê³ , ê·œì¹™ ì¶©ì¡± ì—¬ë¶€ë¥¼ íŒë‹¨í•©ë‹ˆë‹¤.

**OPA ì •ì±… í‰ê°€**:
```python
# governance/backend/policy_controller.py
async def evaluate_policy(policy_name: str, input_data: dict) -> dict:
    response = await http_client.post(
        f"{OPA_URL}/v1/data/{policy_name}",
        json={"input": input_data}
    )
    result = response.json()["result"]
    
    # ë©”íŠ¸ë¦­ ê¸°ë¡
    GOVERNANCE_EVALUATIONS.labels(
        policy=policy_name,
        decision="allow" if result["allow"] else "deny"
    ).inc()
    
    return result
```

**ì •ì±… ì˜ˆì‹œ (Rego)**:
```rego
# governance/bundles/phase0.rego
package curriculum_access

default allow = false

# êµì‚¬ëŠ” ëª¨ë“  ì»¤ë¦¬í˜ëŸ¼ ì ‘ê·¼ ê°€ëŠ¥
allow {
    input.user.role == "teacher"
}

# í•™ìƒì€ ìì‹ ì˜ í•™ë…„ ì»¤ë¦¬í˜ëŸ¼ë§Œ ì ‘ê·¼ ê°€ëŠ¥
allow {
    input.user.role == "student"
    input.request.grade == input.user.grade
}

# ê±°ë¶€ ì‚¬ìœ  ìƒì„±
deny[msg] {
    not allow
    msg := sprintf("User %s cannot access curriculum", [input.user.id])
}
```

#### 4ï¸âƒ£ ì•¡ì…˜ ì‹¤í–‰
ê·œì¹™ì„ ì¶©ì¡±í•˜ëŠ” ê²½ìš°, ì •ì±… ì—”ì§„ì€ í•´ë‹¹ ê·œì¹™ì— ì •ì˜ëœ ì•¡ì…˜ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.

**ì•¡ì…˜ ìœ í˜•**:
*   **í—ˆìš© (Allow)**: ìš”ì²­ í†µê³¼, ë‹¤ìŒ ë¯¸ë“¤ì›¨ì–´ë¡œ ì´ë™
*   **ê±°ë¶€ (Deny)**: HTTP 403 Forbidden ì‘ë‹µ
*   **ì¡°ê±´ë¶€ í—ˆìš©**: íŠ¹ì • ì¡°ê±´ ì¶©ì¡± ì‹œ í—ˆìš© (ì˜ˆ: ë°ì´í„° ë§ˆìŠ¤í‚¹ í›„ í—ˆìš©)
*   **ì•Œë¦¼**: ê´€ë¦¬ìì—ê²Œ ì•Œë¦¼ ì „ì†¡ (ì˜ˆ: ë¯¼ê°í•œ ë°ì´í„° ì ‘ê·¼ ì‹œ)
*   **ë¡œê¹…**: ê°ì‚¬ ë¡œê·¸ ê¸°ë¡

**DreamSeedAI êµ¬í˜„**:
```python
# governance/backend/policy_middleware.py
if not result["allow"]:
    # ê±°ë¶€ ë©”íŠ¸ë¦­ ê¸°ë¡
    GOVERNANCE_DENY.labels(
        policy=policy_name,
        reason=result.get("deny", ["unknown"])[0]
    ).inc()
    
    # 403 ì‘ë‹µ
    raise HTTPException(
        status_code=403,
        detail={"error": "Policy violation", "reason": result["deny"]}
    )

# í—ˆìš© - ìš”ì²­ ê³„ì† ì§„í–‰
response = await call_next(request)
return response
```

#### 5ï¸âƒ£ ë¡œê¹… ë° ê°ì‚¬
ì •ì±… ì—”ì§„ì˜ ëª¨ë“  í™œë™ì€ ê°ì‚¬ ë¡œê·¸ì— ê¸°ë¡ë©ë‹ˆë‹¤.

**ë¡œê·¸ í•­ëª©**:
*   íƒ€ì„ìŠ¤íƒ¬í”„
*   ì‚¬ìš©ì ì •ë³´ (user_id, role)
*   ìš”ì²­ ì •ë³´ (method, path, parameters)
*   ì •ì±… ì´ë¦„
*   í‰ê°€ ê²°ê³¼ (allow/deny)
*   ê±°ë¶€ ì‚¬ìœ 
*   ì‹¤í–‰ ì‹œê°„

**DreamSeedAI êµ¬í˜„**:
```python
# êµ¬ì¡°í™”ëœ ë¡œê¹…
logger.info(
    "Policy evaluation",
    extra={
        "user_id": user_id,
        "role": role,
        "policy": policy_name,
        "decision": "allow" if result["allow"] else "deny",
        "duration_ms": duration * 1000
    }
)
```

**Prometheus ë©”íŠ¸ë¦­ìœ¼ë¡œ ì§‘ê³„**:
```promql
# ì‹œê°„ë³„ ì •ì±… ê±°ë¶€ìœ¨
rate(governance_policy_deny_total[5m]) 
  / 
rate(governance_policy_evaluations_total[5m])
```

---

## 4. ì •ì±… ì˜ˆì‹œ

### 4.1 ê°œì¸ ì •ë³´ ë³´í˜¸ ì •ì±…

**ê·œì¹™**: í•™ìƒ ë°ì´í„°ëŠ” ìµëª…í™” ì²˜ë¦¬ í›„ AI ëª¨ë¸ í•™ìŠµì— ì‚¬ìš©í•´ì•¼ í•œë‹¤.

**Rego ì •ì±…**:
```rego
package student_data_anonymization

default allow = false

# AI í•™ìŠµìš© ë°ì´í„°ëŠ” ìµëª…í™” í•„ìˆ˜
allow {
    input.purpose == "ai_training"
    input.data.anonymized == true
}

# ìµëª…í™”ë˜ì§€ ì•Šì€ ë°ì´í„° ì‚¬ìš© ê±°ë¶€
deny[msg] {
    input.purpose == "ai_training"
    input.data.anonymized != true
    msg := "Student data must be anonymized for AI training"
}
```

**ì•¡ì…˜**:
*   AI ëª¨ë¸ í•™ìŠµ ì „ì— í•™ìƒ ID, ì´ë¦„ ë“± ê°œì¸ ì‹ë³„ ì •ë³´ ì œê±°
*   SHA-256 í•´ì‹œë¡œ ID ë³€í™˜
*   ìƒë…„ì›”ì¼ â†’ ì—°ë ¹ëŒ€ë¡œ ë³€í™˜
*   ì´ë¦„ â†’ ì œê±°

**êµ¬í˜„**:
```python
def anonymize_student_data(student_data: dict) -> dict:
    return {
        "student_hash": hashlib.sha256(student_data["id"].encode()).hexdigest(),
        "age_group": calculate_age_group(student_data["birth_date"]),
        "grade": student_data["grade"],
        "performance": student_data["performance"],
        # ê°œì¸ ì‹ë³„ ì •ë³´ ì œê±°
    }
```

### 4.2 AI ì½˜í…ì¸  ì •ì±… (í•„í„°ë§ ë° ê²€ì—´)

ì½˜í…ì¸  ì •ì±…ì€ DreamSeedAIì—ì„œ í•™ìƒì—ê²Œ ì œê³µë˜ëŠ” ì½˜í…ì¸ ì™€ AI ì‘ë‹µì´ ê±°ë²„ë„ŒìŠ¤ ì›ì¹™ì— ë¶€í•©í•˜ë„ë¡ ì‹¤ì‹œê°„ìœ¼ë¡œ í•„í„°ë§í•˜ê³  ê²€ì—´í•˜ëŠ” ê·œì¹™ë“¤ì„ í¬í•¨í•©ë‹ˆë‹¤.

#### 4.2.1 ëª©í‘œ

*   **ì•ˆì „í•œ í•™ìŠµ í™˜ê²½**: í•™ìƒë“¤ì„ ìœ í•´í•˜ê±°ë‚˜ ë¶€ì ì ˆí•œ ì½˜í…ì¸ ë¡œë¶€í„° ë³´í˜¸
*   **ìœ¤ë¦¬ì  ê°€ì¹˜ ì¤€ìˆ˜**: AI ì‘ë‹µì´ ê³µì •ì„±, ê°ê´€ì„±, ì¡´ì¤‘ì˜ ê°€ì¹˜ë¥¼ ë°˜ì˜í•˜ë„ë¡ ë³´ì¥
*   **í•™ìŠµ ëª©í‘œ ë¶€í•©**: ì½˜í…ì¸ ê°€ êµìœ¡ ê³¼ì • ë° í•™ìŠµ ëª©í‘œì— ë¶€í•©í•˜ë„ë¡ ê´€ë¦¬

#### 4.2.2 í•„í„°ë§ ë° ê²€ì—´ ëŒ€ìƒ

*   **AI íŠœí„° ì‘ë‹µ**: AI íŠœí„°ê°€ ìƒì„±í•˜ëŠ” ëª¨ë“  í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ì˜¤ë””ì˜¤, ë¹„ë””ì˜¤ ì½˜í…ì¸ 
*   **ë¬¸í•­ ì€í–‰ ì½˜í…ì¸ **: ì‹œí—˜ ë¬¸ì œ, ì—°ìŠµ ë¬¸ì œ, ì„¤ëª… ìë£Œ ë° ê´€ë ¨ ì´ë¯¸ì§€/ë¹„ë””ì˜¤
*   **ì‚¬ìš©ì ìƒì„± ì½˜í…ì¸ **: í•™ìƒ ë° êµì‚¬ê°€ ì—…ë¡œë“œí•˜ê±°ë‚˜ ìƒì„±í•˜ëŠ” ì½˜í…ì¸  (í¬ëŸ¼ ê²Œì‹œê¸€, ê³¼ì œ ì œì¶œë¬¼)

#### 4.2.3 ì£¼ìš” ì •ì±… ê·œì¹™

**ìœ í•´ ì½˜í…ì¸  ê¸ˆì§€**:
*   í­ë ¥, í˜ì˜¤, ì°¨ë³„, ì„±ì  ë‚´ìš©, ì•½ë¬¼ ì‚¬ìš©, ìì‚´, ìí•´ ë“± ìœ í•´í•˜ê±°ë‚˜ ë¶ˆë²•ì ì¸ ì½˜í…ì¸  ê¸ˆì§€
*   ì •ì¹˜ì  ë˜ëŠ” ì¢…êµì  í¸í–¥ì„ ë“œëŸ¬ë‚´ëŠ” ì½˜í…ì¸  ê¸ˆì§€
*   íƒ€ì¸ì˜ ê°œì¸ ì •ë³´ ë˜ëŠ” ëª…ì˜ˆë¥¼ ì¹¨í•´í•˜ëŠ” ì½˜í…ì¸  ê¸ˆì§€

**ë¶€ì ì ˆí•œ ì–¸ì–´ ì‚¬ìš© ê¸ˆì§€**:
*   ìš•ì„¤, ë¹„ì†ì–´, ì€ì–´, ì°¨ë³„ì  í‘œí˜„ ë“± ë¶€ì ì ˆí•œ ì–¸ì–´ ì‚¬ìš© ê¸ˆì§€
*   ê³µê²©ì ì´ê±°ë‚˜ ìœ„í˜‘ì ì¸ ì–¸ì–´ ì‚¬ìš© ê¸ˆì§€

**ì—°ë ¹ ë¶€ì ì ˆ ì½˜í…ì¸  ì œí•œ**:
*   íŠ¹ì • ì—°ë ¹ëŒ€ì— ë¶€ì í•©í•œ ì£¼ì œ (ì˜ˆ: ì„±, í­ë ¥, í¡ì—°)ì— ëŒ€í•œ ì½˜í…ì¸  ì œí•œ
*   ë§Œ 13ì„¸ ë¯¸ë§Œ í•™ìƒ ëŒ€ìƒ ë°ì´í„° ìˆ˜ì§‘ ì‹œ COPPA ì¤€ìˆ˜

**í•™ìŠµ ë‚´ìš© ê´€ë ¨ì„±**:
*   ì½˜í…ì¸ ê°€ êµìœ¡ ê³¼ì • ë° í•™ìŠµ ëª©í‘œì™€ ê´€ë ¨ì„±ì´ ìˆì–´ì•¼ í•¨
*   í—ˆìœ„ ì •ë³´ ë˜ëŠ” ì˜¤í•´ë¥¼ ìœ ë°œí•  ìˆ˜ ìˆëŠ” ì½˜í…ì¸  ê¸ˆì§€

#### 4.2.4 Rego ì •ì±… êµ¬í˜„

**ê¸°ë³¸ ì½˜í…ì¸  ì•ˆì „ì„± ì •ì±…**:
```rego
package ai_content_safety

default allow = false

# AI ìƒì„± ì½˜í…ì¸ ëŠ” í•„í„°ë§ í†µê³¼ í•„ìˆ˜
allow {
    input.content_type == "ai_generated"
    input.safety_check.passed == true
    input.safety_check.score >= 0.8
}

# ìœ í•´ ì½˜í…ì¸  ì°¨ë‹¨
deny[msg] {
    input.content_type == "ai_generated"
    input.safety_check.passed != true
    msg := sprintf("Content blocked: safety score %v", [input.safety_check.score])
}

# ì—°ë ¹ë³„ ì½˜í…ì¸  ì œí•œ
deny[msg] {
    input.user.age < 13
    input.content.contains_sensitive_topics == true
    msg := "Age-inappropriate content blocked for user under 13"
}
```

**ìœ í•´ ì–¸ì–´ í•„í„°ë§ ì •ì±…**:
```rego
package content_language_filter

import future.keywords.contains
import future.keywords.if

default allow = false

# ê¸ˆì§€ ë‹¨ì–´ ëª©ë¡ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì™¸ë¶€ ë°ì´í„°ë¡œ ê´€ë¦¬)
prohibited_words := [
    "ìš•ì„¤1", "ë¹„ì†ì–´1", "ì°¨ë³„ì–´1", "í­ë ¥ì–´1"
]

# í…ìŠ¤íŠ¸ì— ê¸ˆì§€ ë‹¨ì–´ í¬í•¨ ì—¬ë¶€ í™•ì¸
contains_prohibited_language(text) if {
    some word in prohibited_words
    contains(lower(text), word)
}

# ê¸ˆì§€ ì–¸ì–´ ì—†ìœ¼ë©´ í—ˆìš©
allow {
    not contains_prohibited_language(input.content.text)
}

# ê¸ˆì§€ ì–¸ì–´ ë°œê²¬ ì‹œ ì°¨ë‹¨
deny[msg] {
    contains_prohibited_language(input.content.text)
    msg := "Content contains prohibited language"
}
```

**ì‚¬ìš©ì ì…ë ¥ ê²€ì—´ ì •ì±…**:
```rego
package user_input_moderation

import future.keywords.if

default allow = false

# ê°œì¸ì •ë³´ íŒ¨í„´ ê°ì§€
contains_personal_info(text) if {
    # ì „í™”ë²ˆí˜¸ íŒ¨í„´ (í•œêµ­)
    regex.match(`\d{3}-\d{4}-\d{4}`, text)
}

contains_personal_info(text) if {
    # ì´ë©”ì¼ íŒ¨í„´
    regex.match(`[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}`, text)
}

contains_personal_info(text) if {
    # ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸ íŒ¨í„´
    regex.match(`\d{6}-\d{7}`, text)
}

# ê°œì¸ì •ë³´ ì—†ìœ¼ë©´ í—ˆìš©
allow {
    not contains_personal_info(input.user_input)
}

# ê°œì¸ì •ë³´ í¬í•¨ ì‹œ ì°¨ë‹¨
deny[msg] {
    contains_personal_info(input.user_input)
    msg := "User input contains personal information"
}
```

#### 4.2.5 êµ¬í˜„ ë©”ì»¤ë‹ˆì¦˜

**1. ì‚¬ì „ í•™ìŠµ í•„í„° (Pre-training Filters)**

AI ëª¨ë¸ í•™ìŠµ ì‹œ, ìœ í•´í•˜ê±°ë‚˜ í¸í–¥ëœ ë°ì´í„°ëŠ” ì œì™¸í•˜ê³  í•™ìŠµí•©ë‹ˆë‹¤.

```python
# ai/training/data_filter.py
class TrainingDataFilter:
    def __init__(self, safety_threshold: float = 0.8):
        self.safety_threshold = safety_threshold
        self.safety_model = load_safety_classifier()
    
    def filter_training_data(self, dataset: List[dict]) -> List[dict]:
        """í•™ìŠµ ë°ì´í„°ì—ì„œ ìœ í•´ ì½˜í…ì¸  ì œê±°"""
        filtered_data = []
        
        for item in dataset:
            # ì•ˆì „ì„± ì ìˆ˜ ê³„ì‚°
            safety_score = self.safety_model.predict(item["content"])
            
            # ì •ì±… í‰ê°€
            policy_result = evaluate_policy("training_data_safety", {
                "content": item["content"],
                "safety_score": safety_score
            })
            
            if policy_result["allow"]:
                filtered_data.append(item)
            else:
                logger.warning(
                    f"Training data filtered: {policy_result['deny']}"
                )
        
        return filtered_data
    
    def fine_tune_with_ethical_data(self, model, ethical_dataset):
        """ìœ¤ë¦¬ì  ë°ì´í„°ë¡œ ëª¨ë¸ ë¯¸ì„¸ ì¡°ì •"""
        # ìœ¤ë¦¬ì  ê°€ì¹˜ë¥¼ ë°˜ì˜í•œ ë°ì´í„°ì…‹ìœ¼ë¡œ fine-tuning
        filtered_data = self.filter_training_data(ethical_dataset)
        model.train(filtered_data)
        return model
```

**2. ì‹¤ì‹œê°„ í•„í„° (Real-time Filters)**

AIê°€ ìƒì„±í•˜ëŠ” ì½˜í…ì¸ ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ë¶„ì„í•˜ê³ , ìœ í•´í•˜ê±°ë‚˜ ë¶€ì ì ˆí•œ ë‚´ìš©ì„ íƒì§€í•©ë‹ˆë‹¤.

```python
# ai/safety/realtime_filter.py
from transformers import pipeline
import re

class RealtimeContentFilter:
    def __init__(self):
        # NLP ê¸°ë°˜ ì•ˆì „ì„± ë¶„ë¥˜ê¸°
        self.text_classifier = pipeline(
            "text-classification",
            model="unitary/toxic-bert"
        )
        
        # ì´ë¯¸ì§€ ì•ˆì „ì„± ë¶„ë¥˜ê¸°
        self.image_classifier = pipeline(
            "image-classification",
            model="Falconsai/nsfw_image_detection"
        )
        
        # ê¸ˆì§€ ë‹¨ì–´ ëª©ë¡ (ì •ê·œ í‘œí˜„ì‹)
        self.prohibited_patterns = [
            r'\bìš•ì„¤\d+\b',
            r'\bë¹„ì†ì–´\d+\b',
            # ... ì¶”ê°€ íŒ¨í„´
        ]
    
    async def check_text_safety(self, text: str) -> dict:
        """í…ìŠ¤íŠ¸ ì•ˆì „ì„± ê²€ì‚¬"""
        # 1. NLP ëª¨ë¸ ê²€ì‚¬
        result = self.text_classifier(text)[0]
        
        # 2. íŒ¨í„´ ë§¤ì¹­ ê²€ì‚¬
        has_prohibited = any(
            re.search(pattern, text) 
            for pattern in self.prohibited_patterns
        )
        
        return {
            "passed": result["label"] == "SAFE" and not has_prohibited,
            "score": result["score"] if result["label"] == "SAFE" else 0.0,
            "toxic_type": result["label"] if result["label"] != "SAFE" else None,
            "prohibited_pattern_found": has_prohibited
        }
    
    async def check_image_safety(self, image_url: str) -> dict:
        """ì´ë¯¸ì§€ ì•ˆì „ì„± ê²€ì‚¬"""
        result = self.image_classifier(image_url)[0]
        
        return {
            "passed": result["label"] == "normal",
            "score": result["score"] if result["label"] == "normal" else 0.0,
            "nsfw_type": result["label"] if result["label"] != "normal" else None
        }
    
    async def check_video_safety(self, video_url: str) -> dict:
        """ë¹„ë””ì˜¤ ì•ˆì „ì„± ê²€ì‚¬ (í”„ë ˆì„ë³„ ì´ë¯¸ì§€ ë¶„ì„)"""
        # ë¹„ë””ì˜¤ë¥¼ í”„ë ˆì„ìœ¼ë¡œ ë¶„í• í•˜ì—¬ ê° í”„ë ˆì„ ê²€ì‚¬
        frames = extract_frames(video_url, interval=1.0)  # 1ì´ˆë§ˆë‹¤
        
        results = []
        for frame in frames:
            frame_result = await self.check_image_safety(frame)
            results.append(frame_result)
        
        # ëª¨ë“  í”„ë ˆì„ì´ ì•ˆì „í•´ì•¼ í†µê³¼
        all_passed = all(r["passed"] for r in results)
        avg_score = sum(r["score"] for r in results) / len(results)
        
        return {
            "passed": all_passed,
            "score": avg_score,
            "total_frames": len(frames),
            "unsafe_frames": [i for i, r in enumerate(results) if not r["passed"]]
        }
```

**3. ì½˜í…ì¸  ìˆ˜ì • ë° ì°¨ë‹¨**

ì •ì±… ì—”ì§„ì€ ìœ í•´ ì½˜í…ì¸  íƒì§€ ì‹œ, ì½˜í…ì¸ ë¥¼ ìë™ìœ¼ë¡œ ìˆ˜ì •í•˜ê±°ë‚˜ ì°¨ë‹¨í•©ë‹ˆë‹¤.

```python
# ai/content/moderator.py
async def generate_ai_content(prompt: str, user_id: str, user_age: int) -> str:
    """AI ì½˜í…ì¸  ìƒì„± ë° í•„í„°ë§"""
    # 1. AI ì½˜í…ì¸  ìƒì„±
    content = await ai_model.generate(prompt)
    
    # 2. ì•ˆì „ì„± ê²€ì‚¬
    safety_filter = RealtimeContentFilter()
    safety_result = await safety_filter.check_text_safety(content)
    
    # 3. ì •ì±… í‰ê°€
    policy_result = await evaluate_policy("ai_content_safety", {
        "content_type": "ai_generated",
        "safety_check": safety_result,
        "user_id": user_id,
        "user": {"age": user_age},
        "content": {"contains_sensitive_topics": check_sensitive_topics(content)}
    })
    
    if not policy_result["allow"]:
        # Slack ì•Œë¦¼
        await slack_notify(
            channel="#ai-safety-alerts",
            message=f"âš ï¸ AI content blocked for user {user_id}: {policy_result['deny']}"
        )
        
        # ê´€ë¦¬ì ê²€í†  ëŒ€ê¸°ì—´ì— ì¶”ê°€
        await add_to_review_queue({
            "content": content,
            "user_id": user_id,
            "reason": policy_result["deny"],
            "timestamp": datetime.now()
        })
        
        # ì‚¬ìš©ìì—ê²Œ ì•ˆì „í•œ ëŒ€ì²´ ë©”ì‹œì§€ ë°˜í™˜
        return "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ë‚´ìš©ì€ ì•ˆì „ì„± ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤. ë‹¤ë¥¸ ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”."
    
    return content

async def moderate_user_content(content: str, content_type: str, user_id: str) -> dict:
    """ì‚¬ìš©ì ìƒì„± ì½˜í…ì¸  ê²€ì—´"""
    safety_filter = RealtimeContentFilter()
    
    # ì½˜í…ì¸  íƒ€ì…ë³„ ê²€ì‚¬
    if content_type == "text":
        safety_result = await safety_filter.check_text_safety(content)
    elif content_type == "image":
        safety_result = await safety_filter.check_image_safety(content)
    elif content_type == "video":
        safety_result = await safety_filter.check_video_safety(content)
    else:
        raise ValueError(f"Unsupported content type: {content_type}")
    
    # ì •ì±… í‰ê°€
    policy_result = await evaluate_policy("user_content_moderation", {
        "content_type": content_type,
        "safety_check": safety_result,
        "user_id": user_id
    })
    
    return {
        "allowed": policy_result["allow"],
        "reason": policy_result.get("deny", [None])[0],
        "requires_review": not policy_result["allow"]
    }
```

**4. ì‚¬ìš©ì ì‹ ê³  ì‹œìŠ¤í…œ**

í•™ìƒ, êµì‚¬, í•™ë¶€ëª¨ëŠ” ë¶€ì ì ˆí•œ ì½˜í…ì¸ ë¥¼ ì‹ ê³ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
# api/routes/content_report.py
from fastapi import APIRouter, Depends
from pydantic import BaseModel

router = APIRouter()

class ContentReport(BaseModel):
    content_id: str
    content_type: str  # "ai_response", "forum_post", "assignment", etc.
    reason: str
    description: str

@router.post("/api/content/report")
async def report_content(
    report: ContentReport,
    current_user: User = Depends(get_current_user)
):
    """ë¶€ì ì ˆí•œ ì½˜í…ì¸  ì‹ ê³ """
    # 1. ì‹ ê³  ë‚´ìš© ì €ì¥
    report_id = await db.content_reports.insert_one({
        "content_id": report.content_id,
        "content_type": report.content_type,
        "reported_by": current_user.id,
        "reason": report.reason,
        "description": report.description,
        "status": "pending",
        "created_at": datetime.now()
    })
    
    # 2. ì½˜í…ì¸  ì„ì‹œ ìˆ¨ê¹€ ì²˜ë¦¬
    await db.contents.update_one(
        {"id": report.content_id},
        {"$set": {"hidden": True, "hidden_reason": "user_report"}}
    )
    
    # 3. ê´€ë¦¬ì ì•Œë¦¼
    await slack_notify(
        channel="#content-moderation",
        message=f"ğŸš¨ New content report: {report.content_type} - {report.reason}\n"
                f"Reporter: {current_user.name} ({current_user.role})\n"
                f"Review: /admin/reports/{report_id}"
    )
    
    # 4. ë©”íŠ¸ë¦­ ê¸°ë¡
    CONTENT_REPORTS.labels(
        content_type=report.content_type,
        reason=report.reason
    ).inc()
    
    return {
        "success": True,
        "report_id": str(report_id),
        "message": "ì‹ ê³ ê°€ ì ‘ìˆ˜ë˜ì—ˆìŠµë‹ˆë‹¤. ê´€ë¦¬ìê°€ ê²€í†  í›„ ì¡°ì¹˜í•  ì˜ˆì •ì…ë‹ˆë‹¤."
    }

@router.get("/api/admin/reports")
async def get_pending_reports(
    admin_user: User = Depends(require_admin)
):
    """ê´€ë¦¬ììš© ì‹ ê³  ëª©ë¡ ì¡°íšŒ"""
    reports = await db.content_reports.find(
        {"status": "pending"}
    ).sort("created_at", -1).to_list(100)
    
    return reports

@router.post("/api/admin/reports/{report_id}/resolve")
async def resolve_report(
    report_id: str,
    action: str,  # "remove", "restore", "warn_user"
    admin_user: User = Depends(require_admin)
):
    """ì‹ ê³  ì²˜ë¦¬"""
    report = await db.content_reports.find_one({"_id": ObjectId(report_id)})
    
    if action == "remove":
        # ì½˜í…ì¸  ì˜êµ¬ ì‚­ì œ
        await db.contents.delete_one({"id": report["content_id"]})
    elif action == "restore":
        # ì½˜í…ì¸  ë³µì›
        await db.contents.update_one(
            {"id": report["content_id"]},
            {"$set": {"hidden": False}}
        )
    elif action == "warn_user":
        # ì½˜í…ì¸  ì‘ì„±ìì—ê²Œ ê²½ê³ 
        content = await db.contents.find_one({"id": report["content_id"]})
        await send_warning(content["user_id"], report["reason"])
    
    # ì‹ ê³  ìƒíƒœ ì—…ë°ì´íŠ¸
    await db.content_reports.update_one(
        {"_id": ObjectId(report_id)},
        {"$set": {
            "status": "resolved",
            "action": action,
            "resolved_by": admin_user.id,
            "resolved_at": datetime.now()
        }}
    )
    
    return {"success": True}
```

#### 4.2.6 ì‚¬ìš©ì ì…ë ¥ ê²€ì—´

í•™ìƒ ì…ë ¥ì— ê¸ˆì§€ëœ ë‚´ìš© (ì˜ˆ: ìš•ì„¤, ê°œì¸ì •ë³´)ì´ ìˆìœ¼ë©´ ê²½ê³  ë˜ëŠ” ë¸”ë¡í•©ë‹ˆë‹¤.

```python
# api/middleware/input_filter.py
from fastapi import Request, HTTPException
import re

class UserInputFilterMiddleware:
    async def __call__(self, request: Request, call_next):
        # POST/PUT ìš”ì²­ì˜ body ê²€ì‚¬
        if request.method in ["POST", "PUT", "PATCH"]:
            body = await request.body()
            body_str = body.decode('utf-8')
            
            # ì •ì±… í‰ê°€
            policy_result = await evaluate_policy("user_input_moderation", {
                "user_input": body_str
            })
            
            if not policy_result["allow"]:
                # ìœ„ë°˜ ë©”íŠ¸ë¦­ ê¸°ë¡
                USER_INPUT_VIOLATIONS.labels(
                    reason=policy_result["deny"][0]
                ).inc()
                
                # ê²½ê³  ë°˜í™˜
                raise HTTPException(
                    status_code=400,
                    detail={
                        "error": "Input validation failed",
                        "reason": policy_result["deny"][0],
                        "message": "ì…ë ¥ ë‚´ìš©ì— ë¶€ì ì ˆí•œ ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
                    }
                )
        
        response = await call_next(request)
        return response

# ì• í”Œë¦¬ì¼€ì´ì…˜ì— ë¯¸ë“¤ì›¨ì–´ ì¶”ê°€
app.middleware("http")(UserInputFilterMiddleware())
```

**ë°˜ë³µ ìœ„ë°˜ ì²˜ë¦¬**:
```python
# api/services/violation_tracker.py
class ViolationTracker:
    def __init__(self, redis_client):
        self.redis = redis_client
    
    async def record_violation(self, user_id: str, violation_type: str):
        """ìœ„ë°˜ ê¸°ë¡"""
        key = f"violations:{user_id}:{violation_type}"
        count = await self.redis.incr(key)
        await self.redis.expire(key, 86400)  # 24ì‹œê°„ TTL
        
        # ìœ„ë°˜ íšŸìˆ˜ì— ë”°ë¥¸ ì¡°ì¹˜
        if count >= 3:
            await self.suspend_user(user_id, duration=3600)  # 1ì‹œê°„ ì •ì§€
            await slack_notify(
                channel="#security-alerts",
                message=f"âš ï¸ User {user_id} suspended: 3+ {violation_type} violations"
            )
        elif count >= 5:
            await self.ban_user(user_id)  # ì˜êµ¬ ì°¨ë‹¨
            await slack_notify(
                channel="#security-alerts",
                message=f"ğŸš« User {user_id} banned: 5+ {violation_type} violations"
            )
        
        return count
    
    async def suspend_user(self, user_id: str, duration: int):
        """ì‚¬ìš©ì ì¼ì‹œ ì •ì§€"""
        await db.users.update_one(
            {"id": user_id},
            {"$set": {
                "suspended": True,
                "suspended_until": datetime.now() + timedelta(seconds=duration),
                "suspended_reason": "repeated_violations"
            }}
        )
    
    async def ban_user(self, user_id: str):
        """ì‚¬ìš©ì ì˜êµ¬ ì°¨ë‹¨"""
        await db.users.update_one(
            {"id": user_id},
            {"$set": {
                "banned": True,
                "banned_at": datetime.now(),
                "banned_reason": "severe_repeated_violations"
            }}
        )
```

#### 4.2.7 ëª¨ë‹ˆí„°ë§ ë° ê°ì‚¬

**ë¡œê·¸ ê¸°ë¡**:
```python
# ëª¨ë“  ì½˜í…ì¸  í•„í„°ë§ í™œë™ ìƒì„¸ ê¸°ë¡
logger.info(
    "Content safety check",
    extra={
        "content_type": content_type,
        "user_id": user_id,
        "safety_score": safety_result["score"],
        "passed": safety_result["passed"],
        "decision": "allow" if policy_result["allow"] else "deny",
        "toxic_type": safety_result.get("toxic_type"),
        "timestamp": datetime.now().isoformat()
    }
)
```

**Prometheus ë©”íŠ¸ë¦­**:
```python
# governance/backend/metrics.py
CONTENT_SAFETY_CHECKS = Counter(
    'content_safety_checks_total',
    'Total content safety checks',
    ['content_type', 'decision']
)

CONTENT_SAFETY_SCORE = Histogram(
    'content_safety_score',
    'Content safety scores',
    ['content_type'],
    buckets=[0.1, 0.3, 0.5, 0.7, 0.8, 0.9, 0.95, 1.0]
)

CONTENT_REPORTS = Counter(
    'content_reports_total',
    'Total content reports',
    ['content_type', 'reason']
)

USER_INPUT_VIOLATIONS = Counter(
    'user_input_violations_total',
    'Total user input violations',
    ['reason']
)
```

**ì •ê¸°ì ì¸ ê°ì‚¬**:
```python
# scripts/audit_content_policies.py
async def audit_content_policies():
    """ì½˜í…ì¸  ì •ì±… íš¨ê³¼ì„± ê°ì‚¬"""
    # 1. ìµœê·¼ 30ì¼ê°„ ì°¨ë‹¨ëœ ì½˜í…ì¸  ë¶„ì„
    blocked_contents = await db.audit_logs.find({
        "event": "content_blocked",
        "timestamp": {"$gte": datetime.now() - timedelta(days=30)}
    }).to_list(None)
    
    # 2. ì°¨ë‹¨ ì‚¬ìœ  í†µê³„
    block_reasons = {}
    for log in blocked_contents:
        reason = log["reason"]
        block_reasons[reason] = block_reasons.get(reason, 0) + 1
    
    # 3. ì˜¤íƒì§€ìœ¨ ê³„ì‚° (ë³µì›ëœ ì½˜í…ì¸  ë¹„ìœ¨)
    restored = await db.contents.count_documents({
        "hidden": False,
        "hidden_reason": "user_report",
        "restored_at": {"$gte": datetime.now() - timedelta(days=30)}
    })
    
    false_positive_rate = restored / len(blocked_contents) if blocked_contents else 0
    
    # 4. ë³´ê³ ì„œ ìƒì„±
    report = {
        "period": "last_30_days",
        "total_blocked": len(blocked_contents),
        "block_reasons": block_reasons,
        "false_positive_rate": false_positive_rate,
        "recommendations": []
    }
    
    # 5. ê°œì„  ê¶Œì¥ì‚¬í•­
    if false_positive_rate > 0.1:
        report["recommendations"].append(
            "High false positive rate detected. Review filtering thresholds."
        )
    
    return report
```

DreamSeedAIëŠ” ìœ„ì™€ ê°™ì€ í¬ê´„ì ì¸ ì½˜í…ì¸  ì •ì±…ì„ í†µí•´ í•™ìƒë“¤ì—ê²Œ ì•ˆì „í•˜ê³  ìœ¤ë¦¬ì ì¸ í•™ìŠµ í™˜ê²½ì„ ì œê³µí•©ë‹ˆë‹¤.

### 4.3 ì ‘ê·¼ ì œì–´ ì •ì±… (Access Control Policies)

ì ‘ê·¼ ì œì–´ ì •ì±…ì€ DreamSeedAIì—ì„œ ëˆ„ê°€ ì–´ë–¤ ë°ì´í„°ì™€ ê¸°ëŠ¥ì— ì ‘ê·¼í•  ìˆ˜ ìˆëŠ”ì§€ ì •ì˜í•œ í•µì‹¬ ê·œì¹™ì…ë‹ˆë‹¤.

#### 4.3.1 ê¸°ë³¸ ì›ì¹™

*   **ìµœì†Œ ê¶Œí•œ ì›ì¹™ (Principle of Least Privilege)**: ì‚¬ìš©ìì—ê²Œ í•„ìš”í•œ ìµœì†Œí•œì˜ ê¶Œí•œë§Œ ë¶€ì—¬í•©ë‹ˆë‹¤.
*   **ì—­í•  ê¸°ë°˜ ì ‘ê·¼ ì œì–´ (Role-Based Access Control, RBAC)**: ì‚¬ìš©ìì—ê²Œ ì—­í• ì„ ë¶€ì—¬í•˜ê³ , ì—­í• ì— ë”°ë¼ ê¶Œí•œì„ ì œì–´í•©ë‹ˆë‹¤.
*   **ëª…ì‹œì  ê±°ë¶€ (Explicit Deny)**: íŠ¹ì • ì‚¬ìš©ìì— ëŒ€í•œ ì ‘ê·¼ì„ ëª…ì‹œì ìœ¼ë¡œ ê±°ë¶€í•˜ëŠ” ê·œì¹™ì„ ì„¤ì •í•©ë‹ˆë‹¤.
*   **ì§ë¬´ ë¶„ë¦¬ (Separation of Duties)**: ë¯¼ê°í•œ ì‘ì—…ì€ ì—¬ëŸ¬ ì—­í• ë¡œ ë¶„ë¦¬í•˜ì—¬ ë‹¨ì¼ ì‚¬ìš©ìê°€ ì „ì²´ í”„ë¡œì„¸ìŠ¤ë¥¼ ì œì–´í•  ìˆ˜ ì—†ë„ë¡ í•©ë‹ˆë‹¤.

#### 4.3.2 ì—­í• ë³„ ì ‘ê·¼ ê¶Œí•œ

**í•™ìƒ (Student)**:
*   ìì‹ ì˜ í•™ìŠµ ë°ì´í„°ë§Œ ì—´ëŒ ê°€ëŠ¥
*   ìì‹ ì˜ í•™ìŠµ í™œë™ ê¸°ë¡ ì¡°íšŒ
*   ìì‹ ì˜ ì„±ì  ë° ì§„ë„ í™•ì¸
*   í• ë‹¹ëœ í•™ìŠµ ì½˜í…ì¸  ì ‘ê·¼

**êµì‚¬ (Teacher)**:
*   ìì‹ ì´ ë‹´ë‹¹í•˜ëŠ” í•™ê¸‰ì˜ í•™ìƒ ë°ì´í„° ì—´ëŒ
*   ë‹´ë‹¹ í•™ê¸‰ ì„±ì  ë°ì´í„° ì¡°íšŒ ë° ë¶„ì„
*   í•™ìŠµ ì½˜í…ì¸  ê´€ë¦¬ (ìƒì„±, ìˆ˜ì •, ì‚­ì œ)
*   í•™ìƒ í•™ìŠµ í™œë™ ëª¨ë‹ˆí„°ë§

**í•™ë¶€ëª¨ (Parent)**:
*   ìë…€ì˜ í•™ìŠµ ë°ì´í„° ì—´ëŒ
*   ìë…€ì˜ ì„±ì  ë° ì§„ë„ í™•ì¸
*   êµì‚¬ì™€ì˜ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ê¸°ë¡ ì¡°íšŒ

**ê´€ë¦¬ì (Administrator)**:
*   ì‹œìŠ¤í…œì˜ ëª¨ë“  ë°ì´í„° ì ‘ê·¼
*   ëª¨ë“  ê¸°ëŠ¥ ì‚¬ìš© ê¶Œí•œ
*   ì‚¬ìš©ì ê´€ë¦¬ (ìƒì„±, ìˆ˜ì •, ì‚­ì œ)
*   ì‹œìŠ¤í…œ ì„¤ì • ë³€ê²½

#### 4.3.3 ê·œì¹™ ì˜ˆì‹œ: êµì‚¬ì˜ í•™ê¸‰ë³„ ì ‘ê·¼ ì œì–´

**ê·œì¹™**: êµì‚¬ëŠ” ìì‹ ì´ ë‹´ë‹¹í•˜ëŠ” í•™ê¸‰ì˜ í•™ìƒ ë°ì´í„°ì—ë§Œ ì ‘ê·¼í•  ìˆ˜ ìˆë‹¤.

**Rego ì •ì±…**:
```rego
package student_data_access

default allow = false

# í•™ìƒì€ ìì‹ ì˜ ë°ì´í„°ë§Œ ì ‘ê·¼ ê°€ëŠ¥
allow {
    input.user.role == "student"
    input.student.id == input.user.id
}

# êµì‚¬ëŠ” ë‹´ë‹¹ í•™ê¸‰ í•™ìƒë§Œ ì ‘ê·¼ ê°€ëŠ¥
allow {
    input.user.role == "teacher"
    input.student.class_id == input.user.class_id
}

# í•™ë¶€ëª¨ëŠ” ìë…€ ë°ì´í„°ë§Œ ì ‘ê·¼ ê°€ëŠ¥
allow {
    input.user.role == "parent"
    input.student.id in input.user.children_ids
}

# ê´€ë¦¬ìëŠ” ëª¨ë“  í•™ìƒ ë°ì´í„° ì ‘ê·¼ ê°€ëŠ¥
allow {
    input.user.role == "admin"
}

# ì ‘ê·¼ ê±°ë¶€ ì‚¬ìœ  (í•™ìƒ)
deny[msg] {
    input.user.role == "student"
    input.student.id != input.user.id
    msg := "Students can only access their own data"
}

# ì ‘ê·¼ ê±°ë¶€ ì‚¬ìœ  (êµì‚¬)
deny[msg] {
    input.user.role == "teacher"
    input.student.class_id != input.user.class_id
    msg := sprintf("Teacher can only access students in class %s", [input.user.class_id])
}

# ì ‘ê·¼ ê±°ë¶€ ì‚¬ìœ  (í•™ë¶€ëª¨)
deny[msg] {
    input.user.role == "parent"
    not (input.student.id in input.user.children_ids)
    msg := "Parents can only access their children's data"
}
```

**ì•¡ì…˜**:
*   êµì‚¬ì˜ ë°ì´í„° ì ‘ê·¼ ìš”ì²­ ì‹œ, í•™ê¸‰ IDë¥¼ ê²€ì‚¬í•˜ì—¬ ì ‘ê·¼ ê¶Œí•œ í™•ì¸
*   ê±°ë¶€ ì‹œ HTTP 403 ì‘ë‹µ
*   ê°ì‚¬ ë¡œê·¸: ì ‘ê·¼ ì‹œë„ ê¸°ë¡

**êµ¬í˜„**:
```python
@app.get("/api/students/{student_id}/data")
async def get_student_data(
    student_id: int,
    current_user: User = Depends(get_current_user)
):
    # í•™ìƒ ì •ë³´ ì¡°íšŒ
    student = await db.get_student(student_id)
    
    # ì •ì±… í‰ê°€
    policy_result = await evaluate_policy("student_data_access", {
        "user": {
            "id": current_user.id,
            "role": current_user.role,
            "class_id": current_user.class_id,
            "children_ids": current_user.children_ids
        },
        "student": {
            "id": student.id,
            "class_id": student.class_id
        }
    })
    
    if not policy_result["allow"]:
        raise HTTPException(status_code=403, detail=policy_result["deny"])
    
    return student.data
```

#### 4.3.4 ì •ì±… ì‹œí–‰ ë©”ì»¤ë‹ˆì¦˜ (Policy Enforcement Mechanisms)

ì •ì±…ì€ ë‹¤ì¸µ ë°©ì–´(Defense in Depth) ì „ëµìœ¼ë¡œ ì—¬ëŸ¬ ê³„ì¸µì—ì„œ ì‹œí–‰ë©ë‹ˆë‹¤.

##### 1ï¸âƒ£ API Gateway ìˆ˜ì¤€

**ì—­í• **: ëª¨ë“  API í˜¸ì¶œì˜ ì§„ì…ì ì—ì„œ ì¸ì¦ ë° ê¶Œí•œ ê²€ì‚¬

**êµ¬í˜„**:
```python
# governance/backend/policy_middleware.py
@app.middleware("http")
async def policy_enforcement_middleware(request: Request, call_next):
    # 1. ì‚¬ìš©ì ì¸ì¦ í™•ì¸
    user = await authenticate_user(request)
    if not user:
        return JSONResponse(
            status_code=401,
            content={"error": "Unauthorized"}
        )
    
    # 2. ìš”ì²­ ê²½ë¡œì— í•´ë‹¹í•˜ëŠ” ì •ì±… ê²€ìƒ‰
    policy_name = get_policy_for_route(request.url.path)
    
    # 3. ì •ì±… í‰ê°€
    if policy_name:
        policy_result = await evaluate_policy(policy_name, {
            "user": user.dict(),
            "request": {
                "method": request.method,
                "path": request.url.path,
                "query": dict(request.query_params)
            }
        })
        
        # 4. ì ‘ê·¼ ê±°ë¶€
        if not policy_result["allow"]:
            GOVERNANCE_DENY.labels(
                policy=policy_name,
                reason=policy_result.get("deny", ["unknown"])[0]
            ).inc()
            
            return JSONResponse(
                status_code=403,
                content={
                    "error": "Access denied",
                    "reason": policy_result["deny"]
                }
            )
    
    # 5. ìš”ì²­ ê³„ì† ì§„í–‰
    response = await call_next(request)
    return response
```

**íŠ¹ì§•**:
*   ëª¨ë“  API ìš”ì²­ì— ëŒ€í•œ ì¤‘ì•™ ì§‘ì¤‘ì‹ ì •ì±… í‰ê°€
*   ê¶Œí•œì´ ì—†ëŠ” ìš”ì²­ì€ ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œì§ ì‹¤í–‰ ì „ì— ì°¨ë‹¨
*   Prometheus ë©”íŠ¸ë¦­ìœ¼ë¡œ ì •ì±… ê±°ë¶€ ì¶”ì 

##### 2ï¸âƒ£ UI ì œì–´ ìˆ˜ì¤€

**ì—­í• **: ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ì—ì„œ ê¶Œí•œì´ ì—†ëŠ” ê¸°ëŠ¥ ìˆ¨ê¹€/ë¹„í™œì„±í™”

**êµ¬í˜„ (React ì˜ˆì‹œ)**:
```typescript
// frontend/components/StudentDataView.tsx
import { usePermission } from '@/hooks/usePermission';

function StudentDataView({ studentId }: Props) {
  const { hasPermission, loading } = usePermission('student_data_access', {
    user: currentUser,
    student: { id: studentId }
  });
  
  if (loading) return <Spinner />;
  
  // ê¶Œí•œì´ ì—†ìœ¼ë©´ ì»´í¬ë„ŒíŠ¸ ìì²´ë¥¼ ë Œë”ë§í•˜ì§€ ì•ŠìŒ
  if (!hasPermission) {
    return <AccessDenied message="You don't have permission to view this student's data" />;
  }
  
  return (
    <div>
      {/* í•™ìƒ ë°ì´í„° í‘œì‹œ */}
      <StudentProfile studentId={studentId} />
      <StudentGrades studentId={studentId} />
    </div>
  );
}

// ì¡°ê±´ë¶€ ë²„íŠ¼ ë Œë”ë§
function AdminPanel() {
  const { hasRole } = useAuth();
  
  return (
    <div>
      {hasRole('admin') && (
        <Button onClick={handleDeleteUser}>Delete User</Button>
      )}
      {hasRole(['admin', 'teacher']) && (
        <Button onClick={handleExportData}>Export Data</Button>
      )}
    </div>
  );
}
```

**íŠ¹ì§•**:
*   ì‚¬ìš©ì ê²½í—˜ í–¥ìƒ (ê¶Œí•œ ì—†ëŠ” ê¸°ëŠ¥ì€ ë³´ì´ì§€ ì•ŠìŒ)
*   ë³´ì•ˆ ê°•í™” (í´ë¼ì´ì–¸íŠ¸ ì¸¡ ì¶”ê°€ ê²€ì¦)
*   ì£¼ì˜: UI ì œì–´ë§Œìœ¼ë¡œëŠ” ì¶©ë¶„í•˜ì§€ ì•Šìœ¼ë©°, ì„œë²„ ì¸¡ ê²€ì¦ í•„ìˆ˜

##### 3ï¸âƒ£ ë°ì´í„°ë² ì´ìŠ¤ ì ‘ê·¼ ì œì–´ ìˆ˜ì¤€

**ì—­í• **: ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ì‹œ ì—­í• ê³¼ ì¡°ì§ ID ê¸°ë°˜ ë°ì´í„° í•„í„°ë§

**êµ¬í˜„ (SQLAlchemy ì˜ˆì‹œ)**:
```python
# models/student.py
from sqlalchemy import select
from sqlalchemy.orm import Session

class StudentRepository:
    def get_students_by_permission(
        self,
        db: Session,
        current_user: User
    ) -> list[Student]:
        """ì‚¬ìš©ì ê¶Œí•œì— ë”°ë¼ ì ‘ê·¼ ê°€ëŠ¥í•œ í•™ìƒ ëª©ë¡ ë°˜í™˜"""
        query = select(Student)
        
        # í•™ìƒ: ìì‹ ë§Œ
        if current_user.role == "student":
            query = query.where(Student.id == current_user.id)
        
        # êµì‚¬: ë‹´ë‹¹ í•™ê¸‰ë§Œ
        elif current_user.role == "teacher":
            query = query.where(Student.class_id == current_user.class_id)
        
        # í•™ë¶€ëª¨: ìë…€ë§Œ
        elif current_user.role == "parent":
            query = query.where(Student.id.in_(current_user.children_ids))
        
        # ê´€ë¦¬ì: ëª¨ë‘
        elif current_user.role == "admin":
            pass  # í•„í„°ë§ ì—†ìŒ
        
        else:
            # ì•Œ ìˆ˜ ì—†ëŠ” ì—­í• : ë¹ˆ ê²°ê³¼ ë°˜í™˜
            query = query.where(Student.id == -1)
        
        return db.execute(query).scalars().all()
```

**Row-Level Security (PostgreSQL)**:
```sql
-- Row-Level Security í™œì„±í™”
ALTER TABLE students ENABLE ROW LEVEL SECURITY;

-- í•™ìƒì€ ìì‹ ì˜ ë°ì´í„°ë§Œ ì¡°íšŒ
CREATE POLICY student_own_data ON students
    FOR SELECT
    TO student_role
    USING (id = current_user_id());

-- êµì‚¬ëŠ” ë‹´ë‹¹ í•™ê¸‰ë§Œ ì¡°íšŒ
CREATE POLICY teacher_class_data ON students
    FOR SELECT
    TO teacher_role
    USING (class_id = current_user_class_id());

-- ê´€ë¦¬ìëŠ” ëª¨ë‘ ì¡°íšŒ
CREATE POLICY admin_all_data ON students
    FOR ALL
    TO admin_role
    USING (true);
```

**íŠ¹ì§•**:
*   ë°ì´í„°ë² ì´ìŠ¤ ë ˆë²¨ì—ì„œ ì¶”ê°€ ë³´ì•ˆ ê³„ì¸µ
*   ì• í”Œë¦¬ì¼€ì´ì…˜ ë²„ê·¸ë¡œ ì¸í•œ ë°ì´í„° ìœ ì¶œ ë°©ì§€
*   PostgreSQL RLS, MySQL ë·°, MongoDB Document-Level Security í™œìš©

##### 4ï¸âƒ£ ì½”ë“œ ê¸°ë°˜ ê²€ì‚¬ ìˆ˜ì¤€

**ì—­í• **: í•µì‹¬ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì—ì„œ ëª…ì‹œì  ê¶Œí•œ í™•ì¸

**êµ¬í˜„**:
```python
# services/grade_service.py
class GradeService:
    async def update_grade(
        self,
        student_id: int,
        grade_data: dict,
        current_user: User
    ) -> Grade:
        """ì„±ì  ì—…ë°ì´íŠ¸ (ëª…ì‹œì  ê¶Œí•œ ê²€ì‚¬)"""
        
        # 1. í•™ìƒ ì •ë³´ ì¡°íšŒ
        student = await self.student_repo.get(student_id)
        if not student:
            raise HTTPException(status_code=404, detail="Student not found")
        
        # 2. ê¶Œí•œ ê²€ì‚¬ (ëª…ì‹œì )
        if current_user.role == "teacher":
            # êµì‚¬ëŠ” ë‹´ë‹¹ í•™ê¸‰ë§Œ
            if student.class_id != current_user.class_id:
                raise HTTPException(
                    status_code=403,
                    detail=f"Teacher can only update grades for class {current_user.class_id}"
                )
        elif current_user.role == "admin":
            # ê´€ë¦¬ìëŠ” ëª¨ë‘ í—ˆìš©
            pass
        else:
            # ê¸°íƒ€ ì—­í• ì€ ê±°ë¶€
            raise HTTPException(
                status_code=403,
                detail=f"Role {current_user.role} cannot update grades"
            )
        
        # 3. ì •ì±… í‰ê°€ (OPA ì´ì¤‘ ê²€ì¦)
        policy_result = await evaluate_policy("grade_update", {
            "user": current_user.dict(),
            "student": student.dict(),
            "grade_data": grade_data
        })
        
        if not policy_result["allow"]:
            raise HTTPException(
                status_code=403,
                detail=policy_result["deny"]
            )
        
        # 4. ì„±ì  ì—…ë°ì´íŠ¸ ì‹¤í–‰
        grade = await self.grade_repo.update(student_id, grade_data)
        
        # 5. ê°ì‚¬ ë¡œê·¸
        await self.audit_log.create({
            "action": "grade_update",
            "user_id": current_user.id,
            "student_id": student_id,
            "timestamp": datetime.utcnow()
        })
        
        return grade
```

**íŠ¹ì§•**:
*   ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ìˆ˜ì¤€ì—ì„œ ìµœì¢… ê¶Œí•œ ê²€ì‚¬
*   OPA ì •ì±…ê³¼ ì½”ë“œ ê²€ì‚¬ ì´ì¤‘ ê²€ì¦
*   ëª…ì‹œì  ì˜ˆì™¸ ì²˜ë¦¬ë¡œ ë³´ì•ˆ ê°•í™”

##### 5ï¸âƒ£ ê°ì‚¬ ë¡œê¹…

**ì—­í• **: ëª¨ë“  ì •ì±… ì‹œí–‰ í™œë™ ê¸°ë¡ ë° ì¶”ì 

**êµ¬í˜„**:
```python
# services/audit_service.py
class AuditService:
    async def log_access_attempt(
        self,
        user_id: str,
        resource: str,
        action: str,
        allowed: bool,
        reason: Optional[str] = None
    ):
        """ì ‘ê·¼ ì‹œë„ ê°ì‚¬ ë¡œê·¸ ê¸°ë¡"""
        await self.db.audit_logs.insert_one({
            "timestamp": datetime.utcnow(),
            "user_id": user_id,
            "resource": resource,
            "action": action,
            "allowed": allowed,
            "reason": reason,
            "ip_address": get_client_ip(),
            "user_agent": get_user_agent()
        })
        
        # Prometheus ë©”íŠ¸ë¦­
        AUDIT_LOG.labels(
            action=action,
            resource=resource,
            result="allowed" if allowed else "denied"
        ).inc()
```

**ê°ì‚¬ ë¡œê·¸ ì¡°íšŒ**:
```python
# íŠ¹ì • ì‚¬ìš©ìì˜ ì ‘ê·¼ ê±°ë¶€ ì´ë ¥ ì¡°íšŒ
denied_accesses = await audit_service.query({
    "user_id": "user123",
    "allowed": False,
    "timestamp": {"$gte": datetime.utcnow() - timedelta(days=7)}
})

# ë¯¼ê°í•œ ë°ì´í„° ì ‘ê·¼ ì´ë ¥ ì¡°íšŒ
sensitive_accesses = await audit_service.query({
    "resource": {"$in": ["student_data", "grade_data"]},
    "timestamp": {"$gte": datetime.utcnow() - timedelta(hours=1)}
})
```

#### 4.3.5 ë‹¤ì¸µ ë°©ì–´ ì „ëµ ìš”ì•½

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer 1: API Gateway (ì •ì±… ë¯¸ë“¤ì›¨ì–´)                         â”‚
â”‚  â†’ ëª¨ë“  ìš”ì²­ ì§„ì…ì ì—ì„œ ì •ì±… í‰ê°€                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Layer 2: UI ì œì–´                                            â”‚
â”‚  â†’ ê¶Œí•œ ì—†ëŠ” ê¸°ëŠ¥ ìˆ¨ê¹€/ë¹„í™œì„±í™”                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Layer 3: ë°ì´í„°ë² ì´ìŠ¤ ì ‘ê·¼ ì œì–´                               â”‚
â”‚  â†’ Row-Level Security, ì¿¼ë¦¬ í•„í„°ë§                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Layer 4: ì½”ë“œ ê¸°ë°˜ ê²€ì‚¬                                      â”‚
â”‚  â†’ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì—ì„œ ëª…ì‹œì  ê¶Œí•œ í™•ì¸                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Layer 5: ê°ì‚¬ ë¡œê¹…                                           â”‚
â”‚  â†’ ëª¨ë“  ì ‘ê·¼ ì‹œë„ ê¸°ë¡ ë° ì¶”ì                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ì´ì **:
*   **ì‹¬ì¸µ ë°©ì–´**: í•œ ê³„ì¸µì´ ëš«ë ¤ë„ ë‹¤ë¥¸ ê³„ì¸µì—ì„œ ì°¨ë‹¨
*   **ì¡°ê¸° ì°¨ë‹¨**: API Gatewayì—ì„œ ëŒ€ë¶€ë¶„ì˜ ë¶ˆë²• ìš”ì²­ ì°¨ë‹¨
*   **ê°ì‚¬ ê°€ëŠ¥ì„±**: ëª¨ë“  ì ‘ê·¼ ì‹œë„ ì¶”ì 
*   **ë³´ì•ˆ ê°•í™”**: ì—¬ëŸ¬ ê²€ì¦ ë‹¨ê³„ë¡œ ë³´ì•ˆ ì·¨ì•½ì  ìµœì†Œí™”

### 4.4 í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ ì •ì±…

**ê·œì¹™**: ìƒˆë¡œìš´ AI ëª¨ë¸ì€ ì„±ëŠ¥ í‰ê°€ë¥¼ í†µê³¼í•œ í›„ì—ë§Œ í”„ë¡œë•ì…˜ì— ë°°í¬í•  ìˆ˜ ìˆë‹¤.

**Rego ì •ì±…**:
```rego
package ai_model_deployment

default allow = false

# AI ëª¨ë¸ ë°°í¬ ê¸°ì¤€
allow {
    input.model.evaluation.accuracy >= 0.85
    input.model.evaluation.fairness_score >= 0.9
    input.model.evaluation.samples >= 10000
    input.model.approval_status == "approved"
}

# ë°°í¬ ê±°ë¶€ ì‚¬ìœ 
deny[msg] {
    input.model.evaluation.accuracy < 0.85
    msg := sprintf("Model accuracy %v below threshold 0.85", [input.model.evaluation.accuracy])
}

deny[msg] {
    input.model.evaluation.fairness_score < 0.9
    msg := sprintf("Model fairness score %v below threshold 0.9", [input.model.evaluation.fairness_score])
}

deny[msg] {
    input.model.approval_status != "approved"
    msg := "Model requires approval before deployment"
}
```

**ì•¡ì…˜**:
*   ì„±ëŠ¥ í‰ê°€ í†µê³¼ ì‹œ: í”„ë¡œë•ì…˜ ë°°í¬
*   ì„±ëŠ¥ ë¯¸ë‹¬ ì‹œ: ë°°í¬ ì¤‘ë‹¨, ê°œë°œíŒ€ ì•Œë¦¼
*   ìŠ¹ì¸ ëŒ€ê¸° ì¤‘: ìŠ¹ì¸ ìš”ì²­ ì•Œë¦¼

**êµ¬í˜„**:
```python
async def deploy_ai_model(model_id: str, evaluation_results: dict):
    # ì •ì±… í‰ê°€
    policy_result = await evaluate_policy("ai_model_deployment", {
        "model": {
            "id": model_id,
            "evaluation": evaluation_results,
            "approval_status": await get_approval_status(model_id)
        }
    })
    
    if not policy_result["allow"]:
        # Slack ì•Œë¦¼
        await slack_notify(
            channel="#ml-ops",
            message=f"ğŸš« Model {model_id} deployment blocked: {policy_result['deny']}"
        )
        raise ValueError(f"Model deployment blocked: {policy_result['deny']}")
    
    # ë°°í¬ ì§„í–‰
    await kubernetes.deploy_model(model_id, environment="production")
    
    # ì„±ê³µ ì•Œë¦¼
    await slack_notify(
        channel="#ml-ops",
        message=f"âœ… Model {model_id} deployed to production"
    )
```

### 4.5 AI í–‰ë™ ì •ì±… (AI Behavior Policies)

AI í–‰ë™ ì •ì±…ì€ DreamSeedAIì—ì„œ AI ëª¨ë¸ì˜ í–‰ë™ ì˜ì—­ê³¼ í•œê³„ë¥¼ ëª…í™•íˆ ì •ì˜í•˜ëŠ” ê·œì¹™ë“¤ì„ í¬í•¨í•©ë‹ˆë‹¤. ì´ ì •ì±…ì€ AIê°€ êµìœ¡ì  ëª©ì ì— ë¶€í•©í•˜ê³ , ìœ¤ë¦¬ì  ë° ë²•ì  ê¸°ì¤€ì„ ì¤€ìˆ˜í•˜ë©°, ì‚¬ìš©ìì—ê²Œ ì•ˆì „í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ë„ë¡ ë³´ì¥í•˜ëŠ” ë° í•µì‹¬ì ì¸ ì—­í• ì„ í•©ë‹ˆë‹¤.

#### 4.5.1 ëª©í‘œ

*   **ìœ¤ë¦¬ì  AI ì‚¬ìš©**: AI ëª¨ë¸ì´ DreamSeedAIì˜ í•µì‹¬ ê°€ì¹˜ì™€ ìœ¤ë¦¬ ì›ì¹™ì„ ì¤€ìˆ˜í•˜ë„ë¡ í•©ë‹ˆë‹¤.
*   **ì•ˆì „í•œ ì‚¬ìš©ì ê²½í—˜**: AI ëª¨ë¸ì´ ìœ í•´í•˜ê±°ë‚˜ ë¶€ì ì ˆí•œ ì½˜í…ì¸ ë¥¼ ìƒì„±í•˜ì§€ ì•Šë„ë¡ í•©ë‹ˆë‹¤.
*   **í•™ìŠµ ëª©í‘œ ì§‘ì¤‘**: AI ëª¨ë¸ì´ í•™ìŠµ í™œë™ê³¼ ê´€ë ¨ëœ ì§ˆë¬¸ì—ë§Œ ì‘ë‹µí•˜ê³ , í•™ìƒë“¤ì˜ í•™ìŠµì— ì§‘ì¤‘í•˜ë„ë¡ ì§€ì›í•©ë‹ˆë‹¤.
*   **ì „ë¬¸ ë¶„ì•¼ ì¡´ì¤‘**: AI ëª¨ë¸ì´ ì „ë¬¸ì ì¸ ì§€ì‹ (ì˜í•™, ë²•ë¥  ë“±)ì„ ì œê³µí•˜ëŠ” ê²ƒì„ ì œí•œí•˜ê³ , ì „ë¬¸ê°€ì˜ ë„ì›€ì„ ë°›ë„ë¡ ì•ˆë‚´í•©ë‹ˆë‹¤.

#### 4.5.2 ì£¼ìš” ì •ì±… ê·œì¹™

**í•™ìŠµ ëª©ì  ì™¸ ëŒ€í™” ê¸ˆì§€**:
*   AI íŠœí„°ëŠ” í•™ìŠµ ë‚´ìš©ê³¼ ì§ì ‘ ê´€ë ¨ë˜ì§€ ì•Šì€ ê°œì¸ì ì¸ ëŒ€í™” (ì‚¬ìƒí™œ ìƒë‹´, ì—°ì•  ìƒë‹´ ë“±)ë¥¼ ìˆ˜í–‰í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
*   í•™ìƒì˜ ê°ì •ì ì¸ ì–´ë ¤ì›€ì— ëŒ€í•œ ê³µê°ì€ ì œê³µí•˜ë˜, ì „ë¬¸ì ì¸ ìƒë‹´ì´ í•„ìš”í•œ ê²½ìš° ì „ë¬¸ê°€ì˜ ë„ì›€ì„ ë°›ë„ë¡ ì•ˆë‚´í•©ë‹ˆë‹¤.

**ì „ë¬¸ ë¶„ì•¼ ë‹µë³€ ì œí•œ**:
*   AI íŠœí„°ëŠ” ì˜í•™ì  ë˜ëŠ” ë²•ë¥ ì  ì¡°ì–¸ì„ ì œê³µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
*   í•´ë‹¹ ë¶„ì•¼ì˜ ì „ë¬¸ê°€ì™€ ìƒë‹´í•˜ë„ë¡ ì•ˆë‚´í•©ë‹ˆë‹¤.

**ì‹œí—˜ ìƒí™©ì—ì„œì˜ íŒíŠ¸ ì œê³µ ê¸ˆì§€**:
*   í•™ìƒì´ ì‹œí—˜ ì‘ì‹œ ì¤‘ì—ëŠ” AI íŠœí„°ì˜ íŒíŠ¸ ì œê³µ ê¸°ëŠ¥ì„ ì œí•œí•©ë‹ˆë‹¤.
*   í•™ìƒì˜ ìê¸° í‰ê°€ ë° ë³µìŠµì„ ë•ëŠ” ê¸°ëŠ¥ì€ ì‹œí—˜ ì¢…ë£Œ í›„ì— ì œê³µí•©ë‹ˆë‹¤.

**ë¶€ì ì ˆí•œ ìš”ì²­ ì²˜ë¦¬ ê¸ˆì§€**:
*   AIëŠ” í­ë ¥ì ì´ê±°ë‚˜ í˜ì˜¤ì ì¸ ì½˜í…ì¸ ë¥¼ ìƒì„±í•˜ëŠ” ìš”ì²­ì„ ê±°ë¶€í•©ë‹ˆë‹¤.
*   AIëŠ” ì°¨ë³„ì ì´ê±°ë‚˜ ë¶ˆì¾Œê°ì„ ì£¼ëŠ” ì–¸ì–´ë¥¼ ì‚¬ìš©í•˜ëŠ” ìš”ì²­ì„ ê±°ë¶€í•©ë‹ˆë‹¤.

#### 4.5.3 Rego ì •ì±… êµ¬í˜„

**í•™ìŠµ ê´€ë ¨ ì§ˆë¬¸ ê²€ì¦ ì •ì±…**:
```rego
package ai_behavior_educational_focus

import future.keywords.if
import future.keywords.contains

default allow = false

# í—ˆìš©ë˜ëŠ” ì£¼ì œ ì¹´í…Œê³ ë¦¬
educational_topics := [
    "mathematics", "science", "language", "history",
    "geography", "computer_science", "arts", "music"
]

# ê¸ˆì§€ëœ ì£¼ì œ ì¹´í…Œê³ ë¦¬
forbidden_topics := [
    "personal_counseling", "romantic_advice", "medical_advice",
    "legal_advice", "financial_advice", "political_opinion"
]

# ì§ˆë¬¸ ë¶„ë¥˜ (ì‹¤ì œë¡œëŠ” ML ëª¨ë¸ ì‚¬ìš©)
classify_question(question) := category {
    # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­ (ì‹¤ì œë¡œëŠ” NLP ëª¨ë¸)
    category := "mathematics"  # ì˜ˆì‹œ
}

# êµìœ¡ ê´€ë ¨ ì§ˆë¬¸ í—ˆìš©
allow {
    category := classify_question(input.question)
    category in educational_topics
}

# ê¸ˆì§€ëœ ì£¼ì œ ì°¨ë‹¨
deny[msg] {
    category := classify_question(input.question)
    category in forbidden_topics
    msg := sprintf("Question category '%s' is not allowed. AI tutor focuses on educational topics only.", [category])
}

# ì „ë¬¸ ë¶„ì•¼ ì•ˆë‚´ ë©”ì‹œì§€
referral_message[msg] {
    category := classify_question(input.question)
    category == "medical_advice"
    msg := "ì˜í•™ì  ì¡°ì–¸ì€ ì „ë¬¸ ì˜ë£Œì¸ê³¼ ìƒë‹´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."
}

referral_message[msg] {
    category := classify_question(input.question)
    category == "legal_advice"
    msg := "ë²•ë¥ ì  ì¡°ì–¸ì€ ì „ë¬¸ ë³€í˜¸ì‚¬ì™€ ìƒë‹´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."
}
```

**ì‹œí—˜ ì¤‘ íŒíŠ¸ ì œê³µ ì œí•œ ì •ì±…**:
```rego
package ai_behavior_exam_assistance

import future.keywords.if

default allow = false

# ì¼ë°˜ í•™ìŠµ ëª¨ë“œì—ì„œëŠ” íŒíŠ¸ í—ˆìš©
allow {
    input.context.mode == "learning"
    input.request.type == "hint"
}

# ì‹œí—˜ ëª¨ë“œì—ì„œëŠ” íŒíŠ¸ ê±°ë¶€
deny[msg] {
    input.context.mode == "exam"
    input.request.type == "hint"
    msg := "Hints are not available during exams. Please complete the exam independently."
}

# ë³µìŠµ ëª¨ë“œì—ì„œëŠ” ìƒì„¸ ì„¤ëª… í—ˆìš©
allow {
    input.context.mode == "review"
    input.request.type in ["hint", "solution", "explanation"]
}
```

**ë¶€ì ì ˆí•œ ìš”ì²­ ì°¨ë‹¨ ì •ì±…**:
```rego
package ai_behavior_request_validation

import future.keywords.if
import future.keywords.contains

default allow = false

# í­ë ¥/í˜ì˜¤ ìš”ì²­ ê°ì§€ (ê°„ë‹¨í•œ ì˜ˆì‹œ)
contains_harmful_intent(request) if {
    harmful_keywords := ["í­ë ¥", "ì°¨ë³„", "í˜ì˜¤", "ê´´ë¡­í˜"]
    some keyword in harmful_keywords
    contains(lower(request), keyword)
}

# ì •ìƒ ìš”ì²­ í—ˆìš©
allow {
    not contains_harmful_intent(input.request)
}

# ìœ í•´ ìš”ì²­ ì°¨ë‹¨
deny[msg] {
    contains_harmful_intent(input.request)
    msg := "This request contains inappropriate content and cannot be processed."
}
```

#### 4.5.4 ì½”ê·¸ë‹ˆí‹°ë¸Œ ì •ì±… ë ˆì´ì–´ (Cognitive Policy Layer)

DreamSeedAIì˜ í•µì‹¬ ê¸°ìˆ ë¡œ, AI ëª¨ë¸ì´ ì¶œë ¥ì„ ìƒì„±í•˜ê¸° **ì „ì—** ì½”ê·¸ë‹ˆí‹°ë¸Œ ì •ì±… ë ˆì´ì–´ê°€ í•´ë‹¹ ë…¼ì˜ ì£¼ì œê°€ í—ˆìš©ë˜ëŠ”ì§€ ì—¬ë¶€ë¥¼ ê²€í† í•©ë‹ˆë‹¤. ì´ ì‚¬ì „ ì–µì œ ë°©ì‹ì€ ë‹¨ìˆœ ì¶œë ¥ ê²°ê³¼ë¥¼ ê²€ì‚¬í•´ ì§€ìš°ëŠ” ì‚¬í›„ í•„í„°ë§ë³´ë‹¤ í›¨ì”¬ ê°•ë ¥í•˜ë©°, AI ì•ˆì „ì„±ì„ íšê¸°ì ìœ¼ë¡œ í–¥ìƒì‹œí‚µë‹ˆë‹¤.

**ë™ì‘ ì›ë¦¬**:

```
ì‚¬ìš©ì ìš”ì²­
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Cognitive Policy Layer              â”‚
â”‚  1. ìš”ì²­ ì˜ë„ ë¶„ì„                   â”‚
â”‚  2. ì •ì±… ê·œì¹™ ë§¤ì¹­                   â”‚
â”‚  3. ì‚¬ì „ í—ˆìš©/ê±°ë¶€ ê²°ì •              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
í—ˆìš©ëœ ê²½ìš°ë§Œ â†’ AI ëª¨ë¸ ì‹¤í–‰
    â†“
ì‘ë‹µ ìƒì„± (ì •ì±… ìœ„ë°˜ ê°€ëŠ¥ì„± â†“â†“)
```

**êµ¬í˜„ ì˜ˆì‹œ**:

```python
# ai/cognitive_policy_layer.py
from typing import Dict, Optional
from enum import Enum

class RequestCategory(Enum):
    EDUCATIONAL = "educational"
    PERSONAL_COUNSELING = "personal_counseling"
    MEDICAL_ADVICE = "medical_advice"
    LEGAL_ADVICE = "legal_advice"
    HARMFUL_INTENT = "harmful_intent"
    EXAM_CHEATING = "exam_cheating"

class PolicyDecision:
    def __init__(self, allowed: bool, reason: str = "", referral: str = ""):
        self.allowed = allowed
        self.reason = reason
        self.referral = referral
    
    def is_allowed(self) -> bool:
        return self.allowed
    
    def get_rejection_message(self) -> str:
        if self.referral:
            return f"{self.reason}\n\n{self.referral}"
        return self.reason

class CognitivePolicyLayer:
    def __init__(self, policy_engine, intent_classifier):
        self.policy_engine = policy_engine
        self.intent_classifier = intent_classifier
    
    async def check(self, user_input: str, context: Dict) -> PolicyDecision:
        """
        AIê°€ ë‹µì„ ë§Œë“¤ê¸° ì „ ì •ì±… ì—”ì§„ì´ ìš”ì²­ì„ ê²€í† í•˜ê³  ì²˜ë¦¬ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.
        
        Args:
            user_input: ì‚¬ìš©ìì˜ ì§ˆë¬¸/ìš”ì²­
            context: ì»¨í…ìŠ¤íŠ¸ ì •ë³´ (ëª¨ë“œ, ì‚¬ìš©ì ì •ë³´ ë“±)
        
        Returns:
            PolicyDecision: í—ˆìš© ì—¬ë¶€ ë° ê±°ë¶€ ì‚¬ìœ 
        """
        # 1. ìš”ì²­ ì˜ë„ ë¶„ì„
        intent = await self.intent_classifier.classify(user_input)
        category = self._map_intent_to_category(intent)
        
        # 2. ì •ì±… ê·œì¹™ ë§¤ì¹­ ë° í‰ê°€
        policy_result = await self.policy_engine.evaluate("ai_behavior", {
            "question": user_input,
            "context": context,
            "request": {"type": intent.request_type},
            "category": category.value
        })
        
        # 3. ì‚¬ì „ í—ˆìš©/ê±°ë¶€ ê²°ì •
        if not policy_result["allow"]:
            # ê±°ë¶€ ì‚¬ìœ  ìƒì„±
            reason = policy_result.get("deny", ["Request not allowed"])[0]
            referral = policy_result.get("referral_message", [""])[0]
            
            # ë©”íŠ¸ë¦­ ê¸°ë¡
            COGNITIVE_POLICY_BLOCKS.labels(
                category=category.value,
                reason=reason
            ).inc()
            
            return PolicyDecision(
                allowed=False,
                reason=reason,
                referral=referral
            )
        
        # í—ˆìš©ëœ ê²½ìš°
        COGNITIVE_POLICY_ALLOWS.labels(category=category.value).inc()
        return PolicyDecision(allowed=True)
    
    def _map_intent_to_category(self, intent) -> RequestCategory:
        """ì˜ë„ë¥¼ ì¹´í…Œê³ ë¦¬ë¡œ ë§¤í•‘"""
        # ML ëª¨ë¸ ê²°ê³¼ë¥¼ ì¹´í…Œê³ ë¦¬ë¡œ ë³€í™˜
        category_map = {
            "education": RequestCategory.EDUCATIONAL,
            "counseling": RequestCategory.PERSONAL_COUNSELING,
            "medical": RequestCategory.MEDICAL_ADVICE,
            "legal": RequestCategory.LEGAL_ADVICE,
            "harmful": RequestCategory.HARMFUL_INTENT,
            "exam_help": RequestCategory.EXAM_CHEATING
        }
        return category_map.get(intent.category, RequestCategory.EDUCATIONAL)

# ì‹¤ì œ ì‚¬ìš© ì˜ˆì‹œ
async def generate_response(user_input: str, user_context: Dict, ai_model) -> str:
    """AI ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤."""
    
    # Cognitive Policy Layer ê²€ì‚¬ (AI ì‹¤í–‰ ì „)
    cognitive_layer = CognitivePolicyLayer(
        policy_engine=OPAEngine(),
        intent_classifier=IntentClassifier()
    )
    
    policy_decision = await cognitive_layer.check(user_input, user_context)
    
    if not policy_decision.is_allowed():
        # AI ëª¨ë¸ ì‹¤í–‰í•˜ì§€ ì•Šê³  ë°”ë¡œ ê±°ë¶€ ë©”ì‹œì§€ ë°˜í™˜
        logger.warning(
            f"Request blocked by cognitive policy layer",
            extra={
                "user_input": user_input,
                "reason": policy_decision.reason
            }
        )
        return policy_decision.get_rejection_message()
    
    # ì •ì±… í†µê³¼í•œ ê²½ìš°ì—ë§Œ AI ëª¨ë¸ ì‹¤í–‰
    response = await ai_model.generate(user_input, context=user_context)
    
    # ì¶”ê°€ ì•ˆì „ì„± ê²€ì‚¬ (ì´ì¤‘ ê²€ì¦)
    safety_check = await RealtimeContentFilter().check_text_safety(response)
    if not safety_check["passed"]:
        return "ì£„ì†¡í•©ë‹ˆë‹¤. ì•ˆì „í•œ ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”."
    
    return response
```

**ì‹¤ì œ ì‹œë‚˜ë¦¬ì˜¤ ì˜ˆì‹œ**:

```python
# ì‹œë‚˜ë¦¬ì˜¤ 1: ë¶€ì ì ˆí•œ ìš”ì²­ (ì‚¬ì „ ì°¨ë‹¨)
user_input = "ë‚˜ìœ ë§ë¡œ ì‚¬ëŒ ë†€ë¦¬ëŠ” ë¬¸ì¥ì„ ë§Œë“¤ì–´ì¤˜"

# Cognitive Policy Layer ë™ì‘:
# 1. Intent Classifier â†’ "harmful_intent" ë¶„ë¥˜
# 2. Policy í‰ê°€ â†’ deny: "inappropriate content"
# 3. AI ëª¨ë¸ ì‹¤í–‰ë˜ì§€ ì•ŠìŒ (ì°¨ë‹¨)

response = await generate_response(user_input, context, ai_model)
# ê²°ê³¼: "This request contains inappropriate content and cannot be processed."

# ì‹œë‚˜ë¦¬ì˜¤ 2: ì‹œí—˜ ì¤‘ íŒíŠ¸ ìš”ì²­ (ì‚¬ì „ ì°¨ë‹¨)
user_input = "ì´ ë¬¸ì œ ë‹µ ì•Œë ¤ì¤˜"
context = {"mode": "exam", "student_id": 123}

# Cognitive Policy Layer ë™ì‘:
# 1. Intent Classifier â†’ "exam_help" ë¶„ë¥˜
# 2. Policy í‰ê°€ (context.mode == "exam") â†’ deny
# 3. AI ëª¨ë¸ ì‹¤í–‰ë˜ì§€ ì•ŠìŒ (ì°¨ë‹¨)

response = await generate_response(user_input, context, ai_model)
# ê²°ê³¼: "Hints are not available during exams. Please complete the exam independently."

# ì‹œë‚˜ë¦¬ì˜¤ 3: ì˜í•™ ì¡°ì–¸ ìš”ì²­ (ì‚¬ì „ ì°¨ë‹¨ + ì „ë¬¸ê°€ ì•ˆë‚´)
user_input = "ë‘í†µì´ ì‹¬í•œë° ë¬´ìŠ¨ ì•½ì„ ë¨¹ì–´ì•¼ í• ê¹Œ?"

# Cognitive Policy Layer ë™ì‘:
# 1. Intent Classifier â†’ "medical_advice" ë¶„ë¥˜
# 2. Policy í‰ê°€ â†’ deny + referral_message
# 3. AI ëª¨ë¸ ì‹¤í–‰ë˜ì§€ ì•ŠìŒ (ì°¨ë‹¨)

response = await generate_response(user_input, context, ai_model)
# ê²°ê³¼: "AI tutor cannot provide medical advice.\n\nì˜í•™ì  ì¡°ì–¸ì€ ì „ë¬¸ ì˜ë£Œì¸ê³¼ ìƒë‹´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."

# ì‹œë‚˜ë¦¬ì˜¤ 4: ì •ìƒ êµìœ¡ ì§ˆë¬¸ (í—ˆìš©)
user_input = "ì´ì°¨ë°©ì •ì‹ í’€ì´ ë°©ë²•ì„ ì•Œë ¤ì¤˜"

# Cognitive Policy Layer ë™ì‘:
# 1. Intent Classifier â†’ "educational" ë¶„ë¥˜
# 2. Policy í‰ê°€ â†’ allow
# 3. AI ëª¨ë¸ ì‹¤í–‰ âœ…

response = await generate_response(user_input, context, ai_model)
# ê²°ê³¼: "ì´ì°¨ë°©ì •ì‹ì€ axÂ² + bx + c = 0 í˜•íƒœë¡œ í‘œí˜„ë˜ë©°, ê·¼ì˜ ê³µì‹ì„ ì‚¬ìš©í•˜ì—¬ í’€ ìˆ˜ ìˆìŠµë‹ˆë‹¤..."
```

#### 4.5.5 êµ¬í˜„ ë©”ì»¤ë‹ˆì¦˜

DreamSeedAIëŠ” AI í–‰ë™ ì •ì±…ì„ íš¨ê³¼ì ìœ¼ë¡œ êµ¬í˜„í•˜ê¸° ìœ„í•´ ë‹¤ìŒê³¼ ê°™ì€ ë©”ì»¤ë‹ˆì¦˜ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

**1. ì‚¬ì „ í•™ìŠµ ë°ì´í„° ì •ì œ**

AI ëª¨ë¸ í•™ìŠµì— ì‚¬ìš©ë˜ëŠ” ë°ì´í„°ì…‹ì—ì„œ ë¶€ì ì ˆí•˜ê±°ë‚˜ í¸í–¥ëœ ë‚´ìš©ì„ ì œê±°í•©ë‹ˆë‹¤.

```python
# ai/training/ethical_data_curation.py
class EthicalDataCurator:
    def __init__(self, toxicity_classifier, bias_detector):
        self.toxicity_classifier = toxicity_classifier
        self.bias_detector = bias_detector
    
    async def curate_training_data(self, raw_dataset: List[Dict]) -> List[Dict]:
        """ìœ¤ë¦¬ì  ê¸°ì¤€ì— ë”°ë¼ í•™ìŠµ ë°ì´í„° íë ˆì´ì…˜"""
        curated_data = []
        filtered_stats = {
            "toxic": 0,
            "biased": 0,
            "off_topic": 0,
            "total": len(raw_dataset)
        }
        
        for item in raw_dataset:
            # 1. ìœ í•´ì„± ê²€ì‚¬
            toxicity_score = await self.toxicity_classifier.predict(item["text"])
            if toxicity_score > 0.7:
                filtered_stats["toxic"] += 1
                continue
            
            # 2. í¸í–¥ì„± ê²€ì‚¬
            bias_result = await self.bias_detector.analyze(item["text"])
            if bias_result["has_bias"]:
                filtered_stats["biased"] += 1
                continue
            
            # 3. êµìœ¡ ê´€ë ¨ì„± ê²€ì‚¬
            if not self._is_educational_content(item):
                filtered_stats["off_topic"] += 1
                continue
            
            # í†µê³¼í•œ ë°ì´í„°ë§Œ í¬í•¨
            curated_data.append(item)
        
        # í†µê³„ ë¡œê¹…
        logger.info(
            f"Data curation complete",
            extra={
                "original_size": filtered_stats["total"],
                "curated_size": len(curated_data),
                "filtered_toxic": filtered_stats["toxic"],
                "filtered_biased": filtered_stats["biased"],
                "filtered_off_topic": filtered_stats["off_topic"]
            }
        )
        
        return curated_data
    
    def _is_educational_content(self, item: Dict) -> bool:
        """êµìœ¡ ì½˜í…ì¸  ì—¬ë¶€ í™•ì¸"""
        educational_keywords = [
            "í•™ìŠµ", "êµìœ¡", "ìˆ˜í•™", "ê³¼í•™", "ì—­ì‚¬", "ì–¸ì–´",
            "ë¬¸ì œ í’€ì´", "ì„¤ëª…", "ê°œë…", "ì›ë¦¬"
        ]
        return any(kw in item["text"] for kw in educational_keywords)
```

**2. ì‹¤ì‹œê°„ í•„í„°ë§ (ì´ì¤‘ ê²€ì¦)**

Cognitive Policy Layer í†µê³¼ í›„ì—ë„ ì¶”ê°€ ì•ˆì „ì„± ê²€ì‚¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.

```python
# ai/safety/dual_verification.py
class DualVerificationFilter:
    """ì´ì¤‘ ê²€ì¦ í•„í„° (Cognitive Policy + Output Filter)"""
    
    async def verify_response(
        self, 
        user_input: str, 
        ai_response: str,
        context: Dict
    ) -> Dict[str, any]:
        """
        1ì°¨: Cognitive Policy Layer (ì…ë ¥ ê²€ì¦)
        2ì°¨: Output Filter (ì¶œë ¥ ê²€ì¦)
        """
        # 1ì°¨ ê²€ì¦ì€ ì´ë¯¸ ì™„ë£Œëœ ìƒíƒœ (Cognitive Policy Layer)
        
        # 2ì°¨ ê²€ì¦: AI ì‘ë‹µ ì¶œë ¥ ê²€ì‚¬
        safety_filter = RealtimeContentFilter()
        output_check = await safety_filter.check_text_safety(ai_response)
        
        # êµìœ¡ ì í•©ì„± ê²€ì‚¬
        educational_check = self._check_educational_alignment(ai_response, context)
        
        # ìµœì¢… íŒì •
        passed = output_check["passed"] and educational_check["passed"]
        
        return {
            "passed": passed,
            "output_safety": output_check,
            "educational_alignment": educational_check,
            "confidence": min(output_check["score"], educational_check["score"])
        }
    
    def _check_educational_alignment(self, response: str, context: Dict) -> Dict:
        """ì‘ë‹µì´ êµìœ¡ ëª©í‘œì— ë¶€í•©í•˜ëŠ”ì§€ í™•ì¸"""
        # ì‘ë‹µ ê¸¸ì´ ì ì ˆì„±
        if len(response) > 2000:
            return {"passed": False, "reason": "Response too long", "score": 0.5}
        
        # í•™ìŠµ ëª¨ë“œë³„ ì í•©ì„±
        if context.get("mode") == "exam" and "ì •ë‹µì€" in response:
            return {"passed": False, "reason": "Direct answer in exam mode", "score": 0.0}
        
        return {"passed": True, "score": 1.0}
```

**3. ê°•í™” í•™ìŠµ (RLHF - Reinforcement Learning from Human Feedback)**

ì¸ê°„ í”¼ë“œë°±ì„ ì‚¬ìš©í•˜ì—¬ AI ëª¨ë¸ì„ ì§€ì†ì ìœ¼ë¡œ í›ˆë ¨í•˜ê³  ìœ¤ë¦¬ì ì¸ ì‘ë‹µì„ ìƒì„±í•˜ë„ë¡ ìœ ë„í•©ë‹ˆë‹¤.

```python
# ai/training/rlhf_trainer.py
class RLHFTrainer:
    """ì¸ê°„ í”¼ë“œë°± ê¸°ë°˜ ê°•í™” í•™ìŠµ"""
    
    def __init__(self, base_model, reward_model):
        self.base_model = base_model
        self.reward_model = reward_model
    
    async def collect_human_feedback(
        self, 
        interactions: List[Dict]
    ) -> List[Dict]:
        """êµì‚¬ ë° ì „ë¬¸ê°€ í”¼ë“œë°± ìˆ˜ì§‘"""
        feedback_data = []
        
        for interaction in interactions:
            # UIë¥¼ í†µí•´ ì „ë¬¸ê°€ì—ê²Œ í‰ê°€ ìš”ì²­
            rating = await self._request_expert_rating(
                question=interaction["question"],
                response=interaction["response"]
            )
            
            feedback_data.append({
                "question": interaction["question"],
                "response": interaction["response"],
                "rating": rating,  # 1-5 ì ìˆ˜
                "expert_comments": rating.get("comments", "")
            })
        
        return feedback_data
    
    async def train_with_feedback(self, feedback_data: List[Dict]):
        """í”¼ë“œë°± ë°ì´í„°ë¡œ ëª¨ë¸ ì¬í•™ìŠµ"""
        # ë³´ìƒ ëª¨ë¸ ì—…ë°ì´íŠ¸
        await self.reward_model.train(feedback_data)
        
        # PPO (Proximal Policy Optimization) ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ëª¨ë¸ ê°œì„ 
        for epoch in range(10):
            for batch in self._create_batches(feedback_data):
                # ì‘ë‹µ ìƒì„±
                responses = await self.base_model.generate_batch(
                    [item["question"] for item in batch]
                )
                
                # ë³´ìƒ ê³„ì‚°
                rewards = await self.reward_model.predict_rewards(
                    questions=[item["question"] for item in batch],
                    responses=responses
                )
                
                # ì •ì±… ì—…ë°ì´íŠ¸ (ë†’ì€ ë³´ìƒì„ ë°›ëŠ” ì‘ë‹µ ê°•í™”)
                loss = self._compute_ppo_loss(responses, rewards)
                await self.base_model.update(loss)
        
        logger.info(f"RLHF training complete: {len(feedback_data)} samples")
```

**4. ì‹ ê³  ì‹œìŠ¤í…œ í†µí•©**

ì‚¬ìš©ìê°€ AI ìƒì„± ì½˜í…ì¸ ë¥¼ ì‹ ê³ í•  ìˆ˜ ìˆìœ¼ë©°, ì‹ ê³  ë°ì´í„°ëŠ” ëª¨ë¸ ê°œì„ ì— í™œìš©ë©ë‹ˆë‹¤.

```python
# api/routes/ai_response_report.py
@router.post("/api/ai/report")
async def report_ai_response(
    report: AIResponseReport,
    current_user: User = Depends(get_current_user)
):
    """AI ì‘ë‹µ ì‹ ê³  (ë¶€ì ì ˆí•œ ë‹µë³€, ì˜¤ë¥˜ ë“±)"""
    # 1. ì‹ ê³  ì €ì¥
    report_id = await db.ai_response_reports.insert_one({
        "conversation_id": report.conversation_id,
        "user_input": report.user_input,
        "ai_response": report.ai_response,
        "reported_by": current_user.id,
        "issue_type": report.issue_type,  # "inappropriate", "incorrect", "unhelpful"
        "description": report.description,
        "created_at": datetime.now()
    })
    
    # 2. AI ì‘ë‹µ ì„ì‹œ ìˆ¨ê¹€
    await db.conversations.update_one(
        {"id": report.conversation_id},
        {"$set": {"ai_response_hidden": True}}
    )
    
    # 3. AI ìœ¤ë¦¬íŒ€ ì•Œë¦¼
    await slack_notify(
        channel="#ai-ethics",
        message=f"ğŸ¤– AI response reported: {report.issue_type}\n"
                f"User: {current_user.name}\n"
                f"Review: /admin/ai-reports/{report_id}"
    )
    
    # 4. RLHF ë°ì´í„°ë¡œ ì €ì¥ (ë¶€ì •ì  í”¼ë“œë°±)
    await rlhf_trainer.add_negative_feedback({
        "question": report.user_input,
        "response": report.ai_response,
        "rating": 1,  # ë‚®ì€ ì ìˆ˜
        "issue": report.issue_type
    })
    
    return {"success": True, "report_id": str(report_id)}
```

#### 4.5.6 ëª¨ë‹ˆí„°ë§ ë° ê°ì‚¬

**Prometheus ë©”íŠ¸ë¦­**:
```python
# governance/backend/metrics.py
COGNITIVE_POLICY_BLOCKS = Counter(
    'cognitive_policy_blocks_total',
    'Total requests blocked by cognitive policy layer',
    ['category', 'reason']
)

COGNITIVE_POLICY_ALLOWS = Counter(
    'cognitive_policy_allows_total',
    'Total requests allowed by cognitive policy layer',
    ['category']
)

AI_RESPONSE_REPORTS = Counter(
    'ai_response_reports_total',
    'Total AI response reports',
    ['issue_type']
)

RLHF_TRAINING_ROUNDS = Counter(
    'rlhf_training_rounds_total',
    'Total RLHF training rounds'
)
```

**ì •ê¸° ê°ì‚¬ ìŠ¤í¬ë¦½íŠ¸**:
```python
# scripts/audit_ai_behavior.py
async def audit_ai_behavior_policies():
    """AI í–‰ë™ ì •ì±… íš¨ê³¼ì„± ê°ì‚¬"""
    # 1. ìµœê·¼ 30ì¼ê°„ ì°¨ë‹¨ëœ ìš”ì²­ ë¶„ì„
    blocked_requests = await db.audit_logs.find({
        "event": "cognitive_policy_block",
        "timestamp": {"$gte": datetime.now() - timedelta(days=30)}
    }).to_list(None)
    
    # 2. ì¹´í…Œê³ ë¦¬ë³„ ì°¨ë‹¨ í†µê³„
    category_stats = {}
    for log in blocked_requests:
        category = log["category"]
        category_stats[category] = category_stats.get(category, 0) + 1
    
    # 3. AI ì‘ë‹µ ì‹ ê³  ë¶„ì„
    reports = await db.ai_response_reports.find({
        "created_at": {"$gte": datetime.now() - timedelta(days=30)}
    }).to_list(None)
    
    issue_stats = {}
    for report in reports:
        issue = report["issue_type"]
        issue_stats[issue] = issue_stats.get(issue, 0) + 1
    
    # 4. RLHF íš¨ê³¼ì„± í‰ê°€
    rlhf_metrics = await analyze_rlhf_effectiveness()
    
    # 5. ë³´ê³ ì„œ ìƒì„±
    report = {
        "period": "last_30_days",
        "cognitive_blocks": {
            "total": len(blocked_requests),
            "by_category": category_stats
        },
        "user_reports": {
            "total": len(reports),
            "by_issue": issue_stats
        },
        "rlhf_effectiveness": rlhf_metrics,
        "recommendations": []
    }
    
    # 6. ê°œì„  ê¶Œì¥ì‚¬í•­
    if len(reports) > 100:
        report["recommendations"].append(
            "High number of AI response reports. Review model behavior and retrain."
        )
    
    if category_stats.get("medical_advice", 0) > 50:
        report["recommendations"].append(
            "Frequent medical advice requests detected. Improve user education."
        )
    
    return report

async def analyze_rlhf_effectiveness():
    """RLHF í›ˆë ¨ íš¨ê³¼ì„± ë¶„ì„"""
    # í›ˆë ¨ ì „í›„ ë¹„êµ
    before_training = await get_model_performance_before_rlhf()
    after_training = await get_current_model_performance()
    
    return {
        "improvement": {
            "safety_score": after_training["safety"] - before_training["safety"],
            "helpfulness": after_training["helpful"] - before_training["helpful"],
            "accuracy": after_training["accuracy"] - before_training["accuracy"]
        },
        "training_rounds": await db.rlhf_training_logs.count_documents({}),
        "feedback_samples": await db.rlhf_feedback.count_documents({})
    }
```

**ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ (Grafana)**:
```yaml
# Grafana Dashboard: AI Behavior Monitoring
panels:
  - title: "Cognitive Policy Blocks (Last 24h)"
    query: |
      sum(rate(cognitive_policy_blocks_total[24h])) by (category)
  
  - title: "AI Response Quality (User Reports)"
    query: |
      sum(rate(ai_response_reports_total[24h])) by (issue_type)
  
  - title: "RLHF Training Progress"
    query: |
      rlhf_training_rounds_total
  
  - title: "Policy Block Rate"
    query: |
      sum(rate(cognitive_policy_blocks_total[1h])) 
        / 
      sum(rate(cognitive_policy_allows_total[1h]))
```

DreamSeedAIëŠ” ìœ„ì™€ ê°™ì€ ì •ì±… ë° ê¸°ìˆ ì  ë©”ì»¤ë‹ˆì¦˜ì„ í†µí•´, AIê°€ êµìœ¡ì  ê°€ì¹˜ë¥¼ í›¼ì†í•˜ì§€ ì•Šê³  ê¸ì •ì ì¸ í•™ìŠµ ê²½í—˜ì„ ì œê³µí•  ìˆ˜ ìˆë„ë¡ ì§€ì†ì ìœ¼ë¡œ ë…¸ë ¥í•©ë‹ˆë‹¤.

### 4.6 ìŠ¹ì¸/ì›Œí¬í”Œë¡œ ì •ì±… (Approval & Workflow Policies)

ìŠ¹ì¸/ì›Œí¬í”Œë¡œ ì •ì±…ì€ DreamSeedAIì—ì„œ êµì‚¬ë‚˜ í•™ë¶€ëª¨ì˜ ìŠ¹ì¸ ì ˆì°¨ê°€ í•„ìš”í•œ ìƒí™©ë“¤ì„ ì •ì˜í•˜ê³  ì²˜ë¦¬í•˜ëŠ” ê·œì¹™ì…ë‹ˆë‹¤. ì´ ì •ì±…ì€ AI ì‹œìŠ¤í…œì˜ ì˜ì‚¬ ê²°ì •ì— ëŒ€í•œ ì¸ê°„ì˜ ê°ë…ì„ ê°•í™”í•˜ê³ , í•™ìƒë“¤ì—ê²Œ ì•ˆì „í•˜ê³  ì ì ˆí•œ í•™ìŠµ ê²½í—˜ì„ ì œê³µí•˜ê¸° ìœ„í•´ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.

#### 4.6.1 ëª©í‘œ

*   **ì¸ê°„ ê°ë… ê°•í™”**: AI ì‹œìŠ¤í…œì˜ ì£¼ìš” ê²°ì •ì— ëŒ€í•œ êµì‚¬ ë° í•™ë¶€ëª¨ì˜ ìŠ¹ì¸ì„ í†µí•´ ì˜¤ë¥˜ ë° ë¶€ì ì ˆí•œ ì½˜í…ì¸  ë…¸ì¶œì„ ë°©ì§€í•©ë‹ˆë‹¤.
*   **í•™ìŠµ í™˜ê²½ ì•ˆì „ ë³´ì¥**: í•™ìƒë“¤ì—ê²Œ ì•ˆì „í•˜ê³  ì ì ˆí•œ í•™ìŠµ ì½˜í…ì¸ ì™€ í™œë™ì„ ì œê³µí•©ë‹ˆë‹¤.
*   **ì •ì±… ì¤€ìˆ˜**: ë°ì´í„° ì ‘ê·¼ ë° ì‚¬ìš©ì— ëŒ€í•œ ì •ì±…ì„ íš¨ê³¼ì ìœ¼ë¡œ ì‹œí–‰í•©ë‹ˆë‹¤.
*   **íˆ¬ëª…ì„± ì œê³µ**: ëª¨ë“  ìŠ¹ì¸ ì ˆì°¨ë¥¼ ì¶”ì í•˜ì—¬ ê°ì‚¬ ê°€ëŠ¥ì„±ì„ ë³´ì¥í•©ë‹ˆë‹¤.

#### 4.6.2 ì£¼ìš” ì •ì±… ê·œì¹™

**ê³ ê¸‰ ì½˜í…ì¸  ì ‘ê·¼**:
*   í•™ìƒì´ íŠ¹ì • ìˆ˜ì¤€ ì´ìƒì˜ ë‚œì´ë„ë¥¼ ê°€ì§„ ì½˜í…ì¸ ì— ì ‘ê·¼ ìš”ì²­ ì‹œ êµì‚¬ ìŠ¹ì¸ í•„ìš”
*   ë¯¼ê°í•œ ì‚¬íšŒ ë¬¸ì œì™€ ê´€ë ¨ëœ ì½˜í…ì¸  ì ‘ê·¼ ì‹œ ì‚¬ì „ ìŠ¹ì¸ í•„ìˆ˜

**AI ìƒì„± ì½˜í…ì¸  ê²€í† **:
*   ìƒˆë¡œ ìƒì„±ëœ AI ë¬¸ì œëŠ” í•™ìƒ ë…¸ì¶œ ì „ êµì‚¬ ê²€í†  í•„ìˆ˜
*   êµì‚¬ëŠ” ë¬¸ì œì˜ ì •í™•ì„±, ëª…í™•ì„±, êµìœ¡ ê³¼ì • ì—°ê´€ì„±ì„ í™•ì¸

**ê°œì¸ ì •ë³´ ì ‘ê·¼**:
*   í•™ìƒì˜ ë¯¼ê°í•œ ê°œì¸ ì •ë³´ (ê±´ê°• ì •ë³´, ìƒë‹´ ê¸°ë¡) ì ‘ê·¼ ì‹œ í•™ë¶€ëª¨ ë™ì˜ í•„ìš”
*   ë°ì´í„° ì ‘ê·¼ ëª©ì  ë° ë²”ìœ„ ëª…ì‹œ í•„ìˆ˜

**ì™¸ë¶€ ìë£Œ ë§í¬**:
*   í•™ìƒì˜ ì™¸ë¶€ ì›¹ì‚¬ì´íŠ¸ ë˜ëŠ” ìë£Œ ì ‘ê·¼ ì‹œ êµì‚¬ ìŠ¹ì¸ í•„ìš”
*   ìœ í•´í•˜ê±°ë‚˜ ë¶€ì ì ˆí•œ ì½˜í…ì¸  ë…¸ì¶œ ë°©ì§€

**AI íŠœí„° ê°œì¸ ì„¤ì • ë³€ê²½**:
*   í•™ìŠµ ë°©ë²•ì´ë‚˜ ë‚œì´ë„ ì¡°ì • ì‹œ êµì‚¬ ë˜ëŠ” í•™ë¶€ëª¨ ìŠ¹ì¸ í•„ìš”
*   ì„¤ì • ë³€ê²½ ì´ë ¥ ì¶”ì 

#### 4.6.3 Rego ì •ì±… êµ¬í˜„

**ê³ ê¸‰ ì½˜í…ì¸  ì ‘ê·¼ ì •ì±…**:
```rego
package approval_advanced_content

import future.keywords.if

default allow = false

# ì½˜í…ì¸  ë‚œì´ë„ ë ˆë²¨ ì •ì˜
difficulty_threshold := 8  # 1-10 ìŠ¤ì¼€ì¼

# ë¯¼ê°í•œ ì£¼ì œ ëª©ë¡
sensitive_topics := [
    "politics", "religion", "war", "violence",
    "discrimination", "controversial_history"
]

# ê¸°ë³¸ ì½˜í…ì¸ ëŠ” ìŠ¹ì¸ ì—†ì´ ì ‘ê·¼ ê°€ëŠ¥
allow {
    input.content.difficulty_level < difficulty_threshold
    not is_sensitive_topic(input.content.topic)
}

# ê³ ê¸‰ ì½˜í…ì¸ ëŠ” êµì‚¬ ìŠ¹ì¸ í•„ìš”
allow {
    input.content.difficulty_level >= difficulty_threshold
    input.approval.teacher_approved == true
    input.approval.approved_at != null
}

# ë¯¼ê°í•œ ì£¼ì œëŠ” êµì‚¬ ìŠ¹ì¸ í•„ìš”
allow {
    is_sensitive_topic(input.content.topic)
    input.approval.teacher_approved == true
}

# ë¯¼ê°í•œ ì£¼ì œ í™•ì¸
is_sensitive_topic(topic) if {
    topic in sensitive_topics
}

# ìŠ¹ì¸ í•„ìš” ì‚¬ìœ 
deny[msg] {
    input.content.difficulty_level >= difficulty_threshold
    input.approval.teacher_approved != true
    msg := sprintf("Advanced content (level %d) requires teacher approval", [input.content.difficulty_level])
}

deny[msg] {
    is_sensitive_topic(input.content.topic)
    input.approval.teacher_approved != true
    msg := sprintf("Sensitive topic '%s' requires teacher approval", [input.content.topic])
}
```

**AI ìƒì„± ì½˜í…ì¸  ê²€í†  ì •ì±…**:
```rego
package approval_ai_generated_content

import future.keywords.if

default allow = false

# AI ìƒì„± ì½˜í…ì¸ ëŠ” êµì‚¬ ê²€í†  í•„ìˆ˜
allow {
    input.content.source == "ai_generated"
    input.content.status == "teacher_reviewed"
    input.content.approved_by != null
}

# ì¸ê°„ì´ ì‘ì„±í•œ ê²€ì¦ëœ ì½˜í…ì¸ ëŠ” ìŠ¹ì¸ ë¶ˆí•„ìš”
allow {
    input.content.source == "human_created"
    input.content.verified == true
}

# ê²€í†  ëŒ€ê¸° ìƒíƒœ
deny[msg] {
    input.content.source == "ai_generated"
    input.content.status == "pending_review"
    msg := "AI-generated content is pending teacher review"
}

# ê²€í†  ê±°ë¶€ë¨
deny[msg] {
    input.content.source == "ai_generated"
    input.content.status == "rejected"
    msg := sprintf("Content rejected by teacher: %s", [input.content.rejection_reason])
}
```

**ê°œì¸ ì •ë³´ ì ‘ê·¼ ìŠ¹ì¸ ì •ì±…**:
```rego
package approval_personal_data_access

import future.keywords.if
import future.keywords.contains

default allow = false

# ë¯¼ê°í•œ ê°œì¸ ì •ë³´ ì¹´í…Œê³ ë¦¬
sensitive_data_categories := [
    "health_records", "counseling_records", 
    "family_information", "financial_data"
]

# ì¼ë°˜ í•™ìŠµ ë°ì´í„°ëŠ” ìŠ¹ì¸ ë¶ˆí•„ìš”
allow {
    not is_sensitive_data(input.data_category)
    input.user.role in ["teacher", "student"]
}

# ë¯¼ê°í•œ ë°ì´í„°ëŠ” í•™ë¶€ëª¨ ë™ì˜ í•„ìš”
allow {
    is_sensitive_data(input.data_category)
    input.approval.parent_consent == true
    input.approval.consent_date != null
    # ë™ì˜ëŠ” 1ë…„ ìœ íš¨
    consent_is_valid(input.approval.consent_date)
}

# ê´€ë¦¬ìëŠ” ëª¨ë“  ë°ì´í„° ì ‘ê·¼ ê°€ëŠ¥ (ê°ì‚¬ ë¡œê·¸ ê¸°ë¡)
allow {
    input.user.role == "administrator"
    input.purpose == "administrative_review"
}

is_sensitive_data(category) if {
    category in sensitive_data_categories
}

consent_is_valid(consent_date) if {
    # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë‚ ì§œ ê³„ì‚° ë¡œì§ ì‚¬ìš©
    consent_date != null
}

deny[msg] {
    is_sensitive_data(input.data_category)
    input.approval.parent_consent != true
    msg := sprintf("Access to %s requires parent consent", [input.data_category])
}

deny[msg] {
    is_sensitive_data(input.data_category)
    input.approval.parent_consent == true
    not consent_is_valid(input.approval.consent_date)
    msg := "Parent consent has expired. Please request new consent."
}
```

**ì™¸ë¶€ ë§í¬ ì ‘ê·¼ ìŠ¹ì¸ ì •ì±…**:
```rego
package approval_external_links

import future.keywords.if
import future.keywords.contains

default allow = false

# í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ ë„ë©”ì¸ (ì‚¬ì „ ìŠ¹ì¸ë¨)
whitelisted_domains := [
    "wikipedia.org", "khanacademy.org", "coursera.org",
    "edx.org", "mit.edu", "youtube.com/education"
]

# í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ ë„ë©”ì¸ì€ ìŠ¹ì¸ ë¶ˆí•„ìš”
allow {
    is_whitelisted_domain(input.external_link.url)
}

# ê¸°íƒ€ ë„ë©”ì¸ì€ êµì‚¬ ìŠ¹ì¸ í•„ìš”
allow {
    not is_whitelisted_domain(input.external_link.url)
    input.approval.teacher_approved == true
    input.approval.approved_at != null
}

is_whitelisted_domain(url) if {
    some domain in whitelisted_domains
    contains(url, domain)
}

deny[msg] {
    not is_whitelisted_domain(input.external_link.url)
    input.approval.teacher_approved != true
    msg := sprintf("External link '%s' requires teacher approval", [input.external_link.url])
}
```

#### 4.6.4 êµ¬í˜„ ë©”ì»¤ë‹ˆì¦˜

**1. ì •ì±… ì—”ì§„ í†µí•©**

ìŠ¹ì¸ ì›Œí¬í”Œë¡œìš°ë¥¼ ê´€ë¦¬í•˜ê³ , í•´ë‹¹ ì´ë²¤íŠ¸ ë°œìƒ ì‹œ ìë™ìœ¼ë¡œ ìŠ¹ì¸ ì ˆì°¨ë¥¼ íŠ¸ë¦¬ê±°í•©ë‹ˆë‹¤.

```python
# governance/backend/approval_engine.py
from enum import Enum
from typing import Optional, Dict, List
from datetime import datetime, timedelta

class ApprovalStatus(Enum):
    PENDING = "pending"
    APPROVED = "approved"
    REJECTED = "rejected"
    EXPIRED = "expired"

class ApprovalRequest:
    def __init__(
        self,
        request_id: str,
        request_type: str,
        requester_id: str,
        approver_role: str,
        content: Dict,
        reason: str = ""
    ):
        self.request_id = request_id
        self.request_type = request_type
        self.requester_id = requester_id
        self.approver_role = approver_role
        self.content = content
        self.reason = reason
        self.status = ApprovalStatus.PENDING
        self.created_at = datetime.now()
        self.approved_by: Optional[str] = None
        self.approved_at: Optional[datetime] = None
        self.rejection_reason: Optional[str] = None

class ApprovalEngine:
    def __init__(self, policy_engine, notification_service, db):
        self.policy_engine = policy_engine
        self.notification_service = notification_service
        self.db = db
    
    async def request_approval(
        self,
        request_type: str,
        requester_id: str,
        content: Dict,
        reason: str = ""
    ) -> ApprovalRequest:
        """ìŠ¹ì¸ ìš”ì²­ ìƒì„± ë° ì²˜ë¦¬"""
        
        # 1. ìŠ¹ì¸ì´ í•„ìš”í•œì§€ ì •ì±… í‰ê°€
        policy_result = await self._check_approval_required(
            request_type, requester_id, content
        )
        
        if not policy_result["approval_required"]:
            # ìŠ¹ì¸ ë¶ˆí•„ìš” - ì¦‰ì‹œ í—ˆìš©
            return self._create_auto_approved_request(
                request_type, requester_id, content
            )
        
        # 2. ìŠ¹ì¸ ìš”ì²­ ìƒì„±
        request = ApprovalRequest(
            request_id=generate_uuid(),
            request_type=request_type,
            requester_id=requester_id,
            approver_role=policy_result["approver_role"],
            content=content,
            reason=reason
        )
        
        # 3. ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
        await self.db.approval_requests.insert_one(request.__dict__)
        
        # 4. ìŠ¹ì¸ìì—ê²Œ ì•Œë¦¼ ë°œì†¡
        await self._send_approval_notification(request)
        
        # 5. ë©”íŠ¸ë¦­ ê¸°ë¡
        APPROVAL_REQUESTS.labels(
            request_type=request_type,
            approver_role=request.approver_role
        ).inc()
        
        return request
    
    async def _check_approval_required(
        self, 
        request_type: str, 
        requester_id: str, 
        content: Dict
    ) -> Dict:
        """ì •ì±… ì—”ì§„ì„ í†µí•´ ìŠ¹ì¸ í•„ìš” ì—¬ë¶€ í™•ì¸"""
        
        # ìš”ì²­ íƒ€ì…ë³„ ì •ì±… ë§¤í•‘
        policy_map = {
            "advanced_content_access": "approval_advanced_content",
            "ai_generated_content": "approval_ai_generated_content",
            "personal_data_access": "approval_personal_data_access",
            "external_link_access": "approval_external_links"
        }
        
        policy_name = policy_map.get(request_type)
        if not policy_name:
            return {"approval_required": False}
        
        # ì •ì±… í‰ê°€ (ìŠ¹ì¸ ì—†ì´)
        policy_input = {
            "content": content,
            "user": await self._get_user_info(requester_id),
            "approval": {
                "teacher_approved": False,
                "parent_consent": False
            }
        }
        
        result = await self.policy_engine.evaluate(policy_name, policy_input)
        
        if not result["allow"]:
            # ìŠ¹ì¸ í•„ìš”
            approver_role = self._determine_approver_role(request_type)
            return {
                "approval_required": True,
                "approver_role": approver_role,
                "reason": result.get("deny", ["Approval required"])[0]
            }
        
        return {"approval_required": False}
    
    def _determine_approver_role(self, request_type: str) -> str:
        """ìš”ì²­ íƒ€ì…ì— ë”°ë¥¸ ìŠ¹ì¸ì ì—­í•  ê²°ì •"""
        approver_map = {
            "advanced_content_access": "teacher",
            "ai_generated_content": "teacher",
            "personal_data_access": "parent",
            "external_link_access": "teacher"
        }
        return approver_map.get(request_type, "teacher")
    
    async def _send_approval_notification(self, request: ApprovalRequest):
        """ìŠ¹ì¸ìì—ê²Œ ì•Œë¦¼ ë°œì†¡"""
        
        # ìŠ¹ì¸ì ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        approvers = await self._get_approvers(
            request.approver_role,
            request.requester_id
        )
        
        for approver in approvers:
            # ì´ë©”ì¼ ì•Œë¦¼
            await self.notification_service.send_email(
                to=approver.email,
                subject=f"Approval Request: {request.request_type}",
                template="approval_request",
                context={
                    "request": request,
                    "requester_name": await self._get_user_name(request.requester_id),
                    "approval_link": f"/approvals/{request.request_id}"
                }
            )
            
            # ì•± í‘¸ì‹œ ì•Œë¦¼
            await self.notification_service.send_push(
                user_id=approver.id,
                title="ìƒˆë¡œìš´ ìŠ¹ì¸ ìš”ì²­",
                body=f"{request.request_type} ìŠ¹ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.",
                data={"request_id": request.request_id}
            )
            
            # Slack ì•Œë¦¼ (êµì‚¬ìš©)
            if request.approver_role == "teacher":
                await slack_notify(
                    channel="#teacher-approvals",
                    message=f"ğŸ“‹ New approval request: {request.request_type}\n"
                            f"From: {await self._get_user_name(request.requester_id)}\n"
                            f"Review: /approvals/{request.request_id}"
                )
    
    async def approve_request(
        self,
        request_id: str,
        approver_id: str,
        comments: str = ""
    ) -> bool:
        """ìŠ¹ì¸ ìš”ì²­ ìŠ¹ì¸"""
        
        # 1. ìŠ¹ì¸ ìš”ì²­ ì¡°íšŒ
        request = await self.db.approval_requests.find_one(
            {"request_id": request_id}
        )
        
        if not request or request["status"] != ApprovalStatus.PENDING.value:
            raise ValueError("Invalid or already processed approval request")
        
        # 2. ìŠ¹ì¸ì ê¶Œí•œ í™•ì¸
        approver = await self._get_user_info(approver_id)
        if approver["role"] != request["approver_role"]:
            raise PermissionError("User does not have permission to approve this request")
        
        # 3. ìŠ¹ì¸ ì²˜ë¦¬
        await self.db.approval_requests.update_one(
            {"request_id": request_id},
            {"$set": {
                "status": ApprovalStatus.APPROVED.value,
                "approved_by": approver_id,
                "approved_at": datetime.now(),
                "comments": comments
            }}
        )
        
        # 4. ìš”ì²­ìì—ê²Œ ì•Œë¦¼
        await self.notification_service.send_notification(
            user_id=request["requester_id"],
            title="ìŠ¹ì¸ ì™„ë£Œ",
            body=f"{request['request_type']} ìš”ì²­ì´ ìŠ¹ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.",
            data={"request_id": request_id}
        )
        
        # 5. ì›Œí¬í”Œë¡œìš° ë‹¤ìŒ ë‹¨ê³„ ì‹¤í–‰
        await self._execute_post_approval_workflow(request)
        
        # 6. ê°ì‚¬ ë¡œê·¸ ê¸°ë¡
        await self._log_approval_action(
            request_id=request_id,
            action="approved",
            approver_id=approver_id,
            comments=comments
        )
        
        # 7. ë©”íŠ¸ë¦­ ê¸°ë¡
        APPROVAL_DECISIONS.labels(
            request_type=request["request_type"],
            decision="approved"
        ).inc()
        
        return True
    
    async def reject_request(
        self,
        request_id: str,
        approver_id: str,
        reason: str
    ) -> bool:
        """ìŠ¹ì¸ ìš”ì²­ ê±°ë¶€"""
        
        # 1. ìŠ¹ì¸ ìš”ì²­ ì¡°íšŒ
        request = await self.db.approval_requests.find_one(
            {"request_id": request_id}
        )
        
        if not request or request["status"] != ApprovalStatus.PENDING.value:
            raise ValueError("Invalid or already processed approval request")
        
        # 2. ìŠ¹ì¸ì ê¶Œí•œ í™•ì¸
        approver = await self._get_user_info(approver_id)
        if approver["role"] != request["approver_role"]:
            raise PermissionError("User does not have permission to reject this request")
        
        # 3. ê±°ë¶€ ì²˜ë¦¬
        await self.db.approval_requests.update_one(
            {"request_id": request_id},
            {"$set": {
                "status": ApprovalStatus.REJECTED.value,
                "rejected_by": approver_id,
                "rejected_at": datetime.now(),
                "rejection_reason": reason
            }}
        )
        
        # 4. ìš”ì²­ìì—ê²Œ ì•Œë¦¼
        await self.notification_service.send_notification(
            user_id=request["requester_id"],
            title="ìŠ¹ì¸ ê±°ë¶€",
            body=f"{request['request_type']} ìš”ì²­ì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤.",
            data={
                "request_id": request_id,
                "reason": reason
            }
        )
        
        # 5. ê°ì‚¬ ë¡œê·¸ ê¸°ë¡
        await self._log_approval_action(
            request_id=request_id,
            action="rejected",
            approver_id=approver_id,
            reason=reason
        )
        
        # 6. ë©”íŠ¸ë¦­ ê¸°ë¡
        APPROVAL_DECISIONS.labels(
            request_type=request["request_type"],
            decision="rejected"
        ).inc()
        
        return True
    
    async def _execute_post_approval_workflow(self, request: Dict):
        """ìŠ¹ì¸ í›„ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰"""
        
        workflow_handlers = {
            "advanced_content_access": self._grant_content_access,
            "ai_generated_content": self._publish_content,
            "personal_data_access": self._grant_data_access,
            "external_link_access": self._enable_external_link
        }
        
        handler = workflow_handlers.get(request["request_type"])
        if handler:
            await handler(request)
```

**2. ì•Œë¦¼ ì‹œìŠ¤í…œ**

```python
# api/services/notification_service.py
class NotificationService:
    def __init__(self, email_client, push_client, sms_client):
        self.email_client = email_client
        self.push_client = push_client
        self.sms_client = sms_client
    
    async def send_notification(
        self,
        user_id: str,
        title: str,
        body: str,
        channels: List[str] = ["push", "email"],
        data: Dict = None
    ):
        """ë‹¤ì¤‘ ì±„ë„ ì•Œë¦¼ ë°œì†¡"""
        
        user = await get_user(user_id)
        
        if "push" in channels and user.push_enabled:
            await self.send_push(user_id, title, body, data)
        
        if "email" in channels and user.email_enabled:
            await self.send_email(
                to=user.email,
                subject=title,
                template="notification",
                context={"title": title, "body": body, "data": data}
            )
        
        if "sms" in channels and user.sms_enabled:
            await self.send_sms(user.phone, f"{title}: {body}")
```

**3. ìŠ¹ì¸ ì¸í„°í˜ì´ìŠ¤ API**

```python
# api/routes/approvals.py
from fastapi import APIRouter, Depends, HTTPException
from pydantic import BaseModel

router = APIRouter()

class ApprovalRequestCreate(BaseModel):
    request_type: str
    content: Dict
    reason: str = ""

class ApprovalDecision(BaseModel):
    decision: str  # "approve" or "reject"
    comments: str = ""
    reason: str = ""  # for rejection

@router.post("/api/approvals/request")
async def create_approval_request(
    request: ApprovalRequestCreate,
    current_user: User = Depends(get_current_user)
):
    """ìŠ¹ì¸ ìš”ì²­ ìƒì„±"""
    approval_engine = ApprovalEngine(opa_engine, notification_service, db)
    
    approval_request = await approval_engine.request_approval(
        request_type=request.request_type,
        requester_id=current_user.id,
        content=request.content,
        reason=request.reason
    )
    
    return {
        "request_id": approval_request.request_id,
        "status": approval_request.status.value,
        "message": "Approval request created successfully" 
                   if approval_request.status == ApprovalStatus.PENDING
                   else "Request auto-approved"
    }

@router.get("/api/approvals/pending")
async def get_pending_approvals(
    current_user: User = Depends(get_current_user)
):
    """í˜„ì¬ ì‚¬ìš©ìì—ê²Œ í• ë‹¹ëœ ëŒ€ê¸° ì¤‘ì¸ ìŠ¹ì¸ ìš”ì²­ ì¡°íšŒ"""
    
    # ì—­í• ì— ë”°ë¥¸ í•„í„°ë§
    approvals = await db.approval_requests.find({
        "approver_role": current_user.role,
        "status": ApprovalStatus.PENDING.value
    }).sort("created_at", -1).to_list(100)
    
    return approvals

@router.post("/api/approvals/{request_id}/decide")
async def decide_approval(
    request_id: str,
    decision: ApprovalDecision,
    current_user: User = Depends(get_current_user)
):
    """ìŠ¹ì¸ ìš”ì²­ì— ëŒ€í•œ ê²°ì • (ìŠ¹ì¸ ë˜ëŠ” ê±°ë¶€)"""
    approval_engine = ApprovalEngine(opa_engine, notification_service, db)
    
    try:
        if decision.decision == "approve":
            await approval_engine.approve_request(
                request_id=request_id,
                approver_id=current_user.id,
                comments=decision.comments
            )
            return {"success": True, "message": "Request approved"}
        
        elif decision.decision == "reject":
            if not decision.reason:
                raise HTTPException(
                    status_code=400,
                    detail="Rejection reason is required"
                )
            
            await approval_engine.reject_request(
                request_id=request_id,
                approver_id=current_user.id,
                reason=decision.reason
            )
            return {"success": True, "message": "Request rejected"}
        
        else:
            raise HTTPException(
                status_code=400,
                detail="Invalid decision. Must be 'approve' or 'reject'"
            )
    
    except PermissionError as e:
        raise HTTPException(status_code=403, detail=str(e))
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))

@router.get("/api/approvals/history")
async def get_approval_history(
    current_user: User = Depends(get_current_user),
    days: int = 30
):
    """ìŠ¹ì¸ ì´ë ¥ ì¡°íšŒ"""
    
    start_date = datetime.now() - timedelta(days=days)
    
    history = await db.approval_requests.find({
        "$or": [
            {"requester_id": current_user.id},
            {"approved_by": current_user.id},
            {"rejected_by": current_user.id}
        ],
        "created_at": {"$gte": start_date}
    }).sort("created_at", -1).to_list(200)
    
    return history
```

#### 4.6.5 ìŠ¹ì¸ ì›Œí¬í”Œë¡œìš° ì˜ˆì‹œ

**ì‹œë‚˜ë¦¬ì˜¤: ê³ ê¸‰ ì½˜í…ì¸  ì ‘ê·¼ ìš”ì²­**

```python
# ì‹¤ì œ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì˜ˆì‹œ
async def student_requests_advanced_content(student_id: str, content_id: str):
    """í•™ìƒì´ ê³ ê¸‰ ì½˜í…ì¸  ì ‘ê·¼ ìš”ì²­"""
    
    # 1. ì½˜í…ì¸  ì •ë³´ ì¡°íšŒ
    content = await db.contents.find_one({"id": content_id})
    
    # 2. ìŠ¹ì¸ ìš”ì²­ ìƒì„±
    approval_engine = ApprovalEngine(opa_engine, notification_service, db)
    
    request = await approval_engine.request_approval(
        request_type="advanced_content_access",
        requester_id=student_id,
        content={
            "content_id": content_id,
            "difficulty_level": content["difficulty_level"],
            "topic": content["topic"],
            "title": content["title"]
        },
        reason="Student requested access to advanced mathematics content"
    )
    
    # 3. ìŠ¹ì¸ ëŒ€ê¸° ìƒíƒœ ë°˜í™˜
    if request.status == ApprovalStatus.PENDING:
        return {
            "access_granted": False,
            "message": "Your request has been sent to your teacher for approval.",
            "request_id": request.request_id
        }
    else:
        # ìë™ ìŠ¹ì¸ëœ ê²½ìš°
        return {
            "access_granted": True,
            "message": "Access granted to content.",
            "content": content
        }

# êµì‚¬ê°€ ìŠ¹ì¸í•œ í›„
async def teacher_approves_content_access(request_id: str, teacher_id: str):
    """êµì‚¬ê°€ ì½˜í…ì¸  ì ‘ê·¼ ìŠ¹ì¸"""
    
    approval_engine = ApprovalEngine(opa_engine, notification_service, db)
    
    # ìŠ¹ì¸ ì²˜ë¦¬
    await approval_engine.approve_request(
        request_id=request_id,
        approver_id=teacher_id,
        comments="Content is appropriate for student's learning level"
    )
    
    # ìë™ìœ¼ë¡œ ë‹¤ìŒ ë™ì‘ ì‹¤í–‰:
    # - í•™ìƒì—ê²Œ ì½˜í…ì¸  ì ‘ê·¼ ê¶Œí•œ ë¶€ì—¬
    # - í•™ìƒì—ê²Œ ì•Œë¦¼ ë°œì†¡
    # - ê°ì‚¬ ë¡œê·¸ ê¸°ë¡
```

**ì „ì²´ ì›Œí¬í”Œë¡œìš°**:

```
1. í•™ìƒì´ ê³ ê¸‰ ì½˜í…ì¸  ì ‘ê·¼ ìš”ì²­
   â†“
2. ì‹œìŠ¤í…œì´ ì •ì±… ì—”ì§„ì„ í†µí•´ ìŠ¹ì¸ í•„ìš” ì—¬ë¶€ í™•ì¸
   - ë‚œì´ë„ ë ˆë²¨ 8 ì´ìƒ â†’ ìŠ¹ì¸ í•„ìš”
   â†“
3. ìŠ¹ì¸ ìš”ì²­ ìƒì„± ë° ì €ì¥
   â†“
4. êµì‚¬ì—ê²Œ ì•Œë¦¼ ë°œì†¡
   - ì´ë©”ì¼: "ìƒˆë¡œìš´ ìŠ¹ì¸ ìš”ì²­"
   - ì•± í‘¸ì‹œ: "í•™ìƒì´ ê³ ê¸‰ ì½˜í…ì¸  ì ‘ê·¼ ìš”ì²­"
   - Slack: "#teacher-approvals ì±„ë„"
   â†“
5. êµì‚¬ê°€ ìŠ¹ì¸ ì¸í„°í˜ì´ìŠ¤ì—ì„œ ìš”ì²­ í™•ì¸
   - ì½˜í…ì¸  ìƒì„¸ ì •ë³´ ê²€í† 
   - í•™ìƒì˜ í•™ìŠµ ë ˆë²¨ í™•ì¸
   â†“
6. êµì‚¬ê°€ ìŠ¹ì¸ ë˜ëŠ” ê±°ë¶€ ê²°ì •
   - ìŠ¹ì¸: "í•™ìƒì˜ ìˆ˜ì¤€ì— ì í•©í•¨"
   - ê±°ë¶€: "ì•„ì§ ì¤€ë¹„ê°€ ë˜ì§€ ì•ŠìŒ"
   â†“
7. ì‹œìŠ¤í…œì´ ê²°ì •ì— ë”°ë¼ ìë™ ì²˜ë¦¬
   ìŠ¹ì¸ ì‹œ:
   - í•™ìƒì—ê²Œ ì½˜í…ì¸  ì ‘ê·¼ ê¶Œí•œ ë¶€ì—¬
   - í•™ìƒì—ê²Œ ìŠ¹ì¸ ì•Œë¦¼ ë°œì†¡
   - ì½˜í…ì¸  ì œê³µ
   
   ê±°ë¶€ ì‹œ:
   - í•™ìƒì—ê²Œ ê±°ë¶€ ì•Œë¦¼ ë°œì†¡ (ì‚¬ìœ  í¬í•¨)
   - ëŒ€ì²´ ì½˜í…ì¸  ì¶”ì²œ
   â†“
8. ëª¨ë“  ìŠ¹ì¸ í–‰ìœ„ë¥¼ ê°ì‚¬ ë¡œê·¸ì— ê¸°ë¡
   - íƒ€ì„ìŠ¤íƒ¬í”„
   - ìš”ì²­ì/ìŠ¹ì¸ì ID
   - ê²°ì • ë° ì‚¬ìœ 
   - ê´€ë ¨ ì½˜í…ì¸  ì •ë³´
```

#### 4.6.6 ê°ì‚¬ ì¶”ì  (Audit Trail)

ëª¨ë“  ìŠ¹ì¸ í–‰ìœ„ëŠ” ìƒì„¸í•˜ê²Œ ê¸°ë¡ë˜ì–´ ì¶”í›„ ê°ì‚¬ ê°€ëŠ¥í•˜ë„ë¡ í•©ë‹ˆë‹¤.

```python
# governance/backend/audit_service.py
class ApprovalAuditService:
    def __init__(self, db, elasticsearch_client=None):
        self.db = db
        self.es = elasticsearch_client
    
    async def log_approval_action(
        self,
        request_id: str,
        action: str,  # "created", "approved", "rejected", "expired"
        actor_id: str,
        actor_role: str,
        details: Dict = None
    ):
        """ìŠ¹ì¸ ê´€ë ¨ í–‰ìœ„ ê°ì‚¬ ë¡œê·¸ ê¸°ë¡"""
        
        audit_log = {
            "timestamp": datetime.now(),
            "event_type": "approval_action",
            "request_id": request_id,
            "action": action,
            "actor_id": actor_id,
            "actor_role": actor_role,
            "actor_name": await self._get_user_name(actor_id),
            "details": details or {},
            "ip_address": get_client_ip(),
            "user_agent": get_user_agent()
        }
        
        # MongoDBì— ì €ì¥
        await self.db.audit_logs.insert_one(audit_log)
        
        # Elasticsearchì— ì €ì¥ (ê²€ìƒ‰ ë° ë¶„ì„ìš©)
        if self.es:
            await self.es.index(
                index="approval-audit-logs",
                body=audit_log
            )
        
        # êµ¬ì¡°í™”ëœ ë¡œê¹…
        logger.info(
            "Approval action recorded",
            extra={
                "request_id": request_id,
                "action": action,
                "actor": actor_id,
                "role": actor_role
            }
        )
    
    async def get_approval_audit_trail(
        self,
        request_id: str
    ) -> List[Dict]:
        """íŠ¹ì • ìŠ¹ì¸ ìš”ì²­ì˜ ì „ì²´ ê°ì‚¬ ì¶”ì  ì¡°íšŒ"""
        
        audit_trail = await self.db.audit_logs.find({
            "request_id": request_id
        }).sort("timestamp", 1).to_list(None)
        
        return audit_trail
    
    async def generate_approval_report(
        self,
        start_date: datetime,
        end_date: datetime,
        approver_role: str = None
    ) -> Dict:
        """ìŠ¹ì¸ í™œë™ ë³´ê³ ì„œ ìƒì„±"""
        
        query = {
            "timestamp": {"$gte": start_date, "$lte": end_date},
            "event_type": "approval_action"
        }
        
        if approver_role:
            query["actor_role"] = approver_role
        
        # ìŠ¹ì¸ í†µê³„
        logs = await self.db.audit_logs.find(query).to_list(None)
        
        stats = {
            "total_requests": 0,
            "approved": 0,
            "rejected": 0,
            "pending": 0,
            "by_type": {},
            "by_approver": {},
            "avg_approval_time": timedelta(0)
        }
        
        approval_times = []
        
        for log in logs:
            if log["action"] == "created":
                stats["total_requests"] += 1
                request_type = log["details"].get("request_type", "unknown")
                stats["by_type"][request_type] = stats["by_type"].get(request_type, 0) + 1
            
            elif log["action"] == "approved":
                stats["approved"] += 1
                approver = log["actor_name"]
                stats["by_approver"][approver] = stats["by_approver"].get(approver, 0) + 1
                
                # ìŠ¹ì¸ ì‹œê°„ ê³„ì‚° (ìš”ì²­ ìƒì„± ~ ìŠ¹ì¸)
                created_log = await self.db.audit_logs.find_one({
                    "request_id": log["request_id"],
                    "action": "created"
                })
                if created_log:
                    approval_time = log["timestamp"] - created_log["timestamp"]
                    approval_times.append(approval_time)
            
            elif log["action"] == "rejected":
                stats["rejected"] += 1
        
        # í‰ê·  ìŠ¹ì¸ ì‹œê°„ ê³„ì‚°
        if approval_times:
            stats["avg_approval_time"] = sum(approval_times, timedelta(0)) / len(approval_times)
        
        return stats
```

**Prometheus ë©”íŠ¸ë¦­**:

```python
# governance/backend/metrics.py
APPROVAL_REQUESTS = Counter(
    'approval_requests_total',
    'Total approval requests',
    ['request_type', 'approver_role']
)

APPROVAL_DECISIONS = Counter(
    'approval_decisions_total',
    'Total approval decisions',
    ['request_type', 'decision']
)

APPROVAL_PROCESSING_TIME = Histogram(
    'approval_processing_time_seconds',
    'Time taken to process approval requests',
    ['request_type'],
    buckets=[60, 300, 900, 1800, 3600, 7200, 86400]  # 1ë¶„ ~ 1ì¼
)

PENDING_APPROVALS = Gauge(
    'pending_approvals_count',
    'Current number of pending approval requests',
    ['approver_role']
)
```

**Grafana ëŒ€ì‹œë³´ë“œ**:

```yaml
# Grafana Dashboard: Approval Workflow Monitoring
panels:
  - title: "Approval Requests (Last 7 days)"
    query: |
      sum(increase(approval_requests_total[7d])) by (request_type)
  
  - title: "Approval Decision Rate"
    query: |
      sum(rate(approval_decisions_total{decision="approved"}[1h]))
        /
      sum(rate(approval_requests_total[1h]))
  
  - title: "Average Approval Processing Time"
    query: |
      avg(approval_processing_time_seconds) by (request_type)
  
  - title: "Pending Approvals"
    query: |
      pending_approvals_count
```

ì´ëŸ¬í•œ ìŠ¹ì¸/ì›Œí¬í”Œë¡œ ì •ì±…ì€ DreamSeedAIê°€ ì•ˆì „í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” í•™ìŠµ í™˜ê²½ì„ ì œê³µí•˜ëŠ” ë° ì¤‘ìš”í•œ ì—­í• ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì¸ê°„ ê°ë…ê³¼ AI ìë™í™”ì˜ ê· í˜•ì„ í†µí•´ íš¨ìœ¨ì„±ê³¼ ì•ˆì „ì„±ì„ ë™ì‹œì— í™•ë³´í•©ë‹ˆë‹¤.

---

## 5. ì •ì±… ìƒëª…ì£¼ê¸° ê´€ë¦¬

### 5.1 ì •ì±… ê°œë°œ

1. **ì •ì±… ì‘ì„±**: Rego ì–¸ì–´ë¡œ ì •ì±… ê·œì¹™ ì‘ì„±
2. **ë‹¨ìœ„ í…ŒìŠ¤íŠ¸**: OPA Test Frameworkë¡œ ì •ì±… í…ŒìŠ¤íŠ¸
3. **ì‹œë®¬ë ˆì´ì…˜**: ì‹¤ì œ ë°ì´í„°ë¡œ ì •ì±… ì‹œë®¬ë ˆì´ì…˜

**í…ŒìŠ¤íŠ¸ ì˜ˆì‹œ**:
```rego
# governance/bundles/phase0_test.rego
test_teacher_can_access_own_class {
    allow with input as {
        "user": {"role": "teacher", "class_id": "A1"},
        "student": {"class_id": "A1"}
    }
}

test_teacher_cannot_access_other_class {
    not allow with input as {
        "user": {"role": "teacher", "class_id": "A1"},
        "student": {"class_id": "B1"}
    }
}
```

### 5.2 ì •ì±… ë°°í¬

**ë°°í¬ í”„ë¡œì„¸ìŠ¤**:
```bash
# 1. ì •ì±… ì»´íŒŒì¼
python governance/scripts/compile.py

# 2. í…ŒìŠ¤íŠ¸ ì‹¤í–‰
opa test governance/bundles/

# 3. ì»¤ë°‹ ë° í‘¸ì‹œ
git add governance/compiled/
git commit -m "feat(policy): Add student data access policy"
git push

# 4. Kubernetes ë°°í¬ (Kustomize)
kubectl apply -k ops/k8s/governance/overlays/phase0/

# 5. ê²€ì¦
bash ops/k8s/governance/monitoring-validation.sh
```

**í™˜ê²½ë³„ ë°°í¬**:
*   **Dev**: ê°œë°œ í™˜ê²½ì—ì„œ ë¨¼ì € í…ŒìŠ¤íŠ¸
*   **Staging**: í”„ë¡œë•ì…˜ ìœ ì‚¬ í™˜ê²½ì—ì„œ ê²€ì¦
*   **Production**: ë‹¨ê³„ì  ë¡¤ì•„ì›ƒ (Canary Deployment)

### 5.3 ì •ì±… ëª¨ë‹ˆí„°ë§

**ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§**:
```bash
# Prometheus ì¿¼ë¦¬
rate(governance_policy_deny_total[5m])  # ì •ì±… ê±°ë¶€ìœ¨
histogram_quantile(0.95, governance_policy_evaluation_duration_bucket)  # P95 ì§€ì—°ì‹œê°„
```

**Grafana ëŒ€ì‹œë³´ë“œ**:
*   ì •ì±… í‰ê°€ ì„±ê³µ/ì‹¤íŒ¨ìœ¨
*   ì •ì±…ë³„ ê±°ë¶€ ì¶”ì´
*   ì •ì±… í‰ê°€ ì§€ì—°ì‹œê°„ ë¶„í¬

**Slack ì•Œë¦¼**:
*   Critical: ì •ì±… ë²ˆë“¤ ë¡œë“œ ì‹¤íŒ¨
*   Warning: ì •ì±… ê±°ë¶€ìœ¨ ê¸‰ì¦

### 5.4 ì •ì±… ê°ì‚¬

**ê°ì‚¬ í•­ëª©**:
*   ì •ì±… ë³€ê²½ ì´ë ¥ (Git ì»¤ë°‹ ë¡œê·¸)
*   ì •ì±… í‰ê°€ ê²°ê³¼ (Prometheus ë©”íŠ¸ë¦­)
*   ì •ì±… ê±°ë¶€ ì‚¬ë¡€ (êµ¬ì¡°í™”ëœ ë¡œê·¸)

**ê·œì œ ì¤€ìˆ˜**:
*   GDPR: ê°œì¸ì •ë³´ ì²˜ë¦¬ ì •ì±… ê°ì‚¬
*   êµìœ¡ë²•: í•™ìƒ ë°ì´í„° ë³´í˜¸ ì •ì±… ê°ì‚¬

---

## 6. ê³ ê¸‰ ê¸°ëŠ¥

### 6.1 Dynamic Policy Loading

**Hot Reload**:
*   ConfigMap ë³€ê²½ ê°ì§€
*   ìë™ ì •ì±… ë²ˆë“¤ ë¦¬ë¡œë“œ
*   ë¬´ì¤‘ë‹¨ ì •ì±… ì—…ë°ì´íŠ¸

**êµ¬í˜„**:
```python
# governance/backend/policy_controller.py
async def reload_bundle():
    new_hash = await get_configmap_hash()
    if new_hash != current_hash:
        await opa_client.put("/v1/policies/main", policy_bundle)
        GOVERNANCE_BUNDLE_RELOAD.inc()
        logger.info("Policy bundle reloaded", extra={"hash": new_hash})
```

### 6.2 Policy as Code

**GitOps ì›Œí¬í”Œë¡œìš°**:
*   ì •ì±… ë³€ê²½ â†’ Git ì»¤ë°‹
*   Pull Request â†’ ì½”ë“œ ë¦¬ë·°
*   Merge â†’ ArgoCD ìë™ ë°°í¬

**ì´ì **:
*   ë²„ì „ ê´€ë¦¬
*   ë³€ê²½ ì´ë ¥ ì¶”ì 
*   ë¡¤ë°± ê°€ëŠ¥
*   ì½”ë“œ ë¦¬ë·°

### 6.3 A/B Testing

**ì •ì±… ì‹¤í—˜**:
*   ìƒˆë¡œìš´ ì •ì±…ì„ ì¼ë¶€ ì‚¬ìš©ìì—ê²Œë§Œ ì ìš©
*   ë©”íŠ¸ë¦­ ë¹„êµ (ê±°ë¶€ìœ¨, ì§€ì—°ì‹œê°„, ì‚¬ìš©ì ë§Œì¡±ë„)
*   ì ì§„ì  ë¡¤ì•„ì›ƒ

**êµ¬í˜„**:
```rego
package ab_testing

allow {
    # 50% ì‚¬ìš©ìì—ê²Œë§Œ ìƒˆ ì •ì±… ì ìš©
    hash(input.user.id) % 100 < 50
    new_policy_allow
}

allow {
    hash(input.user.id) % 100 >= 50
    old_policy_allow
}
```

### 6.4 Machine Learning Integration

**ML ê¸°ë°˜ ì •ì±…**:
*   ì´ìƒ íƒì§€: ë¹„ì •ìƒì ì¸ ë°ì´í„° ì ‘ê·¼ íŒ¨í„´ íƒì§€
*   ì¶”ì²œ: ì‚¬ìš©ì í–‰ë™ ê¸°ë°˜ ì •ì±… ì¶”ì²œ
*   ì˜ˆì¸¡: ì •ì±… ìœ„ë°˜ ì‚¬ì „ ì˜ˆì¸¡

**êµ¬í˜„ ê³„íš**:
```python
async def ml_enhanced_policy(input_data: dict) -> bool:
    # 1. ê¸°ë³¸ ê·œì¹™ í‰ê°€
    base_result = await evaluate_policy("base_policy", input_data)
    
    # 2. ML ëª¨ë¸ í‰ê°€
    ml_score = await ml_model.predict(input_data)
    
    # 3. ê²°í•© ê²°ì •
    return base_result["allow"] and ml_score > 0.8
```

---

## 7. í˜„ì¬ êµ¬í˜„ ìƒíƒœ

### âœ… ì™„ì„±ëœ ê¸°ëŠ¥

*   **OPA ì •ì±… ì—”ì§„**: 3ê°œ ì •ì±… ë²ˆë“¤ (phase0, phase1, production)
*   **ë°±ì—”ë“œ í†µí•©**: 34ê°œ ì—”ë“œí¬ì¸íŠ¸ ì •ì±… ë§¤í•‘
*   **ë¯¸ë“¤ì›¨ì–´**: ìë™ ì •ì±… í‰ê°€ ë° ì‹¤í–‰
*   **Hot Reload**: ConfigMap ê¸°ë°˜ ë¬´ì¤‘ë‹¨ ì—…ë°ì´íŠ¸
*   **ëª¨ë‹ˆí„°ë§**: 19ê°œ ë©”íŠ¸ë¦­, 15ê°œ ì•Œë¦¼ ê·œì¹™
*   **ëŒ€ì‹œë³´ë“œ**: Grafana 16 íŒ¨ë„
*   **ì•Œë¦¼**: Slack í†µí•© (Alertmanager)
*   **ë¬¸ì„œí™”**: 14ê°œ ë¬¸ì„œ, 3,500+ ë¼ì¸

### ğŸš§ ê°œë°œ ì˜ˆì • ê¸°ëŠ¥

*   **ì •ì±… ê´€ë¦¬ UI**: Web ê¸°ë°˜ ì •ì±… í¸ì§‘ ì¸í„°í˜ì´ìŠ¤
*   **ìŠ¹ì¸ ì›Œí¬í”Œë¡œìš°**: ì •ì±… ë³€ê²½ ìŠ¹ì¸ í”„ë¡œì„¸ìŠ¤
*   **A/B í…ŒìŠ¤íŒ…**: ì •ì±… ì‹¤í—˜ í”„ë ˆì„ì›Œí¬
*   **ML í†µí•©**: ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë°˜ ì •ì±… ì˜ì‚¬ê²°ì •
*   **ê°ì‚¬ ëŒ€ì‹œë³´ë“œ**: ì •ì±… ê°ì‚¬ ì „ìš© ëŒ€ì‹œë³´ë“œ

---

## 8. ì°¸ê³  ìë£Œ

**ì½”ë“œ**:
*   `governance/bundles/`: OPA ì •ì±… ì†ŒìŠ¤ ì½”ë“œ
*   `governance/backend/`: FastAPI ë°±ì—”ë“œ í†µí•©
*   `ops/k8s/governance/`: Kubernetes ë°°í¬ ë§¤ë‹ˆí˜ìŠ¤íŠ¸

**ë¬¸ì„œ**:
*   `ops/k8s/governance/DEPLOYMENT_RUNBOOK.md`: ë°°í¬ ê°€ì´ë“œ
*   `ops/k8s/governance/MONITORING_VERIFICATION.md`: ëª¨ë‹ˆí„°ë§ ê²€ì¦
*   `infra/monitoring/alertmanager/QUICKSTART_SLACK.md`: Slack ì•Œë¦¼ ì„¤ì •

**ì™¸ë¶€ ë¬¸ì„œ**:
*   [Open Policy Agent ê³µì‹ ë¬¸ì„œ](https://www.openpolicyagent.org/docs/)
*   [Rego ì–¸ì–´ ê°€ì´ë“œ](https://www.openpolicyagent.org/docs/latest/policy-language/)
*   [OPA Kubernetes Tutorial](https://www.openpolicyagent.org/docs/latest/kubernetes-tutorial/)

---

**ì‘ì„±ì¼**: 2025-11-08  
**ë²„ì „**: 1.0  
**ìƒíƒœ**: Production-Ready
