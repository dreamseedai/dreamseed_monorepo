# DreamSeedAI: ì‹œìŠ¤í…œ ê³„ì¸µ - í•µì‹¬ ìš”ì•½ ë° ê²°ë¡ 

ì‹œìŠ¤í…œ ê³„ì¸µì€ DreamSeedAIì˜ **ë‘ë‡Œì™€ ê·¼ìœ¡**ì…ë‹ˆë‹¤. ì´ ê³„ì¸µì—ì„œ ì‹¤ì œë¡œ AI ëª¨ë¸ì´ ì‹¤í–‰ë˜ê³ , ë°ì´í„°ê°€ ì €ì¥/ì²˜ë¦¬ë˜ë©°, ì‚¬ìš©ìì—ê²Œ ê°€ì¹˜ë¥¼ ì œê³µí•˜ëŠ” ê¸°ëŠ¥ì´ ìˆ˜í–‰ë©ë‹ˆë‹¤. ê±°ë²„ë„ŒìŠ¤ì™€ ì •ì±…ì˜ ìš”êµ¬ì‚¬í•­ì€ ì´ ê³„ì¸µì—ì„œ êµ¬í˜„ë˜ê³  ì¤€ìˆ˜ë©ë‹ˆë‹¤.

---

## ëª©ì°¨

1. [í•µì‹¬ ê¸°ëŠ¥](#1-í•µì‹¬ ê¸°ëŠ¥)
2. [ì •ì±… ì¤€ìˆ˜ ë©”ì»¤ë‹ˆì¦˜](#2-ì •ì±…-ì¤€ìˆ˜-ë©”ì»¤ë‹ˆì¦˜)
3. [ì•„í‚¤í…ì²˜ íŠ¹ì§•](#3-ì•„í‚¤í…ì²˜-íŠ¹ì§•)
4. [ê¸°ìˆ  ìŠ¤íƒ í†µí•©](#4-ê¸°ìˆ -ìŠ¤íƒ-í†µí•©)
5. [ê²°ë¡ ](#5-ê²°ë¡ )

---

## 1. í•µì‹¬ ê¸°ëŠ¥

### 1.1 ë°ì´í„° ê´€ë¦¬

ì‹œìŠ¤í…œ ê³„ì¸µì€ DreamSeedAIì˜ ëª¨ë“  ë°ì´í„°ë¥¼ ì•ˆì „í•˜ê³  íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬í•©ë‹ˆë‹¤.

```python
# ë°ì´í„° ê´€ë¦¬ì˜ í•µì‹¬ ì›ì¹™
class DataManagementPrinciples:
    """
    DreamSeedAI ë°ì´í„° ê´€ë¦¬ ì›ì¹™
    """
    principles = {
        "user_data": {
            "description": "ì‚¬ìš©ì ì •ë³´, í”„ë¡œí•„, ì¸ì¦ ë°ì´í„°",
            "storage": "PostgreSQL users í…Œì´ë¸”",
            "encryption": "bcrypt (ë¹„ë°€ë²ˆí˜¸), AES-256 (ë¯¼ê°ì •ë³´)",
            "retention": "GDPR/COPPA ì¤€ìˆ˜ (ì‚¬ìš©ì ìš”ì²­ ì‹œ ì‚­ì œ)"
        },
        "learning_data": {
            "description": "í•™ìŠµ ê¸°ë¡, ì‹œí—˜ ì‘ë‹µ, ì§„ë„ ë°ì´í„°",
            "storage": "PostgreSQL + Redis (ìºì‹±)",
            "analytics": "ì‹¤ì‹œê°„ í•™ìŠµ ë¶„ì„ íŒŒì´í”„ë¼ì¸",
            "backup": "ì¼ì¼ ë°±ì—…, 7ì¼ ë³´ê´€"
        },
        "content": {
            "description": "ë¬¸í•­, êµìœ¡ ìë£Œ, ë©€í‹°ë¯¸ë””ì–´",
            "storage": "PostgreSQL (ë©”íƒ€ë°ì´í„°) + MinIO/S3 (íŒŒì¼)",
            "versioning": "Git-like ë²„ì „ ê´€ë¦¬",
            "search": "Elasticsearch ì „ë¬¸ ê²€ìƒ‰"
        },
        "ai_models": {
            "description": "IRT íŒŒë¼ë¯¸í„°, íŠœí„° ëª¨ë¸ ê°€ì¤‘ì¹˜",
            "storage": "PostgreSQL (ë©”íƒ€) + íŒŒì¼ ì‹œìŠ¤í…œ (ëª¨ë¸)",
            "versioning": "MLflow ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬",
            "deployment": "ì»¨í…Œì´ë„ˆ ê¸°ë°˜ ë°°í¬"
        }
    }
```

**ì£¼ìš” íŠ¹ì§•**:

- **ë©€í‹° í…Œë„Œì‹œ**: ê¸°ê´€ë³„ ë°ì´í„° ê²©ë¦¬ (`org_id` ê¸°ë°˜)
- **ACID íŠ¸ëœì­ì…˜**: PostgreSQLì„ í†µí•œ ë°ì´í„° ì¼ê´€ì„± ë³´ì¥
- **í™•ì¥ì„±**: ì½ê¸° ë³µì œë³¸, ìƒ¤ë”©ì„ í†µí•œ ìˆ˜í‰ í™•ì¥
- **ë°±ì—…/ë³µêµ¬**: ìë™í™”ëœ ë°±ì—… ë° ì¬í•´ ë³µêµ¬ ê³„íš

### 1.2 AI ì—”ì§„

DreamSeedAIì˜ í•µì‹¬ ì§€ëŠ¥ì„ ì œê³µí•˜ëŠ” AI ì—”ì§„ë“¤ì…ë‹ˆë‹¤.

```python
# AI ì—”ì§„ ê°œìš”
class AIEngineOverview:
    """
    DreamSeedAI AI ì—”ì§„ êµ¬ì„±
    """
    engines = {
        "irt_engine": {
            "name": "ì ì‘í˜• ì‹œí—˜ ì—”ì§„",
            "models": ["1PL", "2PL", "3PL IRT"],
            "algorithms": ["CAT (Computerized Adaptive Testing)", "MLE", "EAP"],
            "framework": "scipy, statsmodels",
            "performance": "ì‹¤ì‹œê°„ ëŠ¥ë ¥ì¹˜ ì¶”ì • (<100ms)"
        },
        "nlp_engine": {
            "name": "ìì—°ì–´ ì²˜ë¦¬ ì—”ì§„",
            "models": ["GPT-4", "Gemini", "Custom Fine-tuned"],
            "use_cases": ["AI íŠœí„°", "ìë™ ì±„ì ", "í”¼ë“œë°± ìƒì„±"],
            "framework": "OpenAI API, LangChain",
            "safety": "ì½˜í…ì¸  í•„í„°ë§, ìœ í•´ì„± ê²€ì¶œ"
        },
        "recommendation_engine": {
            "name": "í•™ìŠµ ì¶”ì²œ ì—”ì§„",
            "algorithms": ["í˜‘ì—… í•„í„°ë§", "ì½˜í…ì¸  ê¸°ë°˜ í•„í„°ë§", "í•˜ì´ë¸Œë¦¬ë“œ"],
            "features": ["ë‹¤ìŒ ë¬¸í•­ ì¶”ì²œ", "í•™ìŠµ ê²½ë¡œ ì œì•ˆ"],
            "framework": "scikit-learn, surprise",
            "optimization": "ë² ì´ì§€ì•ˆ ìµœì í™”"
        },
        "analytics_engine": {
            "name": "í•™ìŠµ ë¶„ì„ ì—”ì§„",
            "models": ["ì„ í˜• íšŒê·€", "ARIMA", "í˜¼í•© íš¨ê³¼ ëª¨ë¸"],
            "outputs": ["ëŠ¥ë ¥ ê¶¤ì ", "ì„±ì¥ ì˜ˆì¸¡", "ë¦¬ìŠ¤í¬ íƒì§€"],
            "framework": "statsmodels, scikit-learn",
            "visualization": "Quarto, Matplotlib"
        },
        "anomaly_detection": {
            "name": "ì´ìƒ íƒì§€ ì—”ì§„",
            "algorithms": ["Isolation Forest", "LSTM Autoencoder"],
            "use_cases": ["ë¶€ì •í–‰ìœ„ íƒì§€", "ë¹„ì •ìƒ í•™ìŠµ íŒ¨í„´"],
            "framework": "scikit-learn, TensorFlow",
            "threshold": "ë™ì  ì„ê³„ê°’ ì„¤ì •"
        }
    }
```

**AI íŒŒì´í”„ë¼ì¸ ì˜ˆì‹œ**:

```mermaid
graph LR
    A[ì‚¬ìš©ì ì‘ë‹µ] --> B[IRT ì—”ì§„]
    B --> C[ëŠ¥ë ¥ì¹˜ ì¶”ì •]
    C --> D[ì¶”ì²œ ì—”ì§„]
    D --> E[ë‹¤ìŒ ë¬¸í•­ ì„ íƒ]
    E --> F[AI íŠœí„°]
    F --> G[ë§ì¶¤í˜• í”¼ë“œë°±]

    B --> H[ë¶„ì„ ì—”ì§„]
    H --> I[í•™ìŠµ ê¶¤ì ]
    I --> J[ë¦¬ìŠ¤í¬ íƒì§€]
    J --> K[êµì‚¬ ì•Œë¦¼]
```

### 1.3 API ì œê³µ

FastAPI ê¸°ë°˜ì˜ RESTful APIë¥¼ í†µí•´ í´ë¼ì´ì–¸íŠ¸ ìš”ì²­ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.

```python
# API ê³„ì¸µ êµ¬ì¡°
class APILayer:
    """
    DreamSeedAI API êµ¬ì¡°
    """
    api_structure = {
        "public_api": {
            "description": "ì™¸ë¶€ í´ë¼ì´ì–¸íŠ¸ìš© ê³µê°œ API",
            "endpoints": [
                "/api/v1/auth/*",
                "/api/v1/content/*",
                "/api/v1/assessments/*"
            ],
            "rate_limit": "100 req/hour (ë¬´ë£Œ), 1000 req/hour (í”„ë¦¬ë¯¸ì—„)",
            "authentication": "JWT Bearer Token"
        },
        "internal_api": {
            "description": "ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ê°„ í†µì‹ ìš© API",
            "endpoints": [
                "/internal/users/*",
                "/internal/analytics/*",
                "/internal/ai/*"
            ],
            "rate_limit": "ë¬´ì œí•œ (ë‚´ë¶€ ë„¤íŠ¸ì›Œí¬)",
            "authentication": "Service-to-Service JWT"
        },
        "admin_api": {
            "description": "ê´€ë¦¬ì ì „ìš© API",
            "endpoints": [
                "/api/admin/users/*",
                "/api/admin/reports/*",
                "/api/admin/system/*"
            ],
            "rate_limit": "ë¬´ì œí•œ",
            "authentication": "JWT + Role=admin"
        },
        "webhook_api": {
            "description": "ì™¸ë¶€ ì„œë¹„ìŠ¤ ì›¹í›…",
            "endpoints": [
                "/webhooks/stripe",
                "/webhooks/lti"
            ],
            "security": "ì„œëª… ê²€ì¦ (HMAC)",
            "retry": "ìë™ ì¬ì‹œë„ (exponential backoff)"
        }
    }
```

**API ì„¤ê³„ ì›ì¹™**:

- **RESTful**: ë¦¬ì†ŒìŠ¤ ê¸°ë°˜ URL ì„¤ê³„
- **Versioning**: `/api/v1`, `/api/v2` ë²„ì „ ê´€ë¦¬
- **Documentation**: OpenAPI 3.0 ìë™ ë¬¸ì„œí™”
- **Error Handling**: í‘œì¤€ HTTP ìƒíƒœ ì½”ë“œ + ìƒì„¸ ì—ëŸ¬ ë©”ì‹œì§€
- **CORS**: í—ˆìš©ëœ ì˜¤ë¦¬ì§„ë§Œ ì ‘ê·¼ ê°€ëŠ¥

### 1.4 ë¹„ë™ê¸° ì²˜ë¦¬

ëŒ€ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ë° ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…ì„ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬í•©ë‹ˆë‹¤.

```python
from celery import Celery
from kafka import KafkaProducer, KafkaConsumer

# Celery ë¹„ë™ê¸° ì‘ì—…
celery_app = Celery('dreamseed', broker='redis://localhost:6379/0')

@celery_app.task
async def generate_report(user_id: int, report_type: str):
    """
    í•™ìŠµ ë¦¬í¬íŠ¸ ìƒì„± (ë¹„ë™ê¸°)
    - ì˜ˆìƒ ì†Œìš” ì‹œê°„: 5-30ë¶„
    - Quarto ë Œë”ë§, í†µê³„ ë¶„ì„, PDF ìƒì„±
    """
    # 1. ë°ì´í„° ìˆ˜ì§‘
    learning_data = await fetch_user_learning_data(user_id)

    # 2. í†µê³„ ë¶„ì„
    analysis = await perform_statistical_analysis(learning_data)

    # 3. Quarto ë Œë”ë§
    report_html = await render_quarto_report(analysis, report_type)

    # 4. PDF ë³€í™˜
    pdf_path = await convert_to_pdf(report_html)

    # 5. S3 ì—…ë¡œë“œ
    report_url = await upload_to_s3(pdf_path)

    # 6. ì‚¬ìš©ì ì•Œë¦¼
    await notify_user(user_id, report_url)

    return report_url

# Kafka ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë°
producer = KafkaProducer(bootstrap_servers='localhost:9092')

async def publish_learning_event(event_type: str, data: dict):
    """
    í•™ìŠµ ì´ë²¤íŠ¸ ë°œí–‰
    """
    message = {
        "event_type": event_type,
        "timestamp": datetime.utcnow().isoformat(),
        "data": data
    }

    producer.send('learning-events', json.dumps(message).encode('utf-8'))
    producer.flush()

# ì´ë²¤íŠ¸ êµ¬ë… ë° ì²˜ë¦¬
consumer = KafkaConsumer(
    'learning-events',
    bootstrap_servers='localhost:9092',
    group_id='analytics-group'
)

async def consume_learning_events():
    """
    í•™ìŠµ ì´ë²¤íŠ¸ êµ¬ë… ë° ì‹¤ì‹œê°„ ë¶„ì„
    """
    for message in consumer:
        event = json.loads(message.value.decode('utf-8'))

        if event['event_type'] == 'item_response':
            # IRT íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸
            await update_irt_parameters(event['data'])

        elif event['event_type'] == 'session_complete':
            # í•™ìŠµ ì„¸ì…˜ ë¶„ì„
            await analyze_session(event['data'])

        elif event['event_type'] == 'risk_detected':
            # êµì‚¬ ì•Œë¦¼
            await notify_teacher(event['data'])
```

**ë¹„ë™ê¸° ì²˜ë¦¬ ì‚¬ìš© ì‚¬ë¡€**:

- **ë¦¬í¬íŠ¸ ìƒì„±**: Quarto ê¸°ë°˜ í†µê³„ ë¦¬í¬íŠ¸ (5-30ë¶„ ì†Œìš”)
- **IRT ìº˜ë¦¬ë¸Œë ˆì´ì…˜**: ëŒ€ëŸ‰ ì‘ë‹µ ë°ì´í„° ë¶„ì„ (ìˆ˜ì‹œê°„ ì†Œìš”)
- **ì´ë©”ì¼ ë°œì†¡**: ë°°ì¹˜ ì´ë©”ì¼ ì „ì†¡
- **íŒŒì¼ ì²˜ë¦¬**: ëŒ€ìš©ëŸ‰ CSV ì„í¬íŠ¸/ìµìŠ¤í¬íŠ¸
- **ML ëª¨ë¸ í•™ìŠµ**: ì£¼ê¸°ì  ëª¨ë¸ ì¬í•™ìŠµ

### 1.5 ì™¸ë¶€ ì—°ë™

LTI, ê²°ì œ ì„œë¹„ìŠ¤ ë“± ì™¸ë¶€ ì‹œìŠ¤í…œê³¼ì˜ ì•ˆì „í•œ ì—°ë™ì„ ì œê³µí•©ë‹ˆë‹¤.

```python
# ì™¸ë¶€ ì—°ë™ ê°œìš”
class ExternalIntegrations:
    """
    DreamSeedAI ì™¸ë¶€ ì—°ë™ í˜„í™©
    """
    integrations = {
        "lti_1p3": {
            "standard": "IMS Learning Tools Interoperability 1.3",
            "lms_platforms": ["Canvas", "Moodle", "Blackboard", "Google Classroom"],
            "features": ["Deep Linking", "Grade Passback", "Names and Roles"],
            "security": "OAuth 2.0 + OIDC"
        },
        "payment_gateways": {
            "stripe": {
                "use_case": "êµ¬ë… ê²°ì œ, í•™êµ ë¼ì´ì„ ìŠ¤",
                "features": ["Checkout", "Subscriptions", "Webhooks", "Invoicing"],
                "pci_compliance": "PCI DSS Level 1"
            },
            "paypal": {
                "use_case": "ëŒ€ì²´ ê²°ì œ ìˆ˜ë‹¨",
                "features": ["Express Checkout", "Recurring Billing"],
                "integration": "REST API"
            }
        },
        "cloud_storage": {
            "aws_s3": {
                "use_case": "íŒŒì¼ ì €ì¥ (ì´ë¯¸ì§€, PDF, ë¹„ë””ì˜¤)",
                "features": ["ë²„ì €ë‹", "ë¼ì´í”„ì‚¬ì´í´ ì •ì±…", "CDN (CloudFront)"],
                "encryption": "AES-256 ì„œë²„ ì¸¡ ì•”í˜¸í™”"
            },
            "minio": {
                "use_case": "ì˜¨í”„ë ˆë¯¸ìŠ¤ ëŒ€ì•ˆ",
                "features": ["S3 í˜¸í™˜ API", "ìì²´ í˜¸ìŠ¤íŒ…"],
                "deployment": "Kubernetes"
            }
        },
        "sso_providers": {
            "google": "OAuth 2.0 / OIDC",
            "microsoft": "Azure AD / OIDC",
            "saml": "í•™êµ SSO (SAML 2.0)"
        },
        "analytics": {
            "google_analytics": "ì‚¬ìš©ì í–‰ë™ ë¶„ì„",
            "mixpanel": "ì œí’ˆ ë¶„ì„",
            "sentry": "ì—ëŸ¬ ì¶”ì "
        }
    }
```

**ì—°ë™ ë³´ì•ˆ ì›ì¹™**:

- **OAuth 2.0**: í† í° ê¸°ë°˜ ì¸ì¦
- **HMAC ì„œëª…**: Webhook ë¬´ê²°ì„± ê²€ì¦
- **TLS 1.3**: ì „ì†¡ ê³„ì¸µ ì•”í˜¸í™”
- **API Key Rotation**: ì£¼ê¸°ì  í‚¤ ê°±ì‹ 

---

## 2. ì •ì±… ì¤€ìˆ˜ ë©”ì»¤ë‹ˆì¦˜

ì‹œìŠ¤í…œ ê³„ì¸µì€ ê±°ë²„ë„ŒìŠ¤ ë° ì •ì±… ê³„ì¸µì˜ ì§€ì¹¨ì„ ì¤€ìˆ˜í•˜ê¸° ìœ„í•´ ë‹¤ì–‘í•œ **ê¸°ìˆ ì  ë©”ì»¤ë‹ˆì¦˜**ì„ ì ìš©í•©ë‹ˆë‹¤.

### 2.1 ë°ì´í„° ê²©ë¦¬ (Data Isolation)

**ì •ì±… ìš”êµ¬ì‚¬í•­**: "í•™ìƒ ë°ì´í„°ëŠ” ê¸°ê´€ë³„ë¡œ ê²©ë¦¬ë˜ì–´ì•¼ í•œë‹¤"

**êµ¬í˜„ ë°©ì‹**:

```sql
-- PostgreSQL Row-Level Security (RLS)
CREATE TABLE users (
    user_id SERIAL PRIMARY KEY,
    email VARCHAR(255) NOT NULL,
    org_id INTEGER NOT NULL REFERENCES organizations(org_id),
    role VARCHAR(50),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- RLS ì •ì±… í™œì„±í™”
ALTER TABLE users ENABLE ROW LEVEL SECURITY;

-- ì •ì±…: ì‚¬ìš©ìëŠ” ìì‹ ì˜ ì¡°ì§ ë°ì´í„°ë§Œ ë³¼ ìˆ˜ ìˆìŒ
CREATE POLICY org_isolation_policy ON users
    FOR ALL
    USING (org_id = current_setting('app.current_org_id')::integer);

-- ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ì¡°ì§ ID ì„¤ì •
SET app.current_org_id = 123;

-- ì´ì œ ëª¨ë“  ì¿¼ë¦¬ëŠ” ìë™ìœ¼ë¡œ org_id í•„í„°ë§ë¨
SELECT * FROM users;
-- ì‹¤ì œ ì‹¤í–‰: SELECT * FROM users WHERE org_id = 123;
```

```python
# FastAPIì—ì„œ ìë™ org_id í•„í„°ë§
from fastapi import Depends, HTTPException
from sqlalchemy.orm import Session

async def get_db_with_org_filter(
    current_user = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜ì— org_id í•„í„° ìë™ ì ìš©
    """
    # PostgreSQL RLS ë³€ìˆ˜ ì„¤ì •
    db.execute(f"SET app.current_org_id = {current_user.org_id}")
    return db

@router.get("/users")
async def list_users(db: Session = Depends(get_db_with_org_filter)):
    """
    ì¡°ì§ ë‚´ ì‚¬ìš©ì ëª©ë¡ (ìë™ ê²©ë¦¬)
    """
    # org_id í•„í„°ë§ì´ ìë™ìœ¼ë¡œ ì ìš©ë¨
    users = db.query(User).all()
    return users
```

### 2.2 ê¸°ëŠ¥ ì œí•œ (Feature Restriction)

**ì •ì±… ìš”êµ¬ì‚¬í•­**: "ì‹œí—˜ ì¤‘ì—ëŠ” AI íŠœí„° íŒíŠ¸ë¥¼ ì œê³µí•  ìˆ˜ ì—†ë‹¤"

**êµ¬í˜„ ë°©ì‹**:

```python
from enum import Enum

class ExamMode(str, Enum):
    PRACTICE = "practice"  # íŒíŠ¸ í—ˆìš©
    ASSESSMENT = "assessment"  # íŒíŠ¸ ê¸ˆì§€
    FINAL_EXAM = "final_exam"  # íŒíŠ¸ ê¸ˆì§€, íƒ€ì´ë¨¸ ê°•ì œ

@router.post("/ai-tutor/hint")
@require_policy("ai_tutor", "provide_hint")
async def get_hint(
    item_id: int,
    session_id: int,
    current_user = Depends(get_current_user)
):
    """
    AI íŠœí„° íŒíŠ¸ ì œê³µ
    """
    # ì„¸ì…˜ ëª¨ë“œ í™•ì¸
    session = await db.execute(
        "SELECT exam_mode FROM test_sessions WHERE session_id = :session_id",
        {"session_id": session_id}
    )
    session = session.fetchone()

    # ì •ì±… ê²€ì‚¬: ì‹œí—˜ ëª¨ë“œì—ì„œëŠ” íŒíŠ¸ ê¸ˆì§€
    if session.exam_mode in [ExamMode.ASSESSMENT, ExamMode.FINAL_EXAM]:
        # OPA ì •ì±… í‰ê°€
        policy_result = await opa_client.evaluate_policy(
            "ai_tutor/hint_restriction",
            {
                "user_id": current_user.user_id,
                "session_id": session_id,
                "exam_mode": session.exam_mode
            }
        )

        if not policy_result.get("allow", False):
            raise HTTPException(
                status_code=403,
                detail="Hints are not allowed during assessments"
            )

    # íŒíŠ¸ ìƒì„±
    hint = await ai_tutor_engine.generate_hint(item_id, current_user.ability_estimate)

    # ê°ì‚¬ ë¡œê·¸
    await audit_log("ai_tutor_hint_requested", {
        "user_id": current_user.user_id,
        "session_id": session_id,
        "item_id": item_id,
        "exam_mode": session.exam_mode
    })

    return {"hint": hint}
```

### 2.3 ê¶Œí•œ ê²€ì‚¬ (Permission Check)

**ì •ì±… ìš”êµ¬ì‚¬í•­**: "êµì‚¬ë§Œ ì„±ì ì„ ìˆ˜ì •í•  ìˆ˜ ìˆë‹¤"

**êµ¬í˜„ ë°©ì‹**:

```python
from functools import wraps
from typing import List

def require_role(allowed_roles: List[str]):
    """
    ì—­í•  ê¸°ë°˜ ì ‘ê·¼ ì œì–´ ë°ì½”ë ˆì´í„°
    """
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, current_user = None, **kwargs):
            if current_user is None:
                raise HTTPException(status_code=401, detail="Not authenticated")

            if current_user.role not in allowed_roles:
                # ê°ì‚¬ ë¡œê·¸: ê¶Œí•œ ê±°ë¶€
                await audit_log("access_denied", {
                    "user_id": current_user.user_id,
                    "role": current_user.role,
                    "required_roles": allowed_roles,
                    "endpoint": func.__name__
                })

                raise HTTPException(
                    status_code=403,
                    detail=f"Role '{current_user.role}' not authorized. Required: {allowed_roles}"
                )

            return await func(*args, current_user=current_user, **kwargs)
        return wrapper
    return decorator

@router.patch("/grades/{assignment_id}")
@require_role(["teacher", "admin"])
@require_policy("grade_management", "update_grade")
async def update_grade(
    assignment_id: int,
    grade_update: GradeUpdate,
    current_user = Depends(get_current_user)
):
    """
    ì„±ì  ì—…ë°ì´íŠ¸ (êµì‚¬ ì „ìš©)
    """
    # ê¸°ì¡´ ì„±ì  ì¡°íšŒ
    existing_grade = await db.execute(
        "SELECT * FROM grades WHERE assignment_id = :assignment_id",
        {"assignment_id": assignment_id}
    )
    existing_grade = existing_grade.fetchone()

    if not existing_grade:
        raise HTTPException(status_code=404, detail="Grade not found")

    # ì—…ë°ì´íŠ¸
    await db.execute(
        """
        UPDATE grades
        SET score = :score, feedback = :feedback, updated_by = :user_id, updated_at = NOW()
        WHERE assignment_id = :assignment_id
        """,
        {
            "score": grade_update.score,
            "feedback": grade_update.feedback,
            "user_id": current_user.user_id,
            "assignment_id": assignment_id
        }
    )

    # ê°ì‚¬ ë¡œê·¸
    await audit_log("grade_updated", {
        "updated_by": current_user.user_id,
        "assignment_id": assignment_id,
        "old_score": existing_grade.score,
        "new_score": grade_update.score
    })

    return {"message": "Grade updated successfully"}
```

### 2.4 ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬ (Data Validation)

**ì •ì±… ìš”êµ¬ì‚¬í•­**: "ëª¨ë“  ì‚¬ìš©ì ì…ë ¥ì€ ê²€ì¦ë˜ì–´ì•¼ í•œë‹¤"

**êµ¬í˜„ ë°©ì‹**:

```python
from pydantic import BaseModel, Field, validator, EmailStr
from datetime import datetime

class UserCreate(BaseModel):
    """
    ì‚¬ìš©ì ìƒì„± ìš”ì²­ ìŠ¤í‚¤ë§ˆ
    """
    email: EmailStr  # ì´ë©”ì¼ í˜•ì‹ ìë™ ê²€ì¦
    username: str = Field(..., min_length=3, max_length=50, regex="^[a-zA-Z0-9_-]+$")
    password: str = Field(..., min_length=8)
    full_name: str = Field(..., max_length=200)
    grade_level: int = Field(..., ge=1, le=12)
    birth_date: datetime

    @validator('password')
    def password_strength(cls, v):
        """
        ë¹„ë°€ë²ˆí˜¸ ê°•ë„ ê²€ì¦
        """
        if not any(char.isdigit() for char in v):
            raise ValueError('Password must contain at least one digit')
        if not any(char.isupper() for char in v):
            raise ValueError('Password must contain at least one uppercase letter')
        if not any(char.islower() for char in v):
            raise ValueError('Password must contain at least one lowercase letter')
        return v

    @validator('birth_date')
    def age_validation(cls, v):
        """
        COPPA ì¤€ìˆ˜: 13ì„¸ ì´ìƒë§Œ ê°€ì… ê°€ëŠ¥
        """
        today = datetime.utcnow()
        age = (today - v).days / 365.25

        if age < 13:
            raise ValueError('Users must be at least 13 years old')

        return v

# XSS, SQL Injection ë°©ì–´
from bleach import clean
import html

async def sanitize_user_input(text: str) -> str:
    """
    ì‚¬ìš©ì ì…ë ¥ ìƒˆë‹ˆíƒ€ì´ì§•
    """
    # HTML íƒœê·¸ ì œê±°
    cleaned = clean(text, tags=[], strip=True)

    # HTML ì—”í‹°í‹° ì¸ì½”ë”©
    encoded = html.escape(cleaned)

    return encoded

@router.post("/comments")
async def create_comment(
    comment_text: str,
    current_user = Depends(get_current_user)
):
    """
    ëŒ“ê¸€ ì‘ì„± (XSS ë°©ì–´)
    """
    # ì…ë ¥ ìƒˆë‹ˆíƒ€ì´ì§•
    safe_comment = await sanitize_user_input(comment_text)

    # DB ì €ì¥ (Parameterized Queryë¡œ SQL Injection ë°©ì–´)
    await db.execute(
        "INSERT INTO comments (user_id, text, created_at) VALUES (:user_id, :text, NOW())",
        {"user_id": current_user.user_id, "text": safe_comment}
    )

    return {"message": "Comment created successfully"}
```

### 2.5 ë¡œê·¸ ê°ì‚¬ (Audit Logging)

**ì •ì±… ìš”êµ¬ì‚¬í•­**: "ëª¨ë“  ë¯¼ê°í•œ ì‘ì—…ì€ ê°ì‚¬ ë¡œê·¸ì— ê¸°ë¡ë˜ì–´ì•¼ í•œë‹¤"

**êµ¬í˜„ ë°©ì‹**:

```python
import logging
from datetime import datetime
from typing import Dict, Any

# êµ¬ì¡°í™”ëœ ë¡œê¹…
logger = logging.getLogger("audit")
handler = logging.FileHandler("/var/log/dreamseed/audit.log")
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
handler.setFormatter(formatter)
logger.addHandler(handler)
logger.setLevel(logging.INFO)

async def audit_log(event_type: str, data: Dict[str, Any]):
    """
    ê°ì‚¬ ë¡œê·¸ ê¸°ë¡
    """
    log_entry = {
        "timestamp": datetime.utcnow().isoformat(),
        "event_type": event_type,
        "data": data,
        "ip_address": data.get("ip_address"),
        "user_agent": data.get("user_agent")
    }

    # ë¡œê·¸ íŒŒì¼ì— ê¸°ë¡
    logger.info(json.dumps(log_entry))

    # PostgreSQL ê°ì‚¬ í…Œì´ë¸”ì— ì €ì¥
    await db.execute(
        """
        INSERT INTO audit_logs (event_type, user_id, data, created_at)
        VALUES (:event_type, :user_id, :data, NOW())
        """,
        {
            "event_type": event_type,
            "user_id": data.get("user_id"),
            "data": json.dumps(data)
        }
    )

    # Kafkaë¡œ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° (SIEM ì—°ë™)
    await publish_to_kafka("audit-events", log_entry)

# ê°ì‚¬ ëŒ€ìƒ ì´ë²¤íŠ¸
AUDITABLE_EVENTS = [
    "user_login",
    "user_logout",
    "password_change",
    "role_change",
    "grade_updated",
    "data_export",
    "policy_violation",
    "ai_tutor_hint_requested",
    "payment_succeeded",
    "license_assigned"
]
```

**ê°ì‚¬ ë¡œê·¸ ì˜ˆì‹œ**:

```json
{
  "timestamp": "2025-11-09T12:34:56.789Z",
  "event_type": "grade_updated",
  "data": {
    "updated_by": 456,
    "user_id": 123,
    "assignment_id": 789,
    "old_score": 85,
    "new_score": 90,
    "reason": "Re-grading after review",
    "ip_address": "192.168.1.100",
    "user_agent": "Mozilla/5.0 ..."
  }
}
```

---

## 3. ì•„í‚¤í…ì²˜ íŠ¹ì§•

### 3.1 ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜

DreamSeedAIëŠ” ë…ë¦½ì ì¸ ì„œë¹„ìŠ¤ë¡œ êµ¬ì„±ë˜ì–´ ìœ ì—°í•œ í™•ì¥ ë° ë°°í¬ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.

```yaml
# Kubernetes ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ë°°í¬ ì˜ˆì‹œ
apiVersion: apps/v1
kind: Deployment
metadata:
  name: user-service
spec:
  replicas: 3
  selector:
    matchLabels:
      app: user-service
  template:
    metadata:
      labels:
        app: user-service
    spec:
      containers:
        - name: user-service
          image: dreamseedai/user-service:v1.2.0
          ports:
            - containerPort: 8001
          env:
            - name: DATABASE_URL
              valueFrom:
                secretKeyRef:
                  name: db-credentials
                  key: connection-string
          resources:
            requests:
              memory: "256Mi"
              cpu: "250m"
            limits:
              memory: "512Mi"
              cpu: "500m"
          livenessProbe:
            httpGet:
              path: /health
              port: 8001
            initialDelaySeconds: 30
            periodSeconds: 10
          readinessProbe:
            httpGet:
              path: /ready
              port: 8001
            initialDelaySeconds: 5
            periodSeconds: 5
---
apiVersion: v1
kind: Service
metadata:
  name: user-service
spec:
  selector:
    app: user-service
  ports:
    - port: 80
      targetPort: 8001
  type: ClusterIP
```

**ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì´ì **:

- **ë…ë¦½ ë°°í¬**: ê° ì„œë¹„ìŠ¤ë¥¼ ë…ë¦½ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸
- **ê¸°ìˆ  ìŠ¤íƒ ë‹¤ì–‘ì„±**: Python, Node.js, Go ë“± ìµœì  ê¸°ìˆ  ì„ íƒ
- **ì¥ì•  ê²©ë¦¬**: í•œ ì„œë¹„ìŠ¤ ì¥ì• ê°€ ì „ì²´ ì‹œìŠ¤í…œì— ì˜í–¥ ìµœì†Œí™”
- **í™•ì¥ì„±**: íŠ¸ë˜í”½ì— ë”°ë¼ ì„œë¹„ìŠ¤ë³„ ìŠ¤ì¼€ì¼ë§

### 3.2 API Gateway

í´ë¼ì´ì–¸íŠ¸ ìš”ì²­ì„ ë¼ìš°íŒ…í•˜ê³  ê³µí†µ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

```python
# Nginx API Gateway ì„¤ì •
upstream user_service {
    server user-service:8001;
}

upstream content_service {
    server content-service:8003;
}

upstream assessment_service {
    server assessment-service:8004;
}

server {
    listen 80;
    server_name api.dreamseedai.com;

    # Rate Limiting
    limit_req_zone $binary_remote_addr zone=api_limit:10m rate=100r/m;

    # CORS
    add_header 'Access-Control-Allow-Origin' 'https://app.dreamseedai.com';
    add_header 'Access-Control-Allow-Methods' 'GET, POST, PUT, DELETE, OPTIONS';

    # API ë¼ìš°íŒ…
    location /api/users/ {
        limit_req zone=api_limit burst=20;
        proxy_pass http://user_service/;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    }

    location /api/content/ {
        proxy_pass http://content_service/;
    }

    location /api/assessments/ {
        proxy_pass http://assessment_service/;
    }

    # Health Check
    location /health {
        access_log off;
        return 200 "healthy\n";
    }
}
```

**API Gateway ê¸°ëŠ¥**:

- **ë¼ìš°íŒ…**: URL íŒ¨í„´ ê¸°ë°˜ ì„œë¹„ìŠ¤ ë¼ìš°íŒ…
- **ì¸ì¦**: JWT í† í° ê²€ì¦
- **Rate Limiting**: DDoS ë°©ì–´ ë° ê³µì • ì‚¬ìš©
- **CORS**: í¬ë¡œìŠ¤ ì˜¤ë¦¬ì§„ ìš”ì²­ ê´€ë¦¬
- **ë¡œë“œ ë°¸ëŸ°ì‹±**: íŠ¸ë˜í”½ ë¶„ì‚°

### 3.3 ë©”ì‹œì§€ í (Message Queue)

ë¹„ë™ê¸° ì‘ì—… ì²˜ë¦¬ ë° ì„œë¹„ìŠ¤ ê°„ í†µì‹ ì„ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬í•©ë‹ˆë‹¤.

```python
# Apache Kafka í† í”½ êµ¬ì¡°
KAFKA_TOPICS = {
    "learning-events": {
        "description": "í•™ìŠµ ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¼",
        "partitions": 10,
        "replication_factor": 3,
        "producers": ["assessment-service", "ai-tutor-service"],
        "consumers": ["analytics-service", "recommendation-service"]
    },
    "audit-events": {
        "description": "ê°ì‚¬ ë¡œê·¸ ìŠ¤íŠ¸ë¦¼",
        "partitions": 5,
        "replication_factor": 3,
        "producers": ["all-services"],
        "consumers": ["audit-service", "siem-connector"]
    },
    "notification-requests": {
        "description": "ì•Œë¦¼ ìš”ì²­ í",
        "partitions": 3,
        "replication_factor": 2,
        "producers": ["user-service", "assessment-service"],
        "consumers": ["notification-service"]
    }
}

# Celery + Redis ì‘ì—… í
CELERY_QUEUES = {
    "default": {
        "description": "ì¼ë°˜ ë¹„ë™ê¸° ì‘ì—…",
        "priority": 5
    },
    "reports": {
        "description": "ë¦¬í¬íŠ¸ ìƒì„± (ì¥ì‹œê°„ ì‘ì—…)",
        "priority": 3
    },
    "emails": {
        "description": "ì´ë©”ì¼ ë°œì†¡",
        "priority": 7
    },
    "ml-training": {
        "description": "ML ëª¨ë¸ í•™ìŠµ",
        "priority": 1
    }
}
```

### 3.4 í´ë¼ìš°ë“œ ê¸°ë°˜ ì¸í”„ë¼

í´ë¼ìš°ë“œ í”Œë«í¼ì„ í™œìš©í•˜ì—¬ í™•ì¥ì„±, ê°€ìš©ì„±, ë¹„ìš© íš¨ìœ¨ì„±ì„ í™•ë³´í•©ë‹ˆë‹¤.

```yaml
# AWS ì¸í”„ë¼ ì˜ˆì‹œ (Terraform)
resource "aws_eks_cluster" "dreamseed" {
name     = "dreamseed-production"
role_arn = aws_iam_role.eks_cluster.arn
version  = "1.27"

vpc_config {
subnet_ids = [
aws_subnet.private_a.id,
aws_subnet.private_b.id,
aws_subnet.private_c.id
]
endpoint_public_access = false
endpoint_private_access = true
}
}

resource "aws_rds_cluster" "postgres" {
cluster_identifier      = "dreamseed-postgres"
engine                  = "aurora-postgresql"
engine_version          = "15.3"
database_name           = "dreamseed_prod"
master_username         = "admin"
master_password         = var.db_password
backup_retention_period = 7
preferred_backup_window = "03:00-04:00"

vpc_security_group_ids = [aws_security_group.database.id]
db_subnet_group_name   = aws_db_subnet_group.main.name

serverlessv2_scaling_configuration {
max_capacity = 64.0
min_capacity = 2.0
}
}

resource "aws_elasticache_cluster" "redis" {
cluster_id           = "dreamseed-redis"
engine               = "redis"
node_type            = "cache.r6g.large"
num_cache_nodes      = 3
parameter_group_name = "default.redis7"
port                 = 6379
subnet_group_name    = aws_elasticache_subnet_group.main.name
}
```

**í´ë¼ìš°ë“œ ì´ì **:

- **Auto Scaling**: íŠ¸ë˜í”½ì— ë”°ë¥¸ ìë™ í™•ì¥
- **High Availability**: ë‹¤ì¤‘ ê°€ìš© ì˜ì—­ ë°°í¬
- **Managed Services**: RDS, ElastiCache ë“± ê´€ë¦¬í˜• ì„œë¹„ìŠ¤
- **Cost Optimization**: ì‚¬ìš©í•œ ë§Œí¼ë§Œ ì§€ë¶ˆ

---

## 4. ê¸°ìˆ  ìŠ¤íƒ í†µí•©

### 4.1 ë°±ì—”ë“œ

```python
BACKEND_STACK = {
    "language": "Python 3.11+",
    "framework": "FastAPI",
    "orm": "SQLAlchemy",
    "validation": "Pydantic",
    "async": "asyncio, aiohttp",
    "testing": "pytest, pytest-asyncio",
    "documentation": "OpenAPI 3.0, Swagger UI"
}
```

### 4.2 í”„ë¡ íŠ¸ì—”ë“œ

```typescript
const FRONTEND_STACK = {
  framework: "React 18 / Next.js 14",
  language: "TypeScript",
  stateManagement: "Zustand / React Query",
  styling: "Tailwind CSS",
  ui: "shadcn/ui",
  editor: "TipTap (with MathJax)",
  testing: "Jest, React Testing Library",
};
```

### 4.3 ë°ì´í„°ë² ì´ìŠ¤

```sql
-- Database Stack
DATABASE_STACK = {
  primary: "PostgreSQL 15",
  cache: "Redis 7",
  search: "Elasticsearch 8",
  object_storage: "MinIO / AWS S3",
  queue: "RabbitMQ / Apache Kafka"
}
```

### 4.4 AI/ML

```python
AI_ML_STACK = {
    "irt_models": "scipy, statsmodels",
    "nlp": "OpenAI API, LangChain, transformers",
    "ml_framework": "scikit-learn, TensorFlow, PyTorch",
    "experiment_tracking": "MLflow",
    "model_serving": "FastAPI, TorchServe",
    "statistical_analysis": "statsmodels, scipy",
    "visualization": "Matplotlib, Plotly, Quarto"
}
```

### 4.5 ì¸í”„ë¼

```yaml
INFRASTRUCTURE_STACK:
  orchestration: Kubernetes (EKS, GKE, AKS)
  ci_cd: GitHub Actions, ArgoCD
  monitoring: Prometheus, Grafana
  logging: ELK Stack (Elasticsearch, Logstash, Kibana)
  tracing: Jaeger, OpenTelemetry
  secrets: HashiCorp Vault, AWS Secrets Manager
  service_mesh: Istio (ì„ íƒì )
```

---

## 5. ê²°ë¡ 

### 5.1 ì‹œìŠ¤í…œ ê³„ì¸µì˜ ì—­í• 

ì‹œìŠ¤í…œ ê³„ì¸µì€ DreamSeedAIì˜ **í•µì‹¬ ì—°ì‚° ë° ë°ì´í„° ì²˜ë¦¬ ê¸°ëŠ¥**ì„ ë‹´ë‹¹í•˜ë©°, ìƒìœ„ ê³„ì¸µ (ê±°ë²„ë„ŒìŠ¤ ë° ì •ì±…)ì˜ ì§€ì¹¨ì„ ì¤€ìˆ˜í•˜ë©´ì„œ ì‚¬ìš©ìì—ê²Œ ê°€ì¹˜ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

```mermaid
graph TB
    A[ê±°ë²„ë„ŒìŠ¤ ê³„ì¸µ] -->|ì •ì±… ì •ì˜| B[ì‹œìŠ¤í…œ ê³„ì¸µ]
    B -->|ë°ì´í„° ì²˜ë¦¬| C[ì‚¬ìš©ì ê°€ì¹˜ ì œê³µ]
    B -->|AI ì¶”ë¡ | C
    B -->|API ì„œë¹„ìŠ¤| C
    B -->|ê°ì‚¬ ë¡œê·¸| A

    B --> D[ë°ì´í„° ê²©ë¦¬]
    B --> E[ê¸°ëŠ¥ ì œí•œ]
    B --> F[ê¶Œí•œ ê²€ì‚¬]
    B --> G[ìœ íš¨ì„± ê²€ì¦]

    D --> H[ì •ì±… ì¤€ìˆ˜]
    E --> H
    F --> H
    G --> H
```

### 5.2 í•µì‹¬ ì„±ê³¼

1. **í™•ì¥ì„±**: ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ + Kubernetesë¡œ ìˆ˜í‰ í™•ì¥
2. **ë³´ì•ˆ**: ë‹¤ì¸µ ë°©ì–´ (ì¸ì¦, ì¸ê°€, ì•”í˜¸í™”, ê°ì‚¬)
3. **ì„±ëŠ¥**: ìºì‹±, ë¹„ë™ê¸° ì²˜ë¦¬, ìµœì í™”ëœ ì¿¼ë¦¬
4. **ì•ˆì •ì„±**: High Availability, ìë™ ë³µêµ¬, ë°±ì—…
5. **ì¤€ìˆ˜ì„±**: GDPR, COPPA, FERPA ë“± ê·œì • ì¤€ìˆ˜

### 5.3 ì§€ì†ì  ê°œì„ 

DreamSeedAIëŠ” ì‹œìŠ¤í…œ ê³„ì¸µì˜ **ê²¬ê³ í•¨ê³¼ í™•ì¥ì„±**ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒì„ ì¶”êµ¬í•©ë‹ˆë‹¤:

- **í˜ì‹ ì ì¸ AI ê¸°ìˆ **: ìµœì‹  NLP, IRT, ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜ ë„ì…
- **ì‚¬ìš©ì ê²½í—˜ í–¥ìƒ**: ë¹ ë¥¸ ì‘ë‹µ ì‹œê°„, ì§ê´€ì ì¸ API
- **ê¸€ë¡œë²Œ í™•ì¥**: ë‹¤êµ­ì–´ ì§€ì›, ì§€ì—­ë³„ ê·œì • ì¤€ìˆ˜
- **ì§€ì† ê°€ëŠ¥í•œ ì„±ì¥**: íš¨ìœ¨ì ì¸ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©, ìë™í™”

### 5.4 ë‹¤ìŒ ë‹¨ê³„

ì‹œìŠ¤í…œ ê³„ì¸µ ë¬¸ì„œë¥¼ ë³´ì™„í•˜ê¸° ìœ„í•œ í–¥í›„ ì‘ì—…:

- [ ] **ë°°í¬ ê°€ì´ë“œ**: Kubernetes, CI/CD íŒŒì´í”„ë¼ì¸ ìƒì„¸ ì„¤ëª…
- [ ] **ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ**: Prometheus + Grafana êµ¬ì„±
- [ ] **ì¬í•´ ë³µêµ¬ ê³„íš**: DR (Disaster Recovery) ì ˆì°¨
- [ ] **ì„±ëŠ¥ ìµœì í™”**: ë³‘ëª© ì§€ì  ë¶„ì„ ë° ê°œì„ 
- [ ] **ë³´ì•ˆ ê°ì‚¬**: ì •ê¸°ì ì¸ ì·¨ì•½ì  ìŠ¤ìº” ë° íŒ¨ì¹˜

---

## ì°¸ê³  ë¬¸ì„œ

- [Architecture Overview](../architecture/overview.md)
- [Assessment Engine](./assessment-engine.md)
- [Content Management](./content-management.md)
- [Analytics Engine](./analytics-engine.md)
- [AI Tutor](./ai-tutor.md)
- [Additional Services](./additional-services.md)
- [Governance Integration Examples](../governance-integration/examples.md)

---

**DreamSeedAI ì‹œìŠ¤í…œ ê³„ì¸µì€ êµìœ¡ì˜ ë¯¸ë˜ë¥¼ ë§Œë“¤ì–´ê°‘ë‹ˆë‹¤** ğŸš€
